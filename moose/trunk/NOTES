API:
Must make it easy to put an existing vanilla C++ class into this framework.
Options: 
	Dual derivation
	Templating.


Class heirarchy:


Moose definition:

Messaging: Function calls into objects.
	Initiator of call can be local to the object or remote. 
	Call can be local method or method of a remote object.
	Arguments can from the initiator, from the target, or from others.
	Return values are always to initiator. Can NEVER directly alter
		remote fields, but can call a function with arguments to do so.
	Messages represent both once-off function calls as well as long-term
		connections which are part of the heirarchy.
	Messages do permission checks at creation only. If permissions
		are changed the changing function must check existing messages.

Heirarchy: All entities are part of an object tree/forest. 
	Access is through paths. 
	Paths can include an index.
	Some nodes can have additional children added, or index limit increased.
	Fields are children of other objects.
	Messages are also fields.
		Messages have fields, like src, dest, etc.
		A message connecting a field of A to B is a child both of
			A as well as B.
		Messagelists are arrays of msgs with identical function.
		Not all classes have messagelists.
	All objects have fields (children) specifying their own identity. These
		include name, class, id, index, access permissions etc.
		Note that this requirement
		is recursive, so the heirarchy will be recursive too;
		but the ids need not.
	It is possible to have 'links' which are similar to UNIX file links,
		pointing to an object elsewhere on the tree as if it were
		another field. Parent of a link is the original parent,
		but parenthood is transferred if original parent is deleted.

Ids: Unique lookup for any object.
	The path or pointer of an object may change, but not its id.
	Ids have a namespace within which they are unique.

Classes: Object classes.
	Regular operations of derivation and overriding.
	All objects know their class and can refer back info about themselves.
	Class infos are also objects which can be accessed in regular ways,
		but a lot of the fields are obviously readonly.


Implementation issues
Objects: Must have minimal housekeeping costs. Big array of ints should have
	same size as C++ array of ints plus small fixed overhead, not
	linear scaling with N.
	Why ? Because every object is in heirarchy and has housekeeping info.
	Need to decide whether to require custom-built moose
	classes, or to provide wrappers for existing C++ classes to help
	them plug into the Moose framework.
	Need to add field info to class info. This should be possible in a
	manner which only uses the info from the original class.

Ids: For now can use pointers.
	Id::GetPtr: Returns ptr of object. Never need it for regular operations,
	but needed for interal functions.
	Id::GetClass: Returns classinfo for object.
	Id::Root: Returns root id.
	Id::Err: Returns error id.
	Id::GetFromPath: Returns ptr after checking path.
	id Id::Execute(id arg1, id arg2, id arg3 ...): Execute the function
		of the id. Not much use unless we already know what func
		the id represents.

Arglist:: Array of ids with # and typecheck info.

Messages: Need to define whether initiator is local or remote.
msg::Verify(arglist): Check # and type of args.
lmsg::Add(arglist) 
id rmsg::Add(arglist) // 
id rmsg::Execute(arglist)
Executing/calling messages.
	How general do you want it ?
	Assume rmsgs only send arguments consisting of their own fields.
		Then the arg types in the function can be regular types.
	If not, then we are in the same pickle as with lmsgs where the
		arguments come from other elements. In brief, how do we
		specify arguments of arbitrary type ? This is the crux of
		the field access system.
	Suppose we compile in the function call each time ? Basically moose
	would need to generate a cpp program, which would have to be
	compiled in with the rest of moose, and then run.
	Seems like the system command should be executed to do the compilation
	and if it works, the compiled output can be executed using 
	execve. What fun! This gives us a nice powerful interpreter to use
	as a bonus. I can only hope that Windoze has some equivalent stuff.
	I believe gcc works there but the shell stuff may be tricky.


4 Jun 2001
Examine implementation using multiple inheritance rather than templates.

See if there is a way to initialize the table of field info in just one place.
Currently the _MFIELD macro is an ugly way of defining the access func and the
field name, and needs a subsequent call to ft<class>::AddField() to fill in the
table entries.

Look closely at msg definitions. They are already highly optimized, but it
may be possible to clean up the handling specialy of the pointers.

ft inherits from fi, which provides props, name, and parent.
ft provides a const access func: create-only.
	static const cid c: defined only once for the templated class.
	static fidlist fl: Filled in fields for the templated class.
	
	InitClass(): called when classes are initialized to set up field info
	Create()
	Set
	Get
	StrSet
	StrGet
	Exec
	Child
	AddField: This is used when initializing classes to put fields on the
		list.
	Fields: Fills in an arglinst with field infos.
		The field infos are filled in as ids. A bit awkward.

=============================================================================
1 Sept 2001.

Based on the historical record of the progress or otherwise of MOOSE
(now 7 years of it) it is pretty clear that I will not be able to make
the whole thing at the functional level of GENESIS in any likely stretch
of time that I may get. So my course of action is to get a function core as
simply and painlessly as possible, and then extend it when possible.

A functional core should only have the most central MOOSE attributes.
Job now is to define them.

Core consists of:
Stuff to define classes and fields and messages
Stuff to create objects
Stuff to attach messages
Stuff to call actions (which are messages).

Stuff to implement with core:
	Signaling stuff.
	(Should be easy to do an interpreter for the very limited dumpfile)
	xcut stuff.
	Some kind of link with Apache and php or Java to do sims.


Generic scaffold option: Define a generic scaffold class which has
parent, kidlist, classinfo, name, and ptr to actual object. 
Cost is pretty trivial, extra ptr is all. 
Classinfo provides specific access functions and field info.
see ci.h.

Classinfo is class specific. Takes obj ptr and casts it into known class.
Could even be templated or multiply inherited from the target class.
Provides standard access funcs: Set/Get/StrSet/StrGet for its class.

Classinfo also has to keep track of the field list. This is basically an
array of other classinfo ptrs for the fields.

In old version the field info gets templated in ft.h to reflect the specific
field. The idea is that stuff to do with accessing field goes in ft.h,
and stuff to do with generic info about class goes in ci.h. One would think
that the fieldlist would be part of ci.h, but not so. It is in ft.h.
What the ft does is to set up access functions mainly. Since fts are unique
for each field and so are fidlists, the fidlist is in ft.h. Seems like I may
as well copy over some parts of the original ft.h.

Access to fields. Earlier I used an AccessFunc. Passes ptrs around. Would
prefer to use regular methods for fields if possible. Almost all GENESIS
type objects would have a set of regular fields which do not need fancy
pointer access operations. I need to use an AddField function anyway to build
up a field list. Could simply plug in methods here. Or even build up the
methods as templated functions taking the references to the field as args.

Tested out a really bizarre idea: use a program to write a program file,
compile it, and run it. Much to my glee and surprise, it works.
See the little directory exectest. Some pretty cool possibilities here.
Actually what I really need is to write out a function in a file, compile it,
and link it in with the currently running program, and then call the new
function. I think this is just what
insmod does with the OS, so it must be possible. Hope it isn't too horrible.
Nothing obvious about how to accomplish it, though. Can get a similar eff
with the exectest method, but will lose local info and will be very slow.
Directions: Proceed with exectest format for now. It is unlikely to be needed
often in interpretive mode. Usually the 'script' file will be worked out
well beforehand and can simply be compiled in with the rest.
Also contact the authors of insmod and find out how to do similar things
with my pgm.

Major issue: Consider situation with msgs. Is the system going to output
the explicit C++ code to contact each target ? Doesn't make sense.


=============================================================================
2 Sept 2001.
Given the problem with using msgs with explicit C++ code, I'll skip the whole
redesign process for now and instead clean out stuff from the previous
incarnation of moose. I'll write a little function for converting the 
script dump files from kkit8 to the appropriate code. It will use the exec
trick from yesterday. Time to get serious and do some benchmarking too.
Then I can also look into array-ifying the computations and doing a 
Gibson/Bruck algorithm.

OK, compiled in old stuff sans interpreter. Let's see if I can cook up a
converter for the kkit8 scripts. I'll also need to make a table object
for this to work.

- Something to skip the header stuff. Best option is to allow only certain
	keywords.
- simobjdump: It would be easier to assume a fixed sequence, but unreliable.
- simundump: Trivial once simobjdump is done.
- Need to create table class.
- loadtab
- Something like in the simdump stuff where I can convert objects (xplots)
	to tables.
- addmsg
- Never mind the calls for the notes. This would be easy to add later.
- Something to execute the simulation
- Something to dump the plots.

OK, an idea: use a derived or friend class rather than all those funny fields
within the regular classes/structs.
Also, perhaps all fields can be passed around as straightforward fields
rather than mfields for the purposes of messages and general field access.
The only reason for
the whole mfield business is to provide a handle to the fields.
It would also be nice to be able to template the mfield business rather
than using #defines. 

Plain code:
	inline Myclass* Classptr(const eid e, const int i) {
		return (Myclass*) e.Data();
	}

	static void* Access_foo(const eid e, const int i) {
		return (void *) & Classptr(e, i)->foo;
	}



}
Hm. Looks like I don't even need to template. I just hand the Access_foo
function pointer to the field template.
To do this I only need the original class changed to allow the access class
as a friend.

I think I can similarly clean up the messages which currently require
a friend function to implement the message, then a template tying the
function to the type of message, then a typedef for the template,
then an mfield. Would be nice to consolidate.

=============================================================================
3 Sept 2001
Working on cleaning up msgs. First, nomenclature. It seems I am still using the
moose2k nomenclature for lmsgs as msgs whose function is executed locally, and
rmsgs as msgs which execute remote functions. Good. I could make it a little
clearer if I said lfunc and rfunc, but this is very low priority.

Args needed by msg templates: 

lmsgsrc: Source of data to be used by lmsg. The required info is already
	there in the msg housekeeping info.
	No template args.

lmsgdest: Location of execution and initiation of lsmg. 'Passive' msg of old.
	ExecFunc, VerifyFunc, N
	(Shouldn't VerifyFunc know N ? Maybe template can't use it directly)

rmsgsrc: Initiator of rmsg, source of data. Possibly one could have an rmsg
	where the initiator and sources of data are different, but this would
	be equivalent to an rmsg calling a function with an lsmg.
	PtrAccessFunc1, 2,... according to # of args. No args for zero arg rmsgs
		A bit odd here. Why use PtrAccessFuncs ? 
		OK. PtrAccessFuncs take the source data as a ptr.
		AccessFuncs take the source data as an eid and an index.
		Should rationalize. See above. Would be easy to do.

rmsgdest: Location of execution of rmsg. 'Active msg' of old. 
	ExecFunc, VerifyFunc.

Info for looking up dests is based on the mgsrc base class. This has a vector
of entries {msgdest *dest, msgid i).  i is currently 
just the index of the entry in the dest list. This is used both for
lmsgs and rmsgs.

Info for looking up srcs to rmsgdests is a vector of msgsrc. This assumes
that all args come from the same src, so there is no need to keep track of
each individual arg. Could be problematic as there is no info on specific
msg slots. Actually the PtrAccessFuncs should handle this part.

Info for looking up srcs to lmsgdests is more complete. Each entry has 
src and a ptr for each arg. Vector as before of entries.


Possible simplifications:
- Verify func is not going to be called all that often. Could make it a func
pointer. Cost in speed and memory use in the msgdest. Forget it.
- Friend func to implement msg may go away if I use a static field in the msgs.
- template probably still needed. I hate the complexity of it though.
	Is there a way to use default template args ? That would start to
	collapse the mess into just a msgdest template and a msgsrc template.
- typedef may not be needed if the msg field is created in the parent class
	(using template etc, of course) and then the regular friend class
	handles the presentation of this msglist as an mfield.

=============================================================================
8 Sept 2001.
Starting to implement nshell.h and nshell.cc.

Template ft is needed only for Create and Set functions.
The rest could be handled by a more generic class.

The interface class should take over the Set and Create functions. That
will eliminate the need for the field template class. The Set function
is already supposed to be set up explicitly somewhere in the class,
so lets move it out into the interface class.

The interface class already is meant to handle the Access functions. The
remaining things that the ft class does are:
Cid()
InitClass()
Create()
Set()
Get()
StrSet()
StrGet()
Exec()
Child()
AddField()
Fields()
InitFields() // defined specifically in the element.cc file.
	and it has fields for
cid c
AccessFunc (For use by the parent of the ft in its fieldlist I guess)
field list 

=============================================================================
15 Sept 2001
Really need to get in more consistent work on this. I hope that with the
postponement of the Wellcome meeting I'll get a chance.

It looks from above that I could inherit most of the functions in the list
from a virtual classinfo type base class. Virtual is OK because the rapid
access stuff is only needed in the messages, and setup can deal with an extra
indirection. 

The functions which need to be classs-specific (cannot be inherited) are:
Create
Set
StrSet
StrGet in part.
Exec sometimes will need to be overridden

OK, I have the fidlist initialization sort of worked out.
There are some exotic strange things going on with initialization of the
messages, such as rmsgsrc1<ShellOutstrPtr>. The templated func is now
just the Access_outstr function, but the class has a bunch of things that
need to be inited like arglist which is just a vector of ids. 
I've set a guess at this up, but it probably won't work. The general pattern
should be OK and is a bit cleaner than it was.

Next step: general implementation and compile.

=============================================================================
16 Sept.
I can replace Set, StrSet and Exec with messages. Create is an internal and
may have to stay. StrGet... hm.
But the Set message has to be located on the parent elm. Need to implement
to see how it will work.

Things needed to get a usable build

Stages
. Creation and deletion of data objects. These can now be regular classes
  with _info suffixes for handling, or m_ prefixes.
	str
	int
	double
. Creation and deletion of elms
. Creation and deletion of messages
. Execution of messages



Ok, began implem. Not much luck so far, a compiler problem which is hard
 to sor tout.
=============================================================================
17 Sept.

Sor touted it. I was up way too late last night. I now have a clean little
compile of the following files:

	main.cc
	str.cc
	cid.cc

plus the headers
	cid.h
	prop.h
	info.h
	fid.h
	fi.h
	ci.h
	str.h
	defs.h (which contains the headers in the right order).

Of these, I can put the contents of cid.cc (just one line to define the vector
of cis) into the main for now, and I do not yet define the vector for fids
either.

Lots of fun trying to now use this to actually create a string. Much needs
to be cleaned up. Looks like I need to put in the startup scan in the main
right away to build the class.

=============================================================================
29 Sept.
Lost the thread. Unfortunately I was doing lots of stuff to extend it and
nothing works anymore.

OK, getting back into the hang of things.
It would be nice to eliminate ci as a separate class from fi. The idea is
to have the ci information (name, author etc) saved as static fields within
each fi derived class. That way instances of m_string would all share the
common ci information. Problem is that a static field in a base class
gets shared among all its derived classes. We want a static field which
is unique to each class derived from fi.

So: 	fid is a handle to an instance of an fi-derived class.
	cid is a handle to static info in fi-derived class
	ci is the static info in the fi-derived class.

As soon as the system is inited, it already will have a heirarchy of
fis. For consistency I want to make this heirarchy a part of the general
object heirarchy. Among other things it will help to use the same 
functions to find fis.

How will Create() be called ? Various levels of use:
	- As method of a class object. Just gives back a ptr.
	- As method of the elm object. Requires info about parent and class.
	- As msg going to one of the above objects. Obeys msging rules.


How are fid and cid to be managed ?

- Do not have field lists within fi-derived classes. Instead build up a
	regular elm heirarchy based on /root/classes.
- When creating a new mclass, build up on this elm heirarchy.
- Need to init the elm heirarchy before anything else.
- Get rid of most of 'info' fields from fi. They go into the elm.
- The cid is a special set of eids which are guaranteed to be classes,
	and uses a special access func to call class-specific commands.
	Could have a special subclass of elm for fis, eclassinfo.
- The eid manages a vector of elms. Elms do not have pointers to each other
	but only eids.

Current status: Building elm class.
Need eid class to keep track of elms.
need bootstrapping of eid so that the root elm is always formed first.
	Perhaps this could be done using efieldinfo.

Need to sleep.
=============================================================================
30 Sept.

Bootstrapping. Should the API use elm creation as a way of making eids,
or eid creation as a way of creating elms ?
	- multiple kinds of elms and the eid won't know which is desired
	- Use eid(elm) and cid(efieldinfo)
	- Use cid to do bootstrapping since it is not called too often and
		can check for presence of root each time.


Current design:
- Bootstrap formation of root and classes eids occurs from the efieldinfo.
	The Neutral cid is also made at the same time.
- All the classes are stored as children of /classes
- fi contains class info as a static, and a static cid for itself. These
	two static fields have to be initialized for each new class.
	- cinfo contains class heirarchy info. Needs to be parsed and filled
		in to get base class etc info in cid form. 
	- c (the cid) contains field heirarchy info since it points to the
		location of the fieldinfo in the /classes tree.

Works so far for the test case which involves the bootstrapping, the
storage of class info, and the generation of a variable (a string) 
when the type name was passed in. Pretty good.

Next to start creating elements of given type on parents
Then to insert messages for the elements to manipulate their values.

There is something a little funny with the makefile. It doesn't want to
provide the -g flag to the main, but is OK with he rest. Doesn't matter
if I rename the main or reposition it.

The fi/cid/efieldclass set of things needs renaming
The neutral as an elm, and neutral as an empty field type needs renaming.

=============================================================================
1 Oct.
The cid provides for creation of a data object.
The neutral provides for adding child elements once they have been created.
To create a full element, need to specify both the elm subclass and the
data class.
The elm subclass should in its creation function call the data class creation
function since it may want to set up arrays etc.
May need size argument for some elm subclasses e.g, specify array size.
Not worth generalizing till I know more about how it works.
All elms should have an equivalent set of args for creation.
How to store elm class info and create functions ?
	General notes:
	- Elm create function is different: needs parent, name, props, size,
		and classname/cid of child. Returns id of child.
		The overall create defaults to a single child, but qualifiers
		like arrays or properties (c.f. const) can be added.
	- Would need a mechanism for redirecting access queries to elm or
		its value.
	- Various 'automatic' fields like name and parent are elm based.
	- The 'automatic' msgs of Set, msgsrc etc are also elm based.
	Options:
	- Two obvious options: same classes tree, or separate elmclasses tree.
	- Regular classes tree reuses field access stuff.
	- Regular classes tree would need to guarantee that elms are used
		for elm part and vice versa.
	- Probably would only need a couple of lines to do separate elm tree
	- Probably wouldn't make much diff to simplicity anyway.

Nomenclature:
	Class id:						cid
	Field/class information base class (currently fi):	m_base
	Class information sub-part of m_base (already ci):	ci 

	Field/class information class for a data class:		m_<name>
	Field/class information class for an elm class:		m_<name>
	Empty data class (currently neutral) :			empty
	elm handling data:					edata
	elm handling data array :				earray
	elm handling kids only (currently neutral) :		eparent
	elm handling kids and data :				epdata
	elm handling kids and data array :			eparray
	elm handling field/class info:				eci

Stuck converting the names. Now to sleep.
=============================================================================
2 Oct.
Fixed conversion. Also cleaned up the files so that each class has its own
files.

Now implementing the element handling stuff.
Problem: The access func stuff usually returns volatiles. This means that
	the return value must immediately be put into local storage.
	- Among the props we can specify the kind of access func and things
		like messages which need to repeatedly access the value can
		take this into account.

Problem: Recurrence of the initialization order stuff. Here the elm
	table within eid is getting reinitialized after having lots of
	stuff loaded in from the Bootstrap routine.
	Patched it over by using a static pointer to the table rather than
	a direct definition. I checked that the pointer was null and then
	allocated it within the bootstrap. Works but adds another indirection.


Feeling my way through the implementation of element creation. As always, the
location of the key function needs some fiddling. At present I have put the
key Create function as a virtual func on the elm to be called from the
viewpoint of the class to be created function. This is silly, because
the function won't be called unless the elm already exists. I should
make it a virtual func on the putative elm parent so that it will know if it
is able to have any children.

elmparent::Create -> check datacid::Create -> 

elmparent::Create -> elmcid->Create -> elm<type> constructor -> datacid::Create

Let's keep the element code, like the data field code, as separate from
the glue stuff as possible.
This means put the creation function in the m_base derived class for elms.
Put it in the m_base for the class which is to be created, obviously.

OK, got stuff to work with creation of a string elm. Verified that the
thing was in fact being created with the data in it.

There is obviously much scope for cleaning:
- cid and ecid overlap greatly and could be merged.
- formation of e_base subclasses should be templated as it is almost
	totally overlapping. Alternatively the only real difference in
	these classes is the Create function and perhaps the field access
	stuff. These could be set up as fields rather than in a class.
- Haven't yet put in access to the ci fields.


Then, next steps:
	- Deletion and copying of elms including trees
	- Accessing individual fields
	- Messages/functions

=============================================================================
6 Oct.
Better not lose momentum
Minor stuff: Got rid of excessive reporting of creation of stuff.
Implemented elm::Path()
Stuck implementing a printout of the class name. Deferred. Minor stuff.

DeepCopying sort of working. Need to do some more checks. Need to be able
to pass in new name for element being copied.

Put in check for copying onto descendant.
There is a bug somewhere which produces large numbers of copies and causes
eventual segv.
Still need to put in name of new elm

=============================================================================
8 Oct
Fixed problem with excessive copies. I was doing two AddChild() calls.
Fixed stuff for name of new elm.
Need to provide easy way for pdata to do Set and StrSet as rmsgs/funcs

=============================================================================
17 Oct
In danger of slipping again. Huge pressure due to teaching and now the 
doqcs stuff.

Analyzing old msg stuff from moose2k:

		both			lmsg			rmsg
msgsrc: 	Add,Drop,Arglist,Nmsg				Execute,AddArg
		vector<entry> destlist
		entry has msgdest* and msgid

msgdest:	Drop,Execute,Data	Lmsg,LExecute		Rmsg,RExecute
				     vector<entry> msglist    vector<id> srclist


msgsrcs only need to keep track of what is at the dest. Pointer to msgdest
	and msgid (index) is unambiguous. The msgdest contains a ptr to
	its parent elm.
	Comment:
		Problem because indices can shuffle when
		msgs are deleted. Can rearrange with call to single additional
		msg, rare enough that it should be OK.
	- Rmsgsrcs also have an Execute function which takes the current elm
		and the context and loops through all targets calling their
		RExecutes.
	- Rmsgsrc also has an arglist. This gets compiled in as a static.
		Makes sense when you consider that the access func is 
		also compiled in. Could generalize out access func as well
		as arglist by storing data ptr locally or storing 
		access func locally. This would enable one to use a single
		Rmsgsrc list for any combo of outgoing values.
		Would help if a given rmsgsrc was used only to send a 
		particular piece of info out. Perhaps would like to
		use an rmsgsrc to send out any field. Then the arglist should
		be specified for each instance of a msg, rather than for the 
		msglist.

msgdests need to do the rest:
	- Keep track of src. Rmsgs just need src msglist id, since the
		calling function provides arg ptrs. Lmsgs have
		src eid and ptrs to each src field.
	  Comments:
		Rmsgs are fine.
		Lmsgs should be generalized to have unique id for each field
		as the fields could come from different elms. Further, should
		store accessfunc rather than field ptr in many cases to
		handle calculated fields and the like. Problem in that
		the elm now stores pointer to the actual object, rather
		than being the actual object. Thus field ptr is attractive
		for fast messaging.

	- Create msg, including arg checking and setting up src list
	- Drop msg, including cleaning up src list
	- R/LExecute function. In Rmsg this is for a single elm.
		In Lmsg it loops over multiple
		srcs, and in func calls also needs arg checking
	- Keep track of parent elm as data*.

Other stuff:
typedef const int (*ExecFunc)(void* data, const context& c, const void** arg);
data* refers to the local ptr to the parent elm
context refers to stuff like timestep, root, etc.
arg is an array of ptrs to the arguments. Would like to improve on this
to reduce indirections. Can't use it for calculated fields.

typedef const int (*VerifyFunc)(const arglist& al);
This is straightforward and is not time-constrained.

Comments:
	The ExecFunc for rmsgs could be expanded to take individual
	arg ptrs rather than array of arg ptrs. Would need at distinct
	ExecFuncs for each # of args.
	The ExecFunc for lmsgs could be expanded likewise.
	Both these options would trade fewer indirections for more stack in
		some cases.
	The Rmsg calls can easily handle calculated fields since it is
	the local elm that calls the ExecFunc
	The Lmsg calls are not so simple.

Simplifying options
	- Use single arg msgs only. Trade off multiple msg calls for the
		rarer cases where more args are needed. May need buffer
		to fill up multiple args. Minor problem when
		executing functions explicitly.
	- The msgs might not need to be derived from a virtual base class.
		There are only a few variations and they are not accessed
		by unknown pointer. Problems would arise if msgs become
		more creative than the predefined set. Which is likely if
		I use templates as I do now.
	- The m_base class handler has to define msg ExecFuncs, including
		ones for the use of Set and StrSet.
		VerifyFunc could be passed in as a ptr, does not have to
		be templated. Or it could be written in the msgdest derived
		class.
		For Rmsg, we could derive from the rmsgdest class using
		RExecute directly in the m_base file. The Execute
		func could call RExecute. These two moves eliminate templating.
		For Lmsg, the ExecFunc could be defined directly, but
		calling it for LExecute would entail virtual class lookup
		around a loop.
		Not clear that any of this elimination of templates is
		particularly useful.
I still await inspiration.

=============================================================================
18 Oct.
Let's take the other tack: Optimize on simplicity. Later worry about efficiency.

Options
- ExecFunc takes as an arg a class which stores data, context, arg ptrs etc.
	This object is initialized at the start of the msgloop. The object
	knows when to use ptrs and when to use Accessfuncs
- Args are stored as elm ptrs/eids and accessfuncs for them. The eid is
  	needed in any case to provide msgsrc info. The accessfunc
	subs for the ptr to the value.
- There are two kinds of msgdests: one uses ptrs, other uses AccessFuncs.
	Since the msgdest is already using virtual funcs, no additional
	overhead in selecting.
- Ban function calls with args. Provide separate stuff for passing info,
	it goes in buffers.
- Brute force it. I am using virtual classes so I may as well pack in all
	the variations explicitly:
	src:
		All lmsgs and zero arg rmsgs use the baseclass msgsrc
		Single arg Rmsg with pointers
		Single arg Rmsg with AccessFuncs
		Single arg Rmsg with compiled-in ptrs
		Single arg Rmsg with compiled-in AccessFunc
		Double arg Rmsg with pointers
		Double arg Rmsg with AccessFuncs
	dest
	- Zero arg Rmsg
	- Single arg Rmsg both for pointers and AccessFunc
	- Double arg Rmgs both for pointers and AccessFunc
	- Single arg Lmsg with pointers
	- Single arg Lmsg with AccessFunc
	- Double arg Lmsg with pointers
	- Double arg Lmsg with AccessFunc

Give up. Go with the brute force and the plethora of subclasses it entails.
Implement generic SET msg.

Note that rmsg on its own is pretty useless, as is lmsg. Both need something
to trigger them. The likely triggers for rmgs are graphical ops, interrupts
and of course the scheduler. Triggers for lmsgs will probably be the
scheduler via rmsgs. It would be nice to be able to make cascadable msgs
which detect events like assignment of fields, and cascade off them. So
the Execute function of an rmsg might itself call an rmsglist. Callbacks
would make sense particularly for the Set function. Would need to know
which field was set. Since the field itself is set, this would be
a fixed-src Rmsg.

Let's go one more level of generality. Every settable field (by definition,
StrSettable too) would have a message to set it. There can be a general Set
message which on a per-message basis assigns any settable field, and can
also call an Rmsglist of its own. This is for the general case, efficiency
is not critical. Other Rmsgs and Lmsgs are optimized to varying degrees with
the options above.

=============================================================================
19 Oct 2001
Slowly making the message data structs. Mostly based on stuff from moose2k,
but changes in how the ExecFuncs and the ptrs work.

Need now to integrate it in. The msg stuff uses ids, Cids, and arglists,
all of which need to be handled.

fids: This turns out to be remarkably simple given the nice structure I have
already set up. The eids of the children of Classes, on their own, will
do the job. Even issues of which field is parent or child of which are taken
care of. The only thing I need to add for a fid class is a check that the
eid in the constructor is in this heirarchy. After that I just look up the
eci. Neat.

On the same lines implemented first pass at id too. Still very neat. Almost
all operations are inline in the header. now need to incorporate, compile
and test all this stuff. Not much is useful right away.

Amazing. Incorporation and compilation went utterly smoothly.
Testing is superficial, but looks good so far.

=============================================================================
23 Oct. Where do the days go.

Working on ideas for general SET rmessage. Tricky part is that the base
Rmsg(const id s) call does not take any other args, for example, to specify
what the dest is going to be. I could create a calculated rmsgdest field
for every normal field which allows SET: this is in fact the general idea.
The point is to make this happen invisibly for every settable field.

OK, that can wait. First do simple incorporation of msgsrc and msgdests and
attempt to make something like a scheduler which cranks out lots of rmsgsrc
calls. Got it to compile all the junk in. Now AccessFunc is const only.

In progress: context, clk, still need sched_job
Should really first get Set sorted out since I can't easily assign fields
till that is done.

=============================================================================
24 Oct. 
I'll start off with the pdata handling a very specific Set msgdest
for the string class. Once that works I'll better be able to see how to
generalize it first for arbitrary single-value classes, then for
arbitrary multi-field classes.

OK, got the Set message to be made. Issues:
- Verify uses an arglist. The arglist should really be a list of cids.
- Need to get Execute working so I can test the msg passing.
- Need to trigger some messages automatically for the same.

=============================================================================
13 Jan 2002.
Months away from any work on this, but wild ideas strike occasionally anyway:
why not do away with parent-child stuff and instead set up such relationships
using messages ?

=============================================================================
24 Jan 2002.
Not now to work, but perchance to plan. Design and then implement.

Core concepts:
	Objects contain fields
	Object info is stored in a heirarcy off /classes
	Messagelists are fields
	Messagelists can be rmsgs and lmsgs.
	Functions are implemented as messagelists
	Parent-child heirarchy is implemented through messages
	Arbitrary C++ classes are the data part
	Elms are the scaffolding which holds the data parts
	Elms are accessed through eids
	Fields are accessed through eids and fids.

...................................................
Objects contain fields.
	Parameters are fields
	Fields can be 'evaluated', that is, occupy no storage but get
		calculated each time the field is accessed.
	Message lists are fields
	Message lists can be rmsgs and lmsgs.
	All messages in a message list are of the same type, only src/dest vary.
	Rmsgs pass args to be executed Remotely.
	Lmsgs collect args to be executed Locally.
	Rmsgs have a single Source and a single Destination.
	Lmsgs can have multiple Sources and a single Destination.
	All private functions are Lmsgdests. 
	All public functions are Rmsgdests.
	All Message Lists have a Verify method for checking args.

	There are zero-arg Rmsgs for parent-child relationships and for
		triggering actions without arguments
	There are generic Rmsgs which pass the fid of the dest function
		and its args.
	There are specific Rmsgs with well-defined numbers and types of args
		for stereotyped, rapid function calls.

Object hierarchy is set up using zero-arg Rmsgs to list kids of parent.
	This Rmsg could be used to delete the child. 
	The base object is /, also known as root.

Class info is set up on a parent object called /Classes.
	Children of /Classes must be classinfos.
	Each class has its own classinfo.
	The classinfo for a class foo is a unique class called m_foo.
	m_foo is derived from m_base.
	m_foo is a friend of foo.
	m_foo knows how to Access, Create, Destroy, Copy, get Cid, etc.
	Fields of foo are represented by children of the m_foo.
	Each child is itself derived from m_base.
	
Class heirarcy is set up again using zero-arg Rmsgs. 

Bootstrapping:
	When the first classinfo is created, it bootstraps and creates a 

I currently have distinct e_base and m_base. e_base is for element info
	m_base is for the data part of each class.

=============================================================================

26 Jan 2002.
Updates.

Core concepts. New ones are marked with a +
	Objects contain fields
	Object info is stored in a heirarcy off /classes
	Messagelists are fields
	Messagelists can be rmsgs and lmsgs.
	Functions are implemented as messagelists
	Parent-child heirarchy is implemented through messages
	Arbitrary C++ classes are the data part
	Elms are the scaffolding which holds the data parts
	+Elms and other objects are all handled by same object info
	+Elms have a special flag in the obj info.
	Elms are accessed through eids
	Fields are accessed through eids and fids.

Accessing elms and fields.
	Requirements:
		Unique ids
		Handling arrays
		Handling multiple fields within each element
		Handling parent objects as a single field
		Handling multiple nodes
		Collapsing complex elms into composites
	Elm lookup
		Eids are an integer lookup in a table of element pointers.
		Data values could just as well be an integer lookup in
			a table of void ptrs, but this can't handle redirection.
	Field lookup
		fid is a unique integer and is actually just the eid for
			the classinfo on the /classes heirarchy.
	Elm and field lookup happens mostly in the setup/compilation phase.
		Go for generality.
	Eid -> elm_ptr
	fid -> class_elm_ptr -> Value -> classinfo ->
		AccessFunc(elm_ptr->Value()) -> field ptr
		Streamline: Table from fid to AccessFunc
			Accessfunc takes elm_ptr directly,
				does Value call internally if needed.
				This gets rid of issues with elm vs data fields
		Overload the AccessFunc to take indices
		fid does not have indices. These are separately handled.
		All fids that are data parts will ask the elm for its Value().
	id has eid and fid.
		id lookup: AccessFunc[fid](elmtab[eid])

	Defining composite elms: 
		Make heirarchy of classinfos analogous to element structure.
		Use existing classinfos for basic properties of heirarchy
		AccessFunc takes an 'offset' arg as well to locate data ?

=============================================================================
7 Feb 2002
Updates
Core concepts. New ones are marked with a +
	Objects contain fields
	Object info is stored in a heirarcy off /classes
		The children of /classes are pdata with data class cinfo
		The children of /classes/<classname> are pdata with data class 
			derived from m_base.
	Messagelists are fields
	Messagelists can be rmsgs and lmsgs.
		Msgsrc has a table of 'entries' with msgdest ptr + index
			This works both for lmsgs and 0 arg rmsgs
		Multi-arg Rmsg msgsrcs also have arg lists or equivalents.
		Rmsg msgdests have a vector of msgsrc ids.
		Lmsg msgdests have a vector of msgsrc ids for each arg,
			plus also arg ptrs or arg accessfuncs.
			In use the arg ptrs are accessed directly.
		+All msgdests have as their 'data' field an identifier for
			the elm. This is used for the first argument for 
			the ExecFuncs. 

	Functions are implemented as messagelists
	Parent-child heirarchy is implemented through messages
	Arbitrary C++ classes are the data part
	Elms are the scaffolding which holds the data parts
	Elms and other objects are all handled by same object info
	Elms have a special flag in the obj info.
	Elms are accessed through eids
	Fields are accessed through eids and fids.
	+Elms contain access and ownership info similar to Unix
	+A multithreaded scheduler/job/clock system runs stuff through rmsgs.
	+Work is done on objects through _shells_ which supply access info
	+shells direct tty input to an interpreter for action.
	+Users have a home object with user access info, and root of user tree.
	+Logins: Could have daemon that detects logins and spawns shells


Fixed Makefile; now it handles the cflags properly.

=============================================================================
9 Feb 2002
Trying to rebuild scaffolding. First eids and elms. 

Bootstrap currently: Each class has a static ci and a cid.
The formation of the cid makes an eci, which calls the eid bootstrap routine.
It creates the elm table. There is a static pointer in eid for the elm table.
This strange sequence is needed because the time of init of the different
static things is undefined. If we could either force the init of the
eid elmtable to happen at first, or avoid it overwriting stuff already
there, it would be better.

Shoved it under the carpet for now. I want to get the parent-child
stuff working.

Getting close. Connected msgsrc to dest, for parenting, but the reverse
side of the operation is not yet done.

Done that too, but with numerous hacks because the rest of the infrastructure
is missing. Time to sleep.
=============================================================================
10 Feb 2002
New bootstrap: Have a global for the root element. This can be the hook
for the bootstrap routine and all the class infos which get created. Once
main starts we can worry about filling in the elmtab for these.

Started out structure for this, not much to do yet. Need to streamline
connecting up parent/child elms for this to work with the class definitions.

OK, now working on cleaning up class initialization.
The new cinfo class has name, author etc info plus cids for base and self.
This replaces the separate cid and ci that the m_base derived classes
used to have.
All m_base classes have a static const cinfo
When the program loads, the m_base derived classes must define their cinfo.
The cinfo calls the bootstrap routine.

cids refer only to the elms directly under /classes.
These elms will have a tree of fields. 
fids refer to the elms under /classes as well as to their children.
Both cids and fids refer to elms which contain m_base derived classes.
Both cids and fids are derived from eids, and refer to the same elm
	as the equivalent eid would.
We would really like to know the eids from the start so we can use them
	while bootstrapping.
OK, let's try going back to an old fashioned array.

That works.
Immediate things needed:
+parent/child stuff. Can we force elms to have a parent on creation.
	*To find parent, we just need to look up source. This is possible
	from both lmsg and Rmsg, but with lmsg we can have multiple
	src for a single msg. May need a second arg for the argno.
	-To find a child we need to look up dests. These are ptrs to the
	rmsgdests of the children. The msgdest has a data field which
	stores the elm ptr in this case.
-Class/cid implementation
-Field id implemention.
-Smoother handling of parent/child/msgs

=============================================================================
17 Feb.


+parent/child stuff. 
	*Can we force elms to have a parent on creation.
	*To find parent, we just need to look up source. This is possible
	from both lmsg and Rmsg, but with lmsg we can have multiple
	src for a single msg. May need a second arg for the argno.
	-To find a child we need to look up dests. These are ptrs to the
	rmsgdests of the children. The msgdest has a data field which
	stores the elm ptr in this case.
-Class/cid implementation
-Field id implemention.
-Smoother handling of parent/child/msgs


Here I run into a problem with the implementation of messages. It is not
possible to find the destination id. I do have the pointer to the msgdest.
	- Use the id to the msgdest.
		Costs storage. I can afford that.
		Costs indirection when calling the message. Cannot afford.
A related problem is that the msgdest itself maintains only a pointer for
data. This pointer is used by the ExecFunc and was intended to be the 
pointer of the reference object on which the ExecFunc acts. What happens
if the data gets reallocated ?

Details of message stuff:
Calling an Rmsg: Event at the src calls Execute of the Rmsglist. 
	Looks up each dest entry in msgsrc::destlist. Calls its
	ExecFunc<N> function with appropriate args provided by event function
	at src.
	The destination entry has a pointer to the appropriate object to
	call with the ExecFunc<N> function.

Calling an Lmsg: Event at dest calls Execute of the Lmsglist.
	Goes through vector of arguments calling the ExecFunc<N>.
	The lmsg has a pointer to the appropriate object to call with the
	ExecFunc.  Looks up other args in a vector of void ptrs.

Finding a msg src from a dest:
	If it is an Rmsgdest, there is only 1 src per msg. These srcs
	are stored in vector<id> srclist. Easy.
	If it is an Lmsgdest, there may be multiple srcs per msg.
	Again, vector<id> srclist. In addition there are arg ptrs.
Finding a msg dest from a src:
	The msgsrc has an array of entries {
		msgdest* dest; // ptr to msgdest
		msgid 	mi; // Index of entry in msgdest. Maybe not needed.
	}
	Options for finding id of msgdest:
	- The msgdest maintains its own id.
		Could be done if elm knows its own id. Doable by using
		eid(pa, name) to create elms rather than the raw elm
		function. Or a global solution - use a hash table to
		find the id of an elm.
	- the msgdest always stores the parent elm, which maintains its own id
		Doable as above. Possible problem with reliance on elm ptr.
		Uses less storage than other methods.
		Incurs couple of extra indirections for execution, to
		resolve elm ptr to virtual func table to accessfunc to data.
	- The msgdest stores both the parent elm which knows how to get its id,
		Plus it stores the data which it has to act upon.
		Doable as above.

Finding msg args from a dest:
	If it is an Rmsgdest, then the src has info on args.
	If it is an Lmsgdest, then the args ids are in vector<id>srclist.

Finding msg args from src:
	If it is an Rmsgsrc, the the src has info on its own args.
	If it is an Lmsgsrc, then the src field is the arg.

Handling elm and obj ptr changes on src:
	msgsrc: This reduces to finding msgs args from a src.
	msgdest: The src id is stored in vector<id>srclist.
		For Rmsgdest that is enough. 
		For Lmsgdest the arg ptrs need to be recalculated from the
			vector<id> srclist.

Handling elm and obj ptr changes on dest:
	msgsrc: vector<entry> destlist needs to have its entry updated.
		The msgsrc finds the dest id from the entry in the destlist.
		It gets hold of the new msgdest ptr and msgid,
		and replaces these values in the old entry.
		
	msgdest: Msgdest itself needs to be recreated. The data field
		will certainly change, but the id will remain the same.
		The msgdest needs to scan its srclist and update the entries
		as above.

Scanning through all msgsrcs: 
	NSrc() gives Number of srcs
	Src(i) gives src for entry i.

Scanning through all msgdests:
	NDest() gives number of dests.
	Dest(i) gives dest for entry i.

=============================================================================
18 Feb.
Msgdest structures contd.
- We always template off msgdests to define a specific one. The templating
	can include the fid of the msgdest.
	Actually it cannot. Templating must be done off predefined 
	values and fields. The fid for the rmsgdest will not be
	known till it is created. I could use a static constant field.
- Storing eid to parent elm is cleaner than storing elm ptr.
- Should elm store its own eid ?


OK, done horrible hacks with the elm creation code. The main operation
now happens in eid::eid(const id& pa, const string&n), since we need to 
pass the eid of the new element to its rmsgdest0 parentlist. Also cleaned up
tests so that the elm is only created when we are pretty sure that its
parent will adopt it.
I have a hook to the CreateFunc which will later become class name or
cid or something, to help create the element of the appropriate type.

Got it all to hang together and work. Now to get back to the list:

*parent/child stuff. 
	*Can we force elms to have a parent on creation.
	*To find parent, we just need to look up source. This is possible
	from both lmsg and Rmsg, but with lmsg we can have multiple
	src for a single msg. May need a second arg for the argno.
	*To find a child we need to look up dests. These are ptrs to the
	rmsgdests of the children. The msgdest has a data field which
	stores the elm ptr in this case.
*Class/cid implementation
	The basic implem is OK. Need to create elms now based on class name.
-Field id implemention.
-Smoother handling of parent/child/msgs


OK, I have much of the infrastructure worked out. Now
to compile in cinfo.h in current version.
=============================================================================
19 Feb
Most of classinfo stuff working. Need to set up the m_parent and 
then put it into the bootstrap so that we can define the elm as well
as the data by name.

I think I have done the class/cid implementation.  I am not too happy 
with some of the ad-hoc functions I've put in to help with the bootstrapping
and loading of the cinfos.

=============================================================================
20 Feb
Core concepts. New ones are marked with a +
	Objects contain fields
	Object info is stored in a heirarcy off /classes
		The children of /classes are pdata with data class 
			derived from m_base. These hold class info.
		The children of /classes/<classname> are pdata with data class 
			derived from m_base. These hold field info.
		+ The m_base derived things are mainly done through the
			m_template.
	+Bootstrapping: All m_base derived classes have a static const cinfo:
		cinfo(name, basename, author, description, m_base* value)
		cinfo is initialized on startup. This calls eid::Bootstrap();
		Bootstrap() executes if elm table is empty.
			- Makes elm table
			- Makes root and classes as parent elms.
			- class_elm->AddParent(id::Root());
			- Makes cinfos for "empty" and "cinfo"
	Messagelists are fields
	Messagelists can be rmsgs and lmsgs.
		Msgsrc has a table of 'entries' with msgdest ptr + index
			This works both for lmsgs and 0 arg rmsgs
		Multi-arg Rmsg msgsrcs also have arg lists or equivalents.
		Rmsg msgdests have a vector of msgsrc ids.
		Lmsg msgdests have a vector of msgsrc ids for each arg,
			plus also arg ptrs or arg accessfuncs.
			In use the arg ptrs are accessed directly.
		+All msgdests have as their 'data' field an identifier for
			the elm. This is used for the first argument for 
			the ExecFuncs. 

	Functions are implemented as messagelists
	Parent-child heirarchy is implemented through messages
	Arbitrary C++ classes are the data part
	Elms are the scaffolding which holds the data parts and cid.
	Elms can also be treated as data parts, and field access is similar.
	Elms and other objects are all handled by same object info
	Elms have a special flag in the obj info.
	Elms are accessed through eids
	Fields are accessed through eids and fids.
	+Elms contain access and ownership info similar to Unix
	+A multithreaded scheduler/job/clock system runs stuff through rmsgs.
	+Work is done on objects through _shells_ which supply access info
	+shells direct tty input to an interpreter for action.
	+Users have a home object with user access info, and root of user tree.
	+Logins: Could have daemon that detects logins and spawns shells


Got templates working for m_base derived classes.
Loaded in field info, but I don't have anything to do with them yet. Need now
to implement Message based Set etc.

+Field id implemention.
	Id from path ?
	Path from id
	Looking up pointer from id.
	Lookup steps:
	Eid -> elm_ptr
	fid -> class_elm_ptr -> Value -> classinfo ->
		AccessFunc(elm_ptr->Value()) -> field ptr
		Streamline: Table from fid to AccessFunc
			Accessfunc takes elm_ptr directly,
				does Value call internally if needed.
				This gets rid of issues with elm vs data fields
		Overload the AccessFunc to take indices
		fid does not have indices. These are separately handled.
		All fids that are data parts will ask the elm for its Value().
-Smoother handling of parent/child/msgs


Set up fids to automagically make a table of AccessFuncs.
Need to pinch the eid from the
cid::cid(const string& classname, m_base* v) function
in cid.cc

=============================================================================
22 Feb.
Some terribly distracted days. 
Q: Should the access func take an elm argument or a void* argument
- elm: Assume we always refer pointers through the element. Extra
	2 indirections for accessing fields. However it is used only when
	setting up messages.
- void: Assume we refer pointers through ptr to Value() of field. 

Let's go with option 1.

Lots of things opening up. I'm now setting up the generic messages on
the elm. These are:
destroy, set, call, call1, callout


Fading into the night.
Stuck at:
Verify and Execute format for Set: in elm.h and elm.cc
Also a problme with verify: How to ensure that the args are fields of
	the data elm.
	Stuff in elm.cc.

-I need to provide a type converter or assignment function for the fields.
	But there is no clear way to pass in a converter or other info
	to the Set function. 
	data is whatever is relevant about the parent elm etc, that can
	be passed in at elm creation. Usually just elm ptr.

=============================================================================
23 Feb
*Clean up and get it to compile
Work on the rmsgdest::Add stuff to incorporate the Verify etc. May need to add
	args to Verify so that it knows src elm and dest elm.
Figure out how to pass in constant args to Verify. Things like an fid
	on the target elm. Or, provide something special for the 
	rmsgdest::Add function. Or, Arglist needs to have qualifiers for args
	indicating whether they are const, static etc. Or, msgdest assumes
	args are const if they are not on the src.
Get the Set working
Get the Call working
Get the Destroy working.


Compilation works but there is something wrong with getting the cid from
the class name.

OK, figured it out. Minor but subtle bug with sequence of static initialization.

Working on Add stuff. rmsgdest::Add is the site of all the fun.

Need a way to set up child messages from the start: looks like the kids
fid has to be bootstrapped in. Not pleasant.

=============================================================================
24 Feb.
Need a top-level AddMsg function too. 

Syntax:
addmsg src dest
addmsg src1 src2 ... dest

- Dest is always unique (later deal with lists of dests as a separate case)
- We always need a msgsrc. For Rmsgs this is unique. For Lmsgs there should
	be a single generic msgsrc.
- Src is singular for rmsg, but we could put in constant args. Ugly. It would
	mix the syntax and require knowledge of msg args. It would also mean
	that a zero arg msgsrc could contact an n-arg msgdest.
- Alternative: All rmsgsrcs are zero arg. Have to select args when defining.
- Alternative: rmsgsrcs have default set of args, they can be overridden.

- For lmsgs, all args need to be specified and there is no special arg.
- Update arglist so in addition to a vector of ids, it also has info on argtype.

Summary: msgdest::Addmsg(arglist&, dest)

- Who calls an lmsgdest function ? 
	- In rare cases (e.g., scheduler, graphics objects) it is an event.
	- Parser issues once-off calls.
	- Source may issue once-off calls.
	- Mostly it is an rmsg. Something triggers the execution of an lmsg.
	- Set up lmsgdests like zero arg rmsgdests ?

- Are there differences in how lmsgdests and rmsgdests are called ?
	- The entire list is called for the lmsgdest. There is a single
	calling src is for the entire list.
	- The rmsgdest only calls the target function once. There may be
	multiple srcs that call the target function.
	- Actually it could go either way. A Process call with a timestamp
	arg may be used to call multiple entries on a msglist. Or a PLOT
	lmsg call with a parameter ptr may only call a single value.

- Can the arg types be mixed or unified ?
	- lmsg dests store pointers to args.
		- Args can be on different elms.
		- Args can be consts, via access funcs, whatever.
		- Each lmsg must store each arg.
	- rmsg dests are passed arguments. These are currently stored on
	the msgsrc.
		- Args must be owned by the msgsrc.
		- Args can be generated on the fly
		- Args can be consts ?
		- Since all dests of a given rmsglist get the same args, it
			uses less space than the unique args of the lmsgdests.

- Who calls the rmsgsrc function ? 
	- Same as lmsgdest. It is an executing function called either by an
		event or another msg, or as a once-off.
- Would all rmsgdests call an rmsgsrc ?
	- No.
- Required data for setting up a msg:
	msgsrc: This is the calling msg. May provide some args.
	args: Optional # of them. Can be const, evaluated, etc.
	msgdest: This is where the action happens. Ensures that total # of 
		args is OK.
- Handling arg in Addmsg: First arg must be msgsrc, then arglist, then dest.
- Number of combinations of src and local args:
	Tot args	# combos	Listing of Combos
	0		1		m0
	1		2		m0+arg, m1
	2		3		m0+2a, m1 + 1a, m2
	3		3		m0+3a, m1 + 2a, m3
	4		3		m0+4a, m1 + 3a, m4
	5		3		m0+5a, m1 + 4a, m5
	Note that we draw the line at 3 combos. Others are farfetched but
	could be implemented if really needed.

- Possible implementation:
	- lmsgs are just a special case of rmsgs.
	- msgsrc list has a set of args that are the same for all dests.
	- Args for lmsgs can be a combo of those sent by the msgsrc, and
		those looked up locally.
		- This sidesteps the problem of const args for rmsgs.
		- Different kinds of msgsrcs can contribute to the 
	- msgsrcs are NOT included in each msgdest, but they frequently
		are called from them.
	- The msgdest is templated as before with a Verify and
		ExecFunc<N>(data, arg1, arg2 ..)
	- The msgdest has msgentries with src and arg info, rather than just
		the srclist.
	
Summary:
See newmsgdest.h, newmsgsrc.h for preliminary implementation and ideas.
Speed implications:
	Rmsg-type calls will be as fast.
	Lmsg calls (anything with general args) take 2 more indirections.
		This may be offset because the call itself is coupled more
		tightly with the preceding msgsrc. Anyway, insignificant.
Space implications:
	Minimal
Generality and code simplification
	Perhaps too general. Pretty much any combination is possible
	Code is structurally simpler but lots of special cases.
	Need to include different message types into the classinfos so
		that we can specify which message type to use.
	Mappings, that is, rule-based messaging, probably works best by
		having an intermediate element getting converging inputs and
		sending diverging output.


Status: Working on newmsgsrc.h and newmsgdest.h
	Figuring out how to handle args passed by msgsrc. Where are they
	defined, how stored, how passed quickly.


=============================================================================
25 Feb. 
Lots of ideas. Now lets retrofit the old messaging scheme and get it going
again before going on to including the new messaging. Since this is a
pretty big change I'll copy the whole mess over to a version directory:
feb23_2002_version

Cleaning up and setting up API for the newmsg stuff. 

Starting to compile it. Running into problems again with bootstrapping:
the msg formation for parents e.g. parent::AddChild()
needs to be able to use the appropriate msgdest function but there is
no fid at this point.

Cleaning up AddChild. This has to be independent of fids and classids
as it happens before they are set up.

Current sequence:
elm::AddParent(id pa)
elm::pa.Elm->AddChild(pa, &parentlist)
parent::parentlist->Add(pa, &kids);
rmsgdest::kids->Add(this, srclist.size())
	msgsrc::destlist.push_back( entry(msgdest, size));
rmsgdest::srclist.push_back(pa)

That is absurd. New version:
elm::AddParent(id pa)
elm:: pa.Elm()->AddChild( parentlist.AddParent( pa ) );
	msgdest.cc:: parentlist.AddParent(pa)
			ret = new parententry(pa)
			msglist.push_back(ret)
			return ret;
parent virtual fn::AddChild(const msgentry m)
	kids.Add(m)
	msgsrc.cc:: msgsrc::Add(const msgentry m)
		destlist.push_back( m )

A little more linear.

Much compilation pain later, it compiles but barfs at line main.cc:30 .
It also gives the wrong parent for bargle. Still, amazing it came so
far after so many major changes.

Next:
* Get current basic stuff to work
	OK, now it has the correct parent for bargle, but it still dumps
	core on line 30.
	OK, fixed that too. I had not initiated the dest field in the msgentry.
	Now it handles the existing main.cc stuff.
* Get Set to work
* Get Call to work

=============================================================================
26 Feb
A minor problem with Arg of the msgentry: It is really a 2-d lookup,
since there can be more than one arg for each function, and there can be
a lot of general msg data sources for a single msgentry.

Another minor problem: The initialization of fields having a msgdest requires
the eid of the elm. This is not usually available unless the field is
itself an elm.

Lots of issues cropping up now that I am actually trying to execute
the messages. I got the Hello to work, sort of, but it doesn't have an
eid to look up.

There are various ways this could be fixed:
	- at elm creation time, it goes in and sticks in the eid into the
	child messages. 
	- When a message is set up between elms, it puts in the eid info
	- Force all fields which have msgdests to include the eid in
		their creation function. Since these fields explicitly
		include messaging constructs, they can go one step further.


OK, implemented the third option. Testclass::Hello now works. On now to
Call.

Issue: Adding further general args to a msgentry. Which msgentry to do ?
What API to use ?
If same src triggers multiple rounds with different general args, we might
use a long series of general args.
Example: A plot collecting many traces in response to a PROCESS action 
	Would we ever have more than one msgsrc calling a different msg list
	on the same msgdest ?
	Would it make more sense to have a separate entry and message each
	time a given src calls the msglist with different general args ?

OK, implemented the last situation.


Need to generate and read from paths.

There is a problem with the Verify within the Execute function, because
of checking for the Src. Should really take the src args and ignore the
src if it is Root.

Inching toward the Set.

Compiled it.
Set it up but it doesn't do anything. Yet.
=============================================================================
27 Feb.
Struggling with Set. Still doesn't work properly. Isn't calling the
m_<field> specific Set function.

OK, fixed all that, and now it works. This is great. Not only do we have
the Set and Call stuff working, but we also have it going in a totally generic
way compatiblem with messaging. In other words, I can now set up a message
to control any field.

A final test: Make a msgsrc on testclass and connect it up.
This causes problems. The msgsrc1 needs the pointer to the argument it is
going to pass to the system. 
OK, fixed by passing the pointer directly at creation.
Things now work wonderfully. I have tested various functions in the m0
msg, still to check out m1, but I expect it will be fine.

With that I think the first level basics are implemented in principle.

General cleanup items, no particular order:
	- Check m1 msg.
	- Put in StrSet
	- Implement Destroy() for children
	- Copy, move etc.
	- Figure out how to convert fields to a string using similar methods
	- Make it easier to make msgs, elms, call functions.
	* Get paths working both ways

Implementation items:
	- Scheduler
	- Shell

Next level major items:
	- Parser
	- Postmaster
	- Graphics

Functional implementation
	- kinetics classes
	- streaming cluster cutting

=============================================================================
2 March. 
A little time to amuse myself and simplify development by putting in the
id<-->path stuff.

id->path: Get elm, 				get fid
	Follow names of parents			Follow names of m_classes
	till root				till /classes
			Catenate.

path->id	Find start elm
	(., .., /)
	Find kids till none found -> eid
	Find cid
	Find classes kids till
	matched or none found. -> fid
	Look for kids of base classes if none found.


Ambiguity possible if there is a name overlap. We allow the elms to 
	override the builtins.
Ambiguity also possible if name overlap in derived class field name. Again,
	derived class overrides baseclass.

id->path works
path->id has bugs.
Got id to work. There is some fragility in base class definitions.
I should explicitly find the elm class rather than assume that the
base class of all fields is elm. It may instead be pdata or other things.

=============================================================================
3 March
Little stuff. Implemented doubles and ints. Now on to scheduling

Sched : infinite loop, calls jobs. Multithread the jobs so that they do not
	block.
jobs: Increment status each call. If it goes above priority then execute it.

Clock_job: derived from job. Maintains time, maxtime, clock list

clock: Maintains dt, nextt, list of elms to call.

Reached Clock_job, but there is a hitch. The clocks have to pass back the
information about their nextt.
=============================================================================
4 March.
Clock_job could be done in several ways:
1 Have separate child clock elms, pass back nextt through messages
	Klutzy. Slow. Sorting the sequence would be painful.
2 Have nested child clock objects in a vector, each with own messages
	Cool if I can do it. The infrastructure for arrays becomes the challenge
3 Have nested child clock objects in a vector, each points to the msgentry
	for a child elist elm which has the message list for attached
	processes.


=============================================================================
6 March 
Trying option 2.
Need to figure out routine when I'm less tired/distracted.

=============================================================================
7 March.
Algorithm
	- At 0 time, all clocks are ordered by increasing dt and nextt is dt.
	- Each time a clock is called, it increments nextt.
		- if x.nextt > y.nextt, swap x and y. Ripple down list
	- Call first item in list.

How it works:
Clock/nextt					Notes		Nops	currtime
a1	b2	c3	d4	e5		a		1	1
a2	b2	c3	d4	e5		a		1	2
a3	b2	c3	d4	e5		Shuffle a	1	-
b2	a3	c3	d4	e5		b		1	2
b4	a3	c3	d4	e5		shuffle b	2	-
a3	c3	b4	d4	e5		a		1	3
a4	c3	b4	d4	e5		shuffle a	1	-
c3	a4	b4	d4	e5		c		1	3
c6	a4	b4	d4	e5		shuffle c	4	-
a4	b4	d4	e5	c6		a		1	4
a5	b4	d4	e5	c6		shuffle a	2	-
b4	d4	a5	e5	c6		b		1	4
b6	d4	a5	e5	c6		shuffle b	3	-
d4	a5	e5	b6	c6		d		1	4
d8	a5	e5	b6	c6		shuffle d	4	-
a5	e5	b6	c6	d8		a		1	5
a6	e5	b6	c6	d8		shuffle a	1	-
e5	a6	b6	c6	d8		e		1	5
e10	a6	b6	c6	d8		shuffle e	4	-
a6	b6	c6	d8	e10		a		1	6
a7	b6	c6	d8	e10		shuffle a	2	-
b6	c6	a7	d8	e10		b		1	6
b8	c6	a7	d8	e10		shuffle b	2	-
c6	a7	b8	d8	e10		c		1	6
c9	a7	b8	d8	e10		shuffle c	3	-
a7	b8	d8	c9	e10		a		1	7
a8	b8	d8	c9	e10		a		1	8
a9	b8	d8	c9	e10		shuffle a	2	-
b8	d8	a9	c9	e10		b		1	8
b10	d8	a9	c9	e10		shuffle b	3	-
d8	a9	c9	b10	e10		d		1	8
d12	a9	c9	b10	e10		shuffle d	4	-
a9	c9	b10	e10	d12		a		1	9
a10	c9	b10	e10	d12		shuffle a	1	-
c9	a10	b10	e10	d12		c		1	9
c12	a10	b10	e10	d12		shuffle c	3	-
a10	b10	e10	c12	d12		a		1	10

OK, so this is fine. Would work very well if there were large ratios. Handles
irrational clock dts fine.

Implemented it in skeleton. Now need a chunk of time to flesh it out.
=============================================================================
8 March. 
Clock stuff sort of implemented, compiles, but not ready to use yet. 

Implemented as far as testing goes. works fine, but still some way to go to 
hook it up to the API for accessing fields etc.

OK, after that little digression, lets move on to real stuff. 
Implement a tty and a shell, and a hook for a parser.

scheduler calls tty.
When a CR happens it sends the latest line to the shell.
Shell calls parser.

Things shell can do:
	Call API for moose


	too tired.

=============================================================================
9 March.
Got in a nearly complete version of tty, need to fill in the Process.
I need reference stuff for the stl, especially strings, to do this.

Things are now getting well enough established that it should be possible
to write a preprocessor for defining m_classes. Only about 20% of
the code in a typical functional class (as opposed to the base code)
is actually code, the rest is boilerplate.

Working on shell. The functions here need to be split at least
between tty, shell and parser.
tty could be a special text window, or a system of buttons with dialogs,
	etc. Input/output is all it cares about.
	tty gets msgs from all over, whenever something needs to report
	something. 
	Can one have more than one tty on a shell? No.
	Can one have more than one shell with a tty? No.
	Should error and other messages go to the shell first, or to the tty
		directly ?
		Via shell.
	Should parser get commands straight from tty, or via shell?
		Via shell.
	Would we ever want to change ttys on a running shell ? Or vice versa ?
		Yes.
	Should tty or shell maintain command history ?
		shell.

parser takes text strings from tty and groks them. Occasionally it spits
	stuff out to the tty. Usually it tells the shell to do things.
	Parser has to handle many ttys/shells. Simplest if all commands
	come from shell.
Shell has to do things.
	Elm manipulation
		Create
		Destroy
		Move
		Copy
	Message manipulation
		Add
		Delete
		Call
	Shell stuff can be handled by calls to set etc, or built in
		ce
		pwe
		pushe
		pope
		showfield
		le
		
	If that is all, it is wonderful.
In addition, I will need a library of functions based on the 
	above basic calls, to do many other sorts of things
		start
		stop
		reset
		status
		get/set (these begin to mix in with the parser funcs)
	etc.


Generic implementation of Shell also done. Now I need to get Parser
defined and then fill in the blanks.

=============================================================================
10 March
Compiled in the keyboard stuff for the tty. Now to put in a skeleton for
Parser and begin slowly to fill it up.

Need to make a dummy msgsrc and use it for direct calls of messages, so
that the Verify can be used.

OK, got as far as calling parser with quit. Pretty impressive how
cleanly it all came together. Still have headaches with the
tty refusing to poll keyboard input and instead waiting till eof to
do anything.
I was not able to find any reference to multithreading in the C++ book.
I will need this especially if the tty blocks.
I also was not able to apply the in_avail() function to the instream
to try to bypass blocking.
Get to it later. Now we're set to start thinking about parsing.

=============================================================================
11 March.
Parsing needs to do the following:
Clean up whitespace and separate tokens

Define grammar
function definition:
	path(primary, primary...) { expr_list }
expr_list:
	expression ;
	expression ; expr_list
argument_list:
	()
	(expression)
	(expression, expression)
expression:
	term + expression
	term - expression
	term
term:
	primary / term
	primary * term
	primary

init_spec
	TYPE
	ETYPE TYPE
	QUALIFIER ETYPE TYPE

initialization:
	init_spec path
	init_spec path[expression]

path:
	NAME
	.
	..
	/
	NAME/path

primary:
	NUMBER
	NAME
	path = expression 
	-primary
	(expression)
	function argument_list



Specify tokens: enum of tokens

get_token: function to get the next token. 

Parser functions: one for each level of the grammar. Takes an arg
	to tell it if it has to get another token


Implemented vanilla version of Bjarne's parser, in test/tc.cc.
Now to elaborate on it.

Read from a file for starters. Trivial - just input redirection
functions
loops and control flow

=============================================================================
12 March.
Implemented 'quit' and builtin functions with 1 arg.
I should be able to generalize easily, and also take the functions
away from the hardcoded list.
All this in tp2.cc

To define a function or have a flow control operation, I need to store
command sequences, either pre-parsed or post-parsed. Post-parsing would
run faster but I then need to have the system able to read a series of
tokens rather than strings.

I also need to convert the system from a functional form to an object-oriented
form.

I also need to force every variable name to be declared.

=============================================================================
14 March.
Over last couple of days stared on object-oriented version in tp3.cc.
Implemented a tokenizer

Things to do:
- more complete oo
- parse without evaluation. Useful for handling functions and control flow
- Typed variables, perhaps something like ids
- Arglists and functions with multiple args.
=============================================================================
15 march
Working on tp4.cc
Adding in a dummy id to start to tie to moose.  Will slowly replace all
values and funcs with this.

=============================================================================
28 march
got it to compile with a dummy id. Next step is to use id to access values
and funcs.
=============================================================================
29 March
token_value currently has various operation-level concepts as well as other
things like NUMBER and FUNC. It would be nice to combine NUMBER, FUNC and
related things into the one concept of ID. 

For now, slowly inserting id into flow.

=============================================================================
30 March
I am concerned that I am just messing around with this without a true
understanding of the algorithm. Perhaps a stack-based structure would
be better for the more complex parser we need.

main
	-> tok.Get(): parses into operators, numbers and others
		If it is an operator, assigns Current to char value of operator
		if it is a number, assigns Current NUMBER
		If it is other, calls identify_token and assigns Current.
	-> expr(bool get = false): This is the call that + and -
		-> term(get): This call does * and /
			-> prim(get): This call does numbers, names,
				(), unary minus, funcs, and quit.
	Each call first sets double left = next nested call
	prim starts off getting a new token if the get flag is true.

a = sqrt (-b + ( 4 *  a + c) / d )

1. Goes down to prim. a is Current and it is a NAME. Look up a in 
	the assoc array. Check if the next token is ASSIGN. If so, 
	do assignment to expr(true).
2. Goes down to prim. Gets a new token there. sqrt is Current and is a FUNC.
	calls eval_func_bracket BEFORE calling func. Once it has finished
	the eval stuff it looks up func in assoc array and calls it and returns
	func evaluation.
3. Inside eval_func_bracket().
	Gets a new token, verifies it is a (. 
	calls e = expr(true).
	Many steps later, Gets a new token, verifies it is a ).
	returns e.
4. Inside expr(true) from 3. Drills down to prim.
	Gets a new token: it is unary MINUS. returns prim(true)
5. Inside prim(true) from 3, 4. Gets a new token: it is b and a NAME.
	Looks up b and gets next token. It is not an ASSIGN, so it just
	returns the value of b. Unary minus is applied.

6. Inside expr(true) from 4. Finds that current token is PLUS.
	left (which is -b) += term(true)

7. Inside term(true) from 6, 4. Goes down to prim(true)

8. Inside prim(true) from 7, 6, 4. Gets token, it is a (. 
	calls e = expr(true)
	Many steps later, gets a new token, verifies it is a )
	returns e to 7.

9. Inside expr(true) from 8. Etc.

.................................................................
Based on this I think I can use this structure for the new parser.
To define a function I need:
	Terminators for each statement.
	Separation between tokenizing and evaluating each line
	A pure tokenizing mode for function definitions (also for flow control)
	Scope rules

To define flow control I need:
	first three items above
	selection or looping operations on sections of the code.
	Boolean ops

To handle moose ops I need:
	functions for move, destroy, copy
	Message setup functions
	Class lookup functions (? may come from funcs within)

Other things to do
	+Use ids for field lookup and type definition
	Type-specific operations
	Create variables as local elms
	Put the operation for different classes as a part of the class,
	rather than use enums etc.
	Error handling. 
	Multi-arg funcs.

OK, coming along nicely. I have substituded ids for the number map.
Compiles and works. Now need to put in declaration of variables
and also extra declaration items like const.

=============================================================================
31 March 2002

Functions are now also done through ids. Need now to put in declarators.
* Set up dummy cids to be more like ids. They can now be searched etc.

Now starting on tp5.cc

Cool. Declarations now work for doubles. They even work in line:
	double m = log (double foo = a * pi + 6)

Design decision: how to handle ops for multiple classes. 
Option 1: Handle numbers and strings only.
	The rest only have assignment and comparison.
	- Straightforward but tedious implem
	- Miss out on useful ops for matrices etc
	
Option 2: Require each class to provide a common set of operators.
	- Limited set of ops
	- Most unused

Option 3: Require each class to provide whichever operators it wants,
	and these can be specialized ones.
	- Nice if it can be implemented cleanly
	- A good implem may actually be smaller and cleaner than the others
	- Would blow away C++. Think of matrix ops, graphics ops.
	- Prone to too much embellishment/featureitis.
	- Op class defined by class of preceding token.
		- What about unary ops like -foo and ++foo ?


I'll use option 3.
	Operator types:
	- Unary pre ops
	- Unary post ops
	- Binary ops. Must specify class range of second arg. 
	- wildcard operators ?
	- Assignment special case of binary ops. Must allow self-type assign
		and string assignment.
	- All ops defined in terms of regular functions
	- Op must additionally define op symbol.
	- Operator precedence is by numbering. Operators of same rank
		are executed left to right.
		- How do we handle conflicts of precedence in diff systems ?
	- General language constructs remain.
	
Can we sustain shell type as well as func type argument handling ?
Function syntax could either be func(a, b, c)
or func a b c
If we want a return value it has to be the first, or we put the thing in ().
I had better not do any coding right now. Too many ideas. Next step
will be to see if I can replace the nesting of operators with the above
	ranking arrangement.

=============================================================================
1 Apr 2002
Implementing. Things taking shape. It will be by far the simplest if I
just predefine a set of legal operators right off, and forbid their use in 
contexts too tricky for simple tokenizing. 
	- Tokenizer can bull through and work out operators
	- I can have a simple array lookup from tokens to operator funcs
	- Syntax of operators consistent across all types. I only need
		to define BODMAS level, is_prefix, nargs and symbol once.
	- Use a virtual base class and func/verify template... identical
		to our old friends for messaging.


=============================================================================
2 Apr.

Things are now getting interesting. The return values for message funcs
(ExecFuncs) used to be ints just indicating success or failure. For our
parser we should provide return values of either ints (for boolean ops)
strings (for string conversions) or the data type itself. What is worse,
many ops require a different return value than the data value, for example
+ and *.
A further implication is that one may want to return values through msgs.
More on that later.

- Always return void*. This can simply be NULL or not NULL for boolean ops.
- Data is allocated within ExecFunc and is volatile. A function using it must
	copy it over at once.
- Return type is specified in Rettype and is either bool, string, or data type.

The string return type is the joker in the pack. If it were only bool
or data type then 
	- don't need Rettype() func.

Advantage of string is that a few things like numbers would be useful to
convert straight off into strings for attaching to variable names etc.
Also simple to do print outs.
Basically I need an easy way of converting to strings.
If that is all then I should not put it at this deep level. It should be
a parser-level call to a stringconv function.

There is a lot of waste in having lots of msg/functions each of which 
internally stores the data and eid of the parent. That system is really
designed for situations where there is a single msg type and a whole lot
of individual messages. Here we have about 20 msg types each of which is
really just a function waiting to be called. Can't afford to be so
extravagant.

This is something I can work on separately. Let's carry on with the test
implementation for the parser. I will assume that the data argument is 
passed in to the function.


Levels of operation. Low is high priority.
0 : brackets
1 : a.field, a->field , a++, a--
2 : ++a, --a, ~a !a -a, +a, &a, *a, new 		Note unary ops.
3 : * / %
4 : + -
5 : <<  >> 
6 : < <= > >=
7 : ==   !=
8 : &
9 : ^ (xor)
10 : | (or)
11: &&
12: ||
13: = *= /= += -= &= 
14: expr, expr (comma)

...........................................................................

I should try to sort things out on the basis of this during the tokenizing
stage, so that each line is done simply by grinding through a series of
ops in order. Two arrays: one of ops and other of operands. Simply go
through arrays and skip operands as per # of args of function. I could
fill the arrays as stacks at the start. This means I need to put things like
type definitions in the stack too.

a = sqrt (-b + ( 4 *  a + c) / d )


Anyway, for now let's try to get it working with the msgdest stuff.
The next thing is to map the functions to the operator symbols.

Why am I doing this with templates anyway ? It would work just as well
and with less compiler juggling if I used function pointers and variables.
However, if these things are implemented as messages then I do not
want any overhead for each data field. I could use static consts in
many cases.  

Starting on map for tokens to opname.

============================================================================
4 Apr
When tokenizing I would want to check if a token exists, and whether it could
be prefix, postfix or binary. I could generally provide this info plus
token name and see if the token is known. Or I could scan every char or char
pair to see if they are tokens, and then figure out the other stuff.

I'll provide a first lookup for symbols at the tokenizing stage. This lookup
will store the contexts in which the symbols can be used and provide
enums for the specific cases to be used in the matrices later.

Lets not get into this. All required info is already there in the msgdests.
I will need to do a multimap.
Ugh. Multimap doesn't work well in this stl. All sorts of messy compiler
errors that I couldn't figure out. Used vectors instead and it
worked first time.

a = func (
	-b + 
		(4 * a + c)
		/ d
	)

func eval
- Find first token
	NUMBER, STRING: create temp id of correct type. left = temp
	NAME: left = id::Id(name)
	PREOP: create temp id(PREOP( eval()) ); left = temp
	LP : temp id(eval()), check for RP; left = temp
	FUNC: id temp(FUNC(eval(), eval, ...)) (look for RP); left = temp
	DECLARATOR: Look for NAME. left = new elm;


- Find next token
	BINOP:	if (levelarg > BINOPlevel) // arg is lower priority
			return BINOP(left, eval())
		else
			pop back on BINOP
			return left
	POSTOP: return POSTOP(left)
	RP, SEMICOLON, COMMA, ARGSEPARATOR, BRACES(?): return left.

OK, this is taking shape. To me it looks lot more structured and easier
to understand than Bjarne's parser, but that may just be my way of thinking
about these things.
Needed:
+	Func from string to execute arglist. This has to return an id,
		so the ExecFunc stuff has to know how to do this.
+	id cid::Create(name)
	Tokenizer putting things into the above categories
	A place to put temporary variables (ids) which can later be
		wiped. Some of these propagate up so it is tricky to make
		them all local in scope, though that would be the cleanest.
	Conversion of all numbers and strings to ids.
	See if I should be returning void* rather than an id, and if left
	should be void* or id.
		- Need the class. So id makes sense
May be able to eliminate this Unary/Binary func business and go
back to Execute with an arglist if I stick with ids. 
Problem is that Execute assumes that the Data is local.
Solution: The return id is a volatile. If the contents are going to be
propagated it has to be copied into a new one. Bad because in multithreading
I could lose data at the transfer point. Simply allocate a new id each
time I return the value. Ugh.
Pass in an id for the return value. Hm. Problem is then I need to create
etc things in the main body and handle all different cases.
Best is allocate and return a new id.

I have a problem here because the concept of a method (function operating
in a class) does not imply any storage, whereas the messages assume the
need to maintain input and output and do use storage.
I also have the problem of accessing a message by name in the cinfo.
This is handled in moose by creating an elm with the fid name for the message.
The m_msgdest could be a repository for some of these funcs.
Then the generic msgdestlist on the elm could simply be a wrapper for calling
the funcs and handle data locally. Quite straightforward.

============================================================================
11 Apr
The sheer amount of junk-work is crippling this project. Current issue:
return values from operations. The returns are usually either
the first argument type, or a boolean. However, one could imagine a
vector outer product giving a matrix etc. 
Would ideally like a form of return that creates a local variable automatically
on the stack, so garbage collection isn't an issue, but also provides type
info.

Options:
	- Create and allocate id and storage for every return value
		Slow, tedious, uniform.
		Headache with subsequent garbage collection
		Perhaps functions that use the ids can kill them, or
		even reuse the space.
		Not in general. Suppose
		c = a + b.
		We don't want to alter a. It might be used later.
	- Provide a static return field and plug it into the returned id.
		Won't work for complicated expressions, nor multithreading.
	- Return a void* to a static and manipulate a generic id for the return.
		See above for static
	- Use globals to handle the return value
		See above
	- Limit to returning numbers and strings
		Limiting.
	- Return an allocated void*
		Need type info, so should use an id.
		But in principle type info is available from syntax and types
		of original args to function.
		Could use a separate cid for return value. It will 
		always be in context of msgdest so cid could be available.
	- Require calling func to provide storage for return
	- Use a derived class of id that ignores most stuff but has 
		lookups for class type and directly holds the value,
		and knows how to kill it.
		- Won't work. The original id does not have virtual funcs.
	- Use a special class (not id) with suitable attributes.
		
If we set up msgdests to handle this we can use the execfunc and put in
a templated wrapper. That is precisely the idea.

Can we get by with fewer template args ? The IsPrefix and Level could
in theory be resolved directly from the symbol table. We definitly do not
want the same symbol placed at different levels of operator precedence
depending on arg type. The IsPrefix part should be identified by the 
tokenizer and the appropriate msgdest selected that way.

So I could put in the cid as another template arg for classifying the
return value.

But if the execfunc is returning a value, we definitely do not want to
get bogged down with allocating storage for the retval.

I could treat unary operators as 2-value operators. One for the 
destination of the answer of the func.
Binary operators would therefore be 3-value ops.

The first arg, like in most msgs, would be the data field meant to hold the
answer. This means that I need to have the answer alloced in advance.

This makes lots of sense from the viewpoint of fast msging, one of the
key requirements for the design. So fine.  Now how do we get it to work
for script parsing ?

Basically lookup the possible funcs corresponding to that symbol and the
types of the one or two args.
Lookup can be expedited knowing the type of the first arg.
Then ask it for the cid and use the cid to create the output arg. 




Split the msgdest into two parts, either of which can be a field:
	The function part. This does not require storage
	The list part. This stores info about the parent field, src, etc,
		and has one or more function parts.


Probably this split will find use only for generic_msgdests. See
dummy_id.h:220 ish to see the site of the action.

============================================================================
12 Apr
Make an array for each class with the ops for that class:
	arg1type->msgfunc[arg2type]
	In cases where it is a unary op, arg2 can identify prefix or postfix.

OK, I don't have to do the split above. All I need is a way to create
the appropriate field ptr from a lookup of the msgdest.

- I lookup the msgdest in some static manner, for example, a tree sitting
of msgdestparent or classparent.
- The msgdest itself can hold a field for the data entry, but for the 
purposes of func evaluation it does not have to have anything in this field
- The generic_msgdest has an array of msgdest ptrs. This array is extended
every time a new class of msgdest is invoked. So we can have any field
connected up to any other by any of the ops possible in SLI, but the
storage cost is only to the elm parent.

Do I need a temporary return type which holds the cid and the result pointer ?
============================================================================
13 Apr

y = x++: int Exec0(void* data). The return value is x before the operation.
y = x += b: int Exec1(void* data, const void* arg. The return value is x after
	the operation.

y = x + z: int Exec2(void* data, const void* arg1, const void* arg2). The
	return value is neither x nor z, but y. Here there is a LHS already.

y = (x + z) * (p + q) : Here there is no way of getting out of providing 
	a temporary variable (or more) for the running answer.
	Exec2(void* data, const void* arg1, const void* arg2)

So in most cases the op returns the id of the first arg.
In some cases the op needs to create a temporary id.
In all cases I should use the first arg as the handle for the op.
From viewpoint of calling a msg: Always the data of the target of the msg
is going to be affected. When there is something like the fourth example,
we do not have a clear target type, and it has to be synthesized from the
two arg types and the op.

Op-based lookup:
	- Linear. There are few ops and I can simply allocate a big table.
	- Can separate unary, binary, pre and postfix ops by tokenizer.
	- Use a Map with index of the first arg. 
	- Use Cid, Verify and Eval of the msgdest to do the rest. 
	- For each op and first arg, there is only one msgdest. It may
		have to accomodate multiple classes of second arg.
	
	static const int opindex = OpInit(msgdest*, opsymbol);
	static const cid retcid = OpInit(msgdest*, opsymbol);
		Problems is that the cid is not necessarily inited at this 
		time. For the same reason I will not be able to provide a
		cid as a template argument.
		- The return cid is usually the same cid as the class where
			the arguments are being defined. Can manage.
		- Could use type::Cid for filling in cid.

	Actually, all msgdests already have a static const field: the fid.
	Currently it is inited simply by passing in the appropriate fid
	generated with the other fids, as a static fid at the top of the
	.cc file.
	I could build on this.
	But I still need to init a cid for the class.
	Has to be a static const otherwise it will waste space.
	Oh, well.
	
	- Provide a static lookup (map ?) from the opsymbol to the op index.
	- Have an array (vector ?) of the actual msgdests for each op,
		looked up by cid of the first arg. Relatively few classes
		will need to have entries here. Linear lookup OK, especially
		as we will do pre-tokenizing.
	- Problem with second lookup: the cid of the first arg is not a 
		regular part of a msgdest. No matter. The lookup is done
		by scanning through using Verify(), and the cid of the
		first and any other args will be available.

	Or I could have them as independent cinfos, in which case things
		become even messier.
		Issue is whether each func of msgdest becomes a distinct
		class.
		const cinfo m_msgdest::msgdestclassinfo(
		msgdest, elmo)


OK, implemented a set of 3 Evaluate functions.
Now considering the array. The first arg cid and the op look up the function.
	Use Verify to ensure that the second arg (if any) is OK.
Options:
	- Array of allocated msgdests each of the appropriate type. This
	would have to be done as a part of the msgdest core class with a
	static const field requiring initialization. This would guarantee
	that all msgdests would be recorded somewhere. The static const could
	be the cid, thus simplifying the msgdest too. Problem with making sure
	that the cid has been initialized before the msgdest.
	- Set up the Evaluate functions as static. Make array of them. 
	Also make array of associated cids for return type.
	- Array of structs for evaluation
		- cids of ret, arg1 and arg2
		- ExecFunc or EvalFunc
		- Static 
	

........................................................................

Much messing around later, settled on a straightforward enough API:

A 2-d array of msgdests is used to store/look up info about the
	arguments for each operation
Set up the msgdest table using a static cid in each msgdest. The
	cid msgdest::OpInit() function is called for this.
msgdest::FindOp looks up msgdest based on op and arglist.



============================================================================
14 Apr.
Compiled. Now to start to put the pieces together.

consider expression like:

a = sqrt (-b + ( 4 *  a + c) / d )

Takes an operator out of the opstack
If it is unary, operates on the varstack and puts the result back
If it is binary, takes 2 variables off the varstack and puts the result back
If it is a func, takes appropriate number of variables off the varstack
	and puts the result back.
If it is a (, pushes opstack down one level till closing ). Puts result back.
	Essentially a stack ordering device.

Operator precedence determines whether op will be pushed down stack or stay
on top.

Step	line			varstack	opstack
0	a = sqrt (-b +		.		.
	( 4 *  a + c) / d )
1	sqrt (-b +		a		=(binary)
	( 4 *  a + c) / d )

2	-b + ( 4 *  a + c) / d)   a		sqrt(unary), =

3	+ (4 * a + c) / d)	b, a		-(un), sqrt(un), =

						Note precedence here
4	(4 * a + c) / d)	b, a		-(un), +, sqrt(un), =

						Note: bracket forces swap.
						and reentrance into parser
						The ( varstack is a placeholder
5	4 * a + c) / d)		(, b, a		swap,  -(un), +, sqrt(u), =

6	a + c) / d)		4, (, b, a	*, swap, -(un), +, sqrt(u), =

						Operator precedence pushes +
						down stack along with its arg.
7	c) / d)			a, 4, (, b, a	*, +, swap, -(un),+,sqrt(u),=

8	/d)			a,4,c,(,b,a	*,+, swap, -(un),+,sqrt(u), =

9	)			a,4,c,d,b,a	*,+, /, swap, -(un),+,sqrt(u),=


Evaluation: a = sqrt (-b + ( 4 *  a + c) / d )

Step	varstack		opstack
0	4, a, c, d, b, a	*, +, /, swap, -(unary), +, sqrt(unary), =
1	x1, c, d, b, a		+, /, swap, -(unary), +, sqrt(unary), =
2	x2, d, b, a		/, swap, -(unary), +, sqrt(unary), =
3	x3, b, a		swap, -(unary), +, sqrt(unary), =
4	b, x3, a		-(unary), +, sqrt(unary), =
5	x4, x3, a		+, sqrt(unary), =
6	x5, a			sqrt(unary), =
7	x6, a			=
8	x7			

x1 = 4 * a
x2 = x1 + c
x3 = x2 / d
x4 = -b
x5 = x3 + x4
x6 = sqrt(x5)
x7 = x6
------------------------------------------------------------------------------
Above I have tried to pre-sort the stack for evaluation. If instead we use
an evaluation stack, it would look like this:

Step	line				evalstack	opstack
0	a = sqrt(-b + (4 *  a + c) / d )
1	sqrt(-b + (4 * a + c) / d)	a		=
2	-b + (4 * a + c) / d)		a		sqrt(, =
3	+ (4 * a + c) / d)		-b, a		sqrt(, =
4	(4 * a + c) / d)		-b, a		+, sqrt(, =
5	4 * a + c) / d)			-b, a		(, +, sqrt(, =
6	a + c)/d)			4, -b, a	*, (, +, sqrt(, =
7	+c) / d)			4a, -b, a	(, +, sqrt(, =
8	) / d)				c, 4a, -b, a	+, (, +, sqrt(, =
9	/d)				4a+c, -b, a	+, sqrt(, =
10	)				(4a+c)/d, -b, a	+, sqrt(, =
11	)				-b+(4a+c)/d, a	sqrt(, =
12					sqrt(), a	=
13					a=sqrt()

Another example:
Step	Line				evalstack	opstack
0	a = c / ((d + e - c) - f) + a	.		.
1	c / ((d + e - c) - f) + a	a		=
2	((d + e - c) - f) + a		c, a		/, =
3	d + e - c) -f) + a		c, a		(,(,/,=
4	e - c ) - f) + a		d, c, a		+,(,(,/,=
				Check if next symbol is greater.
5	- c ) -f ) + a			d + e, c, a	(, (, /, =
5.1	c) -f ) + a			d+e, c, a	- ,( , (, /, =
5.2	)-f)+a				c, d+e, c, a	- ,( , (, /, =
6	)-f)+a				d+e-c, c, a	(, (, /, =
7	-f) + a				d+e-c, c, a	(, /, =
8	) + a				x -f, c, a	(, /, =
9	+a				x-f, c, a	/, =
				Here the division has a higher priority than +
10	+a				c/y, a		=
11					c/y+a, a	=
12					a=c/y+a

So the tokenizer needs to separate the line into a series of ids, this would
work especially if the operators were also ids.
Otherwise it is a series of ids and operators.
Numbers and strings are pre-transformed into ids.

Another example:
Step	Line				evalstack	opstack
0	a = b + c / (d - e - func(g,h))	.		.
1	b + c / (d - e - func(g, h))	a		=
2	c / (d - e - func(g, h))	b, a		+, =
3	(d - e - func(g, h))		c, b, a		/, +, =
4	d - e - func(g, h))		c, b, a		(, /, +, =
5	e - func(g, h))			d, c, b, a	-, (, /, +, =
6	func(g, h))			e, d, c, b, a	-, -, (, /, +, =
							Here the opstack
							permits evaluation.
7	func(g, h))			d-e, c, b, a	-, (, /, +, =
8	g, h))				d-e, c, b, a	func(, -, (, /, +, =
9	h))				g,d-e,c,b,a	func(, -, (, /, +, =
10	)				h,g,d-e,c,b,a	func(, -, (, /, +, =
							Here the opstack
							permits func eval.
11	)			func(g,h),d-e,c,b,a	-, (, /, +, =
							Here the bracket closes
							and permits eval
12					defgh,c, b, a	/, +, =
							Now the 'new' arg is
							lowest priority.
13					c/defgh, b, a	+, =
14					b+c/defgh, a	=
15					a=b+c/defgh

Another example:
Step	Line				evalstack	opstack
0	a = b + c * d - e / f++ + -g	.		.
1	b + c * d - e / f++ + -g	a		=
2	c * d - e / f++ + -g		b, a		+, =
3	d - e / f++ + -g		c, b, a		*, +, =
4	e / f++ + -g			d, c, b, a	-, *, +, =
					Check priority. * is > - so we exec *
5	e / f++ + -g			d*c, b, a	-, +, =
					Check priority. + == - so we exec +
6	e / f++ + -g			b+c*d, a	-, =
7	f++ + -g			e, b+c*d, a	/, -, =
					Here ++ has a higher priority than /
7.1	+ -g				f, e, b+c*d, a	++, /, -, =
					Now ++ has a higher priority than +.	
7.2	-g				f, e, b+c*d,a	+, ++, /, -, =
					We exec ++, and it puts in its old value
7.3	-g				F, e, b+c*d,a	+, /, -, =
					Again, / > + so we do it.
8	-g				e/F, b+c*d,a	+, -, =
					- == + so we do it.
9	-g				b+c*d-e/F,a	+, =
					We're expecting a value, so we can
					identify this as a unary op.
10					g, bcdef, a	end, unary-, +, =
					The end op is the lowest priority of all
11					-g, bcdef, a	end, +, =
12					bcdef+-g, a	end, =
13					a=bcdef+-g	Hooray.


- As you add an op to the stack, check precedence.
	If op already there has >= priority, execute the op already there.
	In both cases put new op on stack

- Unary ops are identified either by unique symbols, or because they are 
	there in front of a name where a name is expected.

- ( has a low numerical priority. It is inserted specially to avoid setting
	off an evaluation. ) is not evaluated in the regular way,
	but as a special case that forces evaluation of everything till the
	matching brace.
- func( acts much like the (, and does not execute till the ). Func can
	do things to the evalstack
- comma, the argument separator, has lowest priority. This forces evaluation
	of everything between the commas. Commas do not affect stack.
- semicolon; is the statement separator, but so is newline. 


Well, it is pretty much together execpt the brackets. I have written a 
neat little Eval() routine using the stacks. The Evaluate operation
should use the stacks rather than arglists, and everything will be
beautiful.

============================================================================
Another example:
Step	Line				evalstack	opstack
0	a = (b + c) * (d * (e + f) / g)	.		.
1	(b + c) * (d * (e + f) / g)	a		=
					Though ( has a low priority, it doesn't
					execute even when it encounters an =.
					The ( occurs within EvalName.
2	b + c) * (d * (e + f) / g)	a		( =
3	c) * (d * (e + f) / g)		b, a		+ ( =
					The ) is met by EvalOp. It clears
					through the opstack till the opening (.
4	* (d * (e + f) / g)		c b, a		) + ( =
					Evaluating the +
5	* (d * (e + f) / g)		b+c, a		) ( =
					Eliminating the braces
6	* (d * (e + f) / g)		b+c, a		=
					Wrapping up by putting the next op in
					place on the stack.
7	(d * (e + f) / g)		b+c, a		* =
8	d * (e + f) / g)		b+c, a		( * =
					* has higher priority than (, so no exec
9	(e + f) / g)			d, b+c, a	* ( * =
					The brace does not respond to priority
9	e + f) / g)			d, b+c, a	( * ( * =
					+ has higher priority than (, so no exec
10	f) / g)				e, d, b+c, a	+ ( * ( * =
11	/ g)				f,e,d,b+c,a	) + ( * ( * =
					Eval the +
12	/g)				e+f,d,b+c,a	)( * ( * =
					Eliminate braces
13	/g)				e+f,d, b+c, a	* ( * =
					Put next op on stack to wrap up braces
14	g)				e+f, d, b+c, a	/ * ( * =
					Eval the * because / is same pri.
15	g)				d * EF, b+c, a	/ ( * =
16					g, d*EF, b+c, a	) / ( * =
17					d*EF/g, b+c, a	)( * =
18					d*EF/g, b+c, a	end * =
19					BC*d*EF/g, a	end =
20					a=BC*d*EF/g	end


============================================================================
2 May 2002
Slowly cleaning up and trying to compile.
Converted functions to stack ops.
Compiled. It even quits. About enough.
============================================================================
11 May 2002
Trying to pick up the threads.
- I want to print out the current state of the stack for debugging.
	Problem is that the msgdests don't store their own symbols at
	present.

- Need then to figure out parsing logic and flow control

Currently stuck because it takes in typed text and I think it is stuck in
Eval() but not sure where.
============================================================================
12 May 2002
There should be a good list of functions in because there have been a lot
of entries from doubles. Let's see if these are registered.
Yes, they are found. The problem is that the optstack now needs to be filled.
The function FindOp seems to rely on knowledge of the arglist. I should
look into this.

Looks like I need to fill in a stack of func symbols rather than parsed
function pointers/msgdests. The priority for symbols is global so that
part of the evaluation can be done without looking up the funcs. The
actual funcs need the arguments (from the stack) to look up, so they can
be done either once the next arg has been parsed or when the entire stack
has been worked out.

Put in a printf to indicate what functions would have been evaluated.
Things are a mess. Perhaps I should not be evaluating intermediate results
on the fly but only after the op and eval stacks are filled.

Step	Line				evalstack	opstack
0	a = (b + c) * (d * (e + f) / g)	.		.

Order of doing things:
	b + c
	e + f
	d * ef
	def/g
	bc * defg
	a = bcdefg

So the advantage of doing things on the fly is that I don't have to do stack
ops to get at bc after evaluating it.

All ops except unary ops operate on top 2 entries in evalstack and put
result on top.

evalstack	opstack
b		+
c		pushup
e		+
f		*
d		/
g		pushdown
a		*
		=
---------------------------------------------------------
a = b + c * d - e / f++ + -g

evalstack	opstack
c		*
d		+
b		pushup
f		post++
e		swap
g		/
a		pushdown
		-
		pushup
		unary-
		pushdown
		+
		=

The merit of this scheme is that it can be preloaded as a sequence of ops.
But it is quite complicated and needs lots of stack ops.

Going back to standard on-the-fly scheme. It is less efficient but at this
point it is more important to get a reasonably functional parser.

Rewrote the Eval() function. It still has a problem in that it won't
evaluate the last op.

Hacking in a ';' symbol to handle the last op problem. The ; symbol is
done through the OpInits in dbl.cc.

Compiled etc, still lots of problems with evaluating the last arg and
brackets, but getting there. Should get it done in another session.

============================================================================
13 May
It is parsing regular stuff properly, but brackets and unary ops 
are still problematic.
Implemented an opinfo that holds list of ops, their levels and their nargs.
This is a map indexdc by op name.
Unary prefix ops work now.

Some further fixes
Looks line unary postfix ops also work now

Brackets are messed up still
The closing bracket needs to be annhilated by the opening bracket to prevent it
from going on and killing everything to the left.

Further fixes.
Looks like brackets also work now. Need to do lots more stress tests and
cleanup.

============================================================================
14 May.
Several tests later, it still looks good.
Kept old version, cleaned up version is tp7.cc

Goals of this version:
*Handle type definitions (and also multiple lines and quit statement)
*Handle functions with arbitrary args.
Handle multiple arg types and interconversions
Handle control flow.

If I can get all these to work it could well be the final test version
prior to merging back into the moose tree.
After that the three big steps are parallelization, graphics, and a library of
	classes. Additional minor steps are scheduling with multithreading,
	security, and audio.

============================================================================
16 May
Put in the comma syntax for multiple args.
In order to handle the functions properly I need to be able to access the
msgdest info for the function including the number of args it expects.
I have sortof implemented a kludge which goes outside the stack scheme and
instead uses recursion, and not very well. Now commented it out on line 227
of tp7.cc

============================================================================
18 May
func syntax appears to be working but I don't have a clean way of assigning
functions and the correct number of args for them to use up. Implemented
a test case for now with 3 args for everything. Handles nested evaluation.
There is a remaining problem with function handling: if we use function
names to identify them, then it will be difficult to locate versions that
take different argument types. However, we would like to have a panel of such
functions and if possible select the one that matches the arguments. The
same issue applies to operators with different types. For the operators it
is manageable because we have a predetermined set, and can simply build
a list of the types. For functions the names are not predetermined.
Also, the implementation requires instantiation of a msgdest for the function.
Where would it live ?
Actually this is a generic issue for all generic operations that we want
to create on the parent elm without creating an explicit msgdest on each
data part of the elm. So clearly the msgdest must be created and live on
the msgclass.

Now on to multiple arg types.
Wrote an intgr.cc
Should really do a str.cc. That will involve some real and interesting
cases of conversion.

General rules:
String catenation uses special operator like C++
	In C++, the operations + and += are permitted between strings.
Otherwise the system tries to promote the string to a double and use numerical
arithmetic operations on the it.


============================================================================
19 May
Put in registration of functions and different number of args for functions.

============================================================================
20 May
Goals of this version:
*Handle type definitions (and also multiple lines and quit statement)
*Handle functions with arbitrary args.
Handle multiple arg types and interconversions
Handle control flow.

So, now on to multiple arg types. In EvalOp, we have all the args available
so could do a check on the arg types. The ops will typically have a fair
number of entries based on arg types for some ops like == and =, but a few for
others like ++. Should look up way of handling this sparse mapping.
A given function will typically have rather few argument options, so again
that has to be a sparse mapping.

Now using tp8.
Trying to put the function/op lookup using FindOp into the EvalOp so that
the operations actually get done.

Around line 200 in tp8.cc.
Need a way of specifying the return type, or of making an elm of the return
type so that I can handle stack ops. Also need to coordinate this with the
generic msg operations.

============================================================================
21 May
Options for return type:
1 Return type is the type of the class on which the msgdest is sitting. In
 msg use, the function would assign one or more fields within its parent.
 This doesn't work when the msg is just setting one of the fields after a 
 complex calculation. For example, in a compartment we want to set the Vm as
 a double after a step, but it is not that the calculation is something that
 is associated with all doubles. Nor does one want to create a compartment
 to return the Vm.
2 Return type is associated only with ops. 
	This would invalidate the construction
	a = func(b, c).
 How would we do sin and log ? sin(ret, angle) ?
 Note that we already invalidate this construction when defining messages, 
 since we do not permit a return value in a message.
3 Return type is assumed to be first arg, and is assumed to be the type of the
 class on which the function acts. 
 This is pretty much what is done at present.
 Restrictive. One may want our Vm = func(compt, Ra, Im) calculation to be
 available to return a double even though the parent class is a compartment.
 I think we can live with this restriction. If one is doing an operation on
 a compartment, it is not surprising that the return value is a compartment.
4 msgdests that want to be functions returning values have to define this
 type separately.
 This is messy because the native class (compartment) may differ from the
 optimum return class (double for Vm). A different func scheme would
 be needed in the two cases. Or, we could have a generic func where 
 the return value could simply be ignored in the return-value case. But this
 would entail passing in a class anyway for functional form:
 Vm = func(compartment, Ra, Im)

If we assume option 3, then there is the issue of passing by value or by
reference. In other words, how do we decide that the return value needs to
be newly allocated and when it is just being passed in ?
1 Return values are always defined ahead. For example, to do
	a = b + c
 we have to have already defined a, and further, a will be on the stack.
 So we can always return by reference.
2 Sometimes the func may take the same variable as an argument. That could
 lead to overwriting problems unless the function guarantees reallocation in
 such cases. 
 	string a
	a = a + a
 Note that the ExecFunc definition assumes that all args except the first
 are const void *. Only the first is void* and permitted to be altered.
3 Actually option 1 above does not work. Consider
	a = (b + c) / (d + e)
 We need to create variables to represent b+c as well as d+e.
 Even in the simple case
 	a = b + c
 we would have to somehow merge the operation = in with the + operation in
 order to take advantage of the fact that a is predefined. So we need to
 allocate the return value as an independent id.

Summary:
- The return type is the first arg, which is the 'data' of the msgdest, and
 is the parent elm of the msgdest.
- The msgdest knows the cid of the return value
- A new id of the appropriate class is allocated and assigned 
  when executing funcs and ops in scripts.
- Unary ops such as , and ) do not need to create a new id, as they act
	on the original.

Implemented in tp8.cc and sundry changes elsewhere. Starting to look really
neat. Now to compile etc.
Compiled.

Parts work. Need better debugging to figure out what it is doing.

Much cleaning out later, it works pretty well for brackets and functions.
Now to get back to different types. I think the framework is mostly in.

Type specification works, assignment works, but inter-type operations only
partly work. The doubles allow mistaken assignment to strings.

OK, fixed. Now do figure out how to do mixed type args.
OK, done. Straightforward matter, but tedious.

Goals of this version:
*Handle type definitions (and also multiple lines and quit statement)
*Handle functions with arbitrary args.
*Handle multiple arg types and interconversions
Handle control flow.

============================================================================
22 May 2002
- To do control flow we need to be able to put the thing into states.
- The unit of control flow has to be expressions, and at present
	the carriage return is the expression delimiter rather than the ;.
	Need to go to ; if we are aiming for a C-like syntax.
- States can be nested/stacked. Better stick with stacks for now.
- if - else: tells the system when it can start evaluating. The condition
	line needs to be separated out and evaluated once.
- while: Closing brace needs to go back to top. Condition line needs to
	be evaluated each time.
- do-while: Similar.
- for: Need to do some fancy parsing for the opening line. First statement
	is simple, second is the condition, third has to be done after the
	closing of the loop and before the condition.
- foreach: Need to decide if space or comma is a separator. Other than that,
	it involves a new construct of an array of ids. This may even be
	a regular language type. Scanning through it is not too bad and the
	termination condition is straightforward.
- break: stack operations to pop out of current loop. Appropriate for 
	while and for loops.
- functions: Assume I'm going for C-style function declarations
	(no initial 'function' keyword.) That will need the identify_token
	function to figure this out in context of start of expression. Either
	that or I catch this case early and go right in for separate parsing.
	- Argument declarations will then have to be converted. On the function
	elm I will create explicit elements and their ids in an arglist.
	To maintain compatibility with C format, all args will be copied
	into this arglist. Some of the args will be idrefs, that is, 
	elms whose contents are ids. This is the equivalent of pointers.
	Perhaps for ease the calling line can pass an id in to an idref, and
	it will be treated as call by reference.
	- Body of the function will have to be stored as a string on the
	function elm. Evaluation is simply a matter of calling the parser
	for the function.
	- The function elm is called in the same way as inbuilt functions.
	It provides a msgdest equivalent with all the appropriate hooks for
	Narg(), Cid() for return value, Verify(), and Evaluate().
	- The return call is simple enough.


Lots of fun trying to convert quit into a function. There is a problem with
zero arg functions. Much messing around, now fixed. I am not too
happy with the solution but it works. Created another test zero arg function
this one returning a number, and it works too.

Current status:
Need to get semicolons to work as expression terminators.  ? to start line
if expecting further input.

at tp9.cc:189 the EOL is used to give a semicolon.
Instead I should find a way of putting the remaining part of the string
in storage, emitting a ? if this string length > 0, and prepending it to
the next string read in.

============================================================================
23 May 2002
Had to open up the EvalName function (which originally returned ids) so that
I could pass back information about the state of the evaluation. This also
makes the logic cleaner (I think) but the thing yet has to compile.

Still struggling with semicolon and expression termination.
Too tired to deal with it.

============================================================================
24 May 2002
Lots of holes in the above implementation.
Need to rewrite the entire parsing loop as a state-based system. That will
allow it to pass in the latest token, do something, and return. There should
be no attempts to get a new token within the evaluation.

OK, rewrite done. Much cleaner. Handles line breaks well.
Two minor problems remain:
	* There is a Get() in identify_token.
	* Zero arg funcs don't work.

Great. Now on to control flow.

All the loops and functions need to store the script, and cannot be
evaluated till this is done. Make a new class, and set it up with id etc.

Copied existing stuff over to tp9dir. Started out with tp10

Current issue is: how to take an expression bounded by brackets for the
purpose of doing a conditional ?
Could use function evaluation stuff.
Trick is to put the test function on the opstack.

Would this insertion of functions work as a viable approach for all control
flow ?  Depending on conditions, the control function could spit out
stuff to sit on the stacks.

This would also amount to pre-parsing functions and perhaps files too.
Alternative is to keep expression evaluation separate from control-flow
evaluation. Use a separate stack for control flow.

The control flow routine should sit above the evaluation routine, and
pass it statements to run.

I need to do some design here. 

- Look for control op: if, then, {}, while, do, for, foreach, return
	May need some help to identify a function declaration
- Check that it has occurred when EVAL_COMPLETE
- Handle control_stack based on existing top and new op.
- If I put in an automatic check on the EvalControlOp function every time
	there is an EVAL_COMPLETE, I would not have so much junk to handle
	in the code later, that either passes or does not pass stuff to
	Eval().
- I can put in a fake semicolon to force evaluation of the braces for the
	if, for, while statements and get an EVAL_COMPLETE. Or I can check
	for an empty opstack.

- When not a control op, then call Eval() depending on control_stack.back().
	This will either execute or not execute the operation.


Can we stack up the tokenized program ? 
	- Easier to work out start and stop of loops etc
	- Much faster
	- How do you handle nested control structures ?
	- Would token evaluation change ?
	- Should there be a pass through the tokenizing without evaluation ?
		Can't do. Things might need creation etc.

Can we bypass the tokenizing and store the control code directly ?
Can we get the same effect using a transcript of the code/script and 
	indexes to tell us where to go back to for loops ? 

OK, we must store the control code.
	- Do we store every line that comes in ?
	- OK for interactive editing.
	- Harder for multi-file script programs. We want to 
		be able to point out error lines. Need to store filename
		as well as line #. Could create objects to store script
		files in a similar manner to the way we will store functions.

Stuff now in tp10.cc:200

============================================================================
25 May 2002

Starting to see some functionality here. 
May need to have a close look at the logic of the control flow and how
it gets values from the evalstack.


Could I put a function into the opstack that flags the control flow ?
Could I make functions for each of the keywords, put them in the opstack,
and just leave them there till they are evaluated ?
	- If would set flags to decide whether further commands are evaluated
		at all.
	- while would put a tag and a GOTO equivalent on the script
	- for would need some fancy parsing
	- return, break and continue would jump around in the position on
		the script and stack.

I will start a new branch to try this out. Put the current tp10.cc into
oldtp10.cc
Look around line 690

Several ways to pass in the tokenizer into the control-flow functions
- Store it at the time of the creation of the msgdest.
	This is OK as the tokenizer is language-specific and a new one
	would be used for every thread.
	Doesn't work because the evaluation routine has to pass in the
	data arg, and usually just passes in the newly created return value.
- Pass it in as the id for 'ret' during EvalOp.
	This looks like being the fallback.
- Do something special in FindOp

I like the first approach. Simple and clean.

Some headaches with types. For example, the dbl.cc doesn't really know about
ints which it needs for EQ and LT Verifies around  line 157.

Got to the point where the IfFunc is being called. This looks pretty decent
and let's see if the control flow stuff will work from here.


============================================================================
26 May 2002

Resolved the little problem with types, but as a more general solution I need
to look into automatic type promotion.

Could put a semicolon in by treating eval funcs as different from funcs.
Ugly.

The key step is that after the evaluation of the braces for the flow function,
the eval_state is set to EVAL_OPSTACK. At this point the system does not know
that the next op is going to be a flow function. So it cannot do better.
When next it gets a token in EVAL_OPSTACK mode, it treats the token as an op
and pushes it onto the stack without further ado. This token is generally
a name and we should be doing EVAL_NAME subject to the flow function.

One possibility would be to put in special symbols standing in for LP '('
following control flow functions. These would have the same low evaluation
level as regular LP, but the system would now expect an expression starting
with either a LB '{' or a name.

There are special control flow words like else, break, continue and sometimes
return that do not need () to follow them.
	else expects an expression list
	continue, break expect a semicolon
	return expects either a semicolon, (), or an expression. The
		braces could be part of the expression.

Now I need to figure out how to put the tokenizer pointer into the 
flow funcs, and were in business.

Stuck a bit in FindOp because the symbol flow( is not known.

Still messing around with brackets. Need to figure out how to handle
- flow control braces for if statements. Works.
- ? braces for functions (works if they have args but not if they are empty)
- Braces for evaluation (works)

if, while: The () are an expression and are followed by an expression list
functions: () enclose a comma-separated series of expressions that can
	be empty. Followed by an operation or a semicolon.
for: () enclose 3 expressions, which can be empty (just semicolons).
return: followed optionally by an expression which may be in braces but need
	not be.
foreach: () enclose an arglist.
switch: () encloses an integer.
include: () encloses a filename. 

Expression list: series of expression; enclosed by {} braces.


OK, got ifs to work. Hoorah.
The zero arg brace funcs don't work again.
Invaded by tiny bugs (of the insect variety.) Shutting down.

============================================================================
27 May 2002
Try out the while() statement. 

Need first to clean things up so that the end of an expression and an
expression list is clearly delineated.
End of expression is a semicolon. 
End of expression list is a RB }.
There is an error if the semicolon is right after a binary op like a + b.
Otherwise no problem.
Backed up yesterday's version as may26_tp10.cc

Depressingly slow going. The expression lists are a pain. There are bugs
obvious by inspection in the SkipToEndOfEvalList function. For example,
suppose I have syntax errors in the expression following  the if:
	if (false) expr;
It won't even see them.
It will stop erroneously in after foo in the following case:
	if (false) 
		if (whatever) {
			foo;
			bar;
		}

and so on.
Current problem is how to handle the termination of the if part. I have
inserted into the opstack a function endif_false. This is called at the
right time but how can I get it to do something ? Maybe it should now set the
next_eval_state to test for an 'else'

Things moving on, I think if I get this going then the loops will fall into
place.

If seems to be working. Haven't yet tried nesting it or with complicated
braces for expression lists.

Working on while. Need a place to put the while line number in. Preferably
not just line number, but also the char # on that line. Opstack comes to
mind as a place but there is all that conversion.

Too tired, but I can see that this should work.

============================================================================
28 May 2002
Should convert the opstack to tokens/ints.
Can I aovid useing IfFunc and WhileFunc ? I do a lot of stack stuff at the
time of tokenizing. The next stack op should be pretty straightforward if
I can pass the status of the test back.
For example, if the test is over I can put a different thing in the stack.
I need a way of inline op funcs forcing the next eval state. 
OK, let's clean this mess up.
We have several places where we could execute bits of the condition. In order:

- Get(). This is where the function is identified, but not a good idea for
	execution.
- EvalName. The name of the func is known here, and it is present as the
	current token. 'else' is evaluated here because we need to
	set up the stacks without any further entries. In theory we could
	do this elsewhere with some difficulty.
- EvalFlowFunc. The func is on the opstack here, and the next token is
	available. This is useful for various kinds of checking and
	deciding what to expect next.
- EvalOpstack. Again, func and current token are available. 
- EvalOp and the C++ function. Here we have access to the evaluated result of
	the condition if any. Can do various opstack functions.

As a bonus, we can probably get rid of EvalFunc too.

To what extent can we do it all within EvalOpstack and EvalOp ?
	if: 
	Treat it like a function. Need to put the "open_expr_list" into the
	stack. Need to be able to control the next eval state. This gets rid
	of the EvalFlowFunc part.
	else: 
	Treat it too like a function. I think this will work even without
	the brackets. In fact we can set up the functions themselves to
	specify whether they want brackets.
	while:
	Similar to if. Need additionally to note current location in stack.
	The while operation itself should not be 


---- Problem is that the ElseFunc is evaluated when there is a = on the
opstack and the variable b on the evalstack.

To what extent can we get rid of the EvalOp and C++ function ?
	if: Check for it within EvalOpstack, evaluate the top of the evalstack.
	else: Check for it on EvalName() or equivalent, use either the 
		endif info or the evalstack to select flow.
	while: Same as if.
	endwhile: really just a goto back to the start of the while statement.

This may be cleaner than the current approach.
	Saved current version as evalop_tp10.cc
	Trying this out in tp10.cc
	OK, got the if-else stuff to work again.

Now working on while. I got the history stuff working. The while is supposed
to look up a value on the evalstack, but this gets messed up by the time the
'endwhile' is evaluated.

Another problem is that the END_WHILE is not executed till something else
is done. It should be executed as soon as it is reached.
perhaps:
	278 if (string_value == ";") return EXPR_LIST_COMPLETE;
and 
	282 if (op == "{" && string_value == "}")
	283	return EXPR_LIST_COMPLETE;

should not return, but check the next item on the stack. Will this affect
if and else ?
Yes. The opstack evaluation is designed to halt under these conditions.
So I need a way of forcing the evaluation of the terminal step.
In other words, when EXPR_LIST_COMPLETE returns, I need to check for
pending loop ops.

Need a way of finding the position of the ist.
While is beginning to do stuff with the non-braces evaluation.

Almost there, but mind has gone.

============================================================================
29 May
Even with the help of the C++ book, I cannot get the position of the stream
in the input string. tellg() returns -1. I have a somewhat fragile thing
working that counts the position assuming that the while is preceeded only by
whitespace. That will have to do for now.

OK, the while loop now works with semicolon, but not with braces.
OK, now braces work but only if there is just one operation.
	Remember that I had to do a hack to get rid of surplus junk on
	evalstack.

Now need to clean up the mess with the evalstack.
That was easy. Just pop the evalstack at each semicolon.

There is still some foolishness with the eval level prompt.
The > is when we are still within braces.
The ? is when we still have something to evaluate within a line.

Next: 
	Many slots to be filled in: break, continue, etc.
	else if
	for loop
	foreach
	* echo: Surprisingly tricky to do properly. May need instead to 
		use a temporary explicity type check followed by casting.
		Longer term: Require a string converter in the cid. So
		we'll put the conversion stuff here in the cid.
	Functions
	Includes

echo seems to work. There is some fishiness with the if statements within
the while loop, though.
Looks like nested statements in general are fishy.

Implemented script reads from files. This will help testing.
Fixed a minor bug with strings.

Ifs seem OK when nested.
while seems OK when nested inside if.

Nothing works when nesting inside while, not even while without braces.

Many fixes later:
whiletest.m seems to work, as sdoes whiletest2.
Whileif does not work. whilewhile does not work.
My brain does not work. Time to sleep.

============================================================================
30 May
Another look at things. The existing structure does evaluation on the fly
so that an if-statement is evaluated as the contents are entered. The first
round of a while statement is also evaluated as entered. This contrasts with
the behaviour of the GENESIS SLI and most other interpreters I am familiar
with, with the notable exception of the Linux tcsh shell.
It will be easier I think and more familiar to adopt the GENESIS SLI
convention.
Since so much work has been done on version 10, I'll save tp10 as tp10dir
and start off tp11.

Now I need to identify the blocks in the script. 
- associate block name with line # of script. 
	Theoretically it is possible for a disgusting person to write a 
	program without line breaks. So it will have to be line and char#.
	Later we might have to add includefilename too. Or we could
	treat a console session as a main() function.
- Do blocks have an id ? Or are they based on a virtual base class ? We
	could maintain an array of pointers to this in the tokenizer
- An advantage of blocks is to limit the scope of locally declared ids.
	By scope we only mean that they get deleted after the block is done.
	Access to these ids can be from anywhere depending on permissions,
	since it is all in an elm tree heirarchy.
	In theory this means that one function could access a local variable
	of another function. That would have to be access denied except for
	debuggers.
- Do I need a blockstack in the tokenizer ? This would help keeping track
	of which 'else' belonged to which 'if' etc.


Derive classes off block, which has Parse and Execute as virtual funcs.
Make an array of blocks on tokenizer.
The main block parses and evaluates simultaneously till a control-flow
	keyword is reached. 
If the control op has an existing block, it is Executed and control
	returned at the end of the block.
If the control op is new, a new block is created, pushed on the stack,
	and parsing for the new block begins without execution.
Parsing consists only of looking for control-flow keywords and filling up
	the block delimiters internally.
When the parsing encounters a new keyword, it appropriately checks
	for existence.
If the block exists it skips to the end of the block and carries on. This is
	an unlikely case.
If it is a new block, it creates another one, pushes on the stack,
	and parsing begins for the new block begins without execution, etc.
When parsing ends for a block, control drops down to the parent block.
	If execution is enabled for parent block, then the just-created
	block is executed.
During execution of a block it sends tokens to the tokenizer to evaluate.
	If it encounters an existing block, goes to new block etc. See
	above.
Local variables are listed on each block, and are zapped at end of it.
	In id terms, they are children of the blonck.


Who should control the input: the tokenizer or the block, or something
else ?
	- Tokenizer can get it easily from the main() or other source.
	- 

	Tokenizer should do the line handling because the blocks will
	typically hand it strings to be evaluated. Or even just tell it
	the start and end positions of those strings.


Slowly coming together, trying to compile.

OK, compilation works and the old eval stuff seems OK still.
Working on setting up ifs.

============================================================================
31 May 2002
I really want something like a Get() for use in the blocks. This will allow
me to scan cleanly ahead through the symbols, avoiding comments, and do
the condition parsing that way. The Get() function should allow me to
build up a string of the condition, and also to scan across line breaks.

It also looks like a total pain to handle the script_position stuff. 
There are so many special cases that come up due to line breaks, and the
char offset stuff is not reliable.
Options:
- copy the relevant eval string into the block.
	Problem with reporting line numbers if I do this
- Clean up its interface so it is pleasant to use.	
- Replace Get() with something that can examine cin or a filein itself,
	and handles line breaks with aplomb.
	Problem is that Get() should not have to do the raw IO itself, otherwise
	the reading loop will get stuck there. 
	- I need anyway to do non-blocking io using a polling mechanism
	- Get() needs to be assured that there is a complete line available
		before launching off, otherwise it will get confused at
		incomplete tokens.
	OK, so I put the incoming chars in a buffer. The buffer can be
	activitated either by scripts or by raw io.
	Get() reads from the buffer. In interactive mode the parser is
	triggered by the linebreaks.

As an illustration, I have an 'unrolled' version of the condition parser
which uses a switch and internal states, but can take input from outside
the loop. And then I have a regular version which assumes that Get()
always has something good to return and does not fall outside the line.
About a 10-fold difference in length.
We can guarantee the presence of stuff for Get() if we do a superficial
parse of stuff coming in such that we know when we are in a condition
and require a closing brace.

OK, slowly working through the stuff surrounding Get() so that it will
in fact behave nicely when called by a control_flow parser.
It is a bit strange to use the full power of Get() when all we want is a 
few key symbols, much like we have in the pre-parser.

PassLineToBlock: Figures out when the sub-blocks can be called.
Also knows quite a bit about the state of the system.
On this first pass I could make an array of tokens as strings that keeps track
also of their line# and char#. Get() could then simply extract these tokens
from the array. Most tokens can be evaluated within this first pass simply
by their chars, the rest could be lumped into a generic identifier to be
worked out later.
	char#, line#, type, strval: entries in the array of tokens.
	Number_value not needed. It is not needed often and atof will serve.
	ptr to control op not needed either. It too is needed rarely and
	can be found as a string.

Currently left things in a big mess, the intial parseing stuff to feed
into Get() being the main part. 

============================================================================
1 June 2002
Working on making a token-info array.
Where should array reside ?
	- tokenizer. 
		Could separate tokenizer from evaluator
	- on each block.
		Easy to pass sections of code to evaluator
	- on main block.
		Central control point. Could double as evaluator.
	- on evaluator
		it is the evaluator that needs to refer to the tokens
		most often.

Other variable: The tokenizer should now point out where the calls to the
blocks have to be. Should the block pointers be added to the token-infos ?
In other words, how will we go through evaluation ? 
Does the evaluator or the block decide when to jump to a sub-block ?
	- Each block marches through its token list, calling the evaluator
	- When the token is a flowfunc, it would be nice to have the sub-block
		ptr handy in the token list itself. That way the block could
		readily jump to it. On the other hand, the block could
		have its own sequence of sub-blocks available in an array
		and just go to them in sequence as flowfunc tokens are met.

	Block->Evaluate(): marches through token list.
	Checks for a flowfunc token, if so, passes control to sub-block ptr in
		token.
		When control returns, the sub-block tells its parent where
		to resume.
	Passes token indices to evaluator to do the job.
	Control has to reside with blocks as they need to evaluate conditions,
		jump back for loops, etc.

During initial parsing:
	main marches through lines and passes to tokenizer
	tokenizer does first pass, converting to tokens. 
	token list is stored on evaluator. Main-block evaluates them
		on the fly while in interpreter mode.
	When a token is a control word, the appropriate block type is created.
		Ptr to block is stored both on the tokenlist and parent block.
		System goes out of interpreter mode.
	Next lines go on list as usual, but no evaluation happens.
	When token is end of all control (and many controls can be nested)
		then main block calls parsing function for child blocks.
		- Parsing functions go from the block start till the end of
		the control flow block. They are self-contained, only need
		to be able to get the tokens.
	If in interpreter mode, then main block resumes evaluation as above.


Setting up inner loop for passing lines to tokenizer PassLineToBlock

Compiles. Now to really get started. 
OK, the initial tokenizer works and puts stuff onto the evaluator.
Now to get the main-block stuff going.
OK, now the basic evaluation stuff works. It doesn't like functions though.
It doesn't like names over 1 char in length.
============================================================================
2 June 2002
Ok, it was not name length, it was that the id for root had not been
initialized.
Now it does not deal with functions.
There is a more general problem with identifying named tokens in the tokenizer:
some tokens may be declared after the tokenizer has scanned the line.
I have various options: 
	- Catch the token declarations during tokenizing itself,
		and use that to assign tokens.
		Problem because classes themselves may be declared and then
		used. We now have an issue of many layers of declaration.
	- Move the lookup of the tokens to the evaluation stage.
	- Do both. Try to identify tokens at the tokenizer, and also 
		use the NEWTOKEN info to tell the evaluator that this
		token was unknown at first, but give it another shot.

Functions now work.
Declarations now seem to work. Tested out strings.

This looks like a good place to start serious control flow stuff.

OK, set up a Parse routine before the Evaluate one in main.cc, and it
percolates down to the if_block::Parse. Now I need to pass in token # info
and just do it.

Finally getting to call the parser in the right place and begin to figure
out the start and end of each of the condition blocks. Now to get the 
parse functions to behave and we'll be in business.

There is a minor headache with the else. I need some way to hold off
evaluation till I know that there is or isn't an else statement pending
after an if.

Got to the evaluation statement within the if. Now need to have some way
of skipping past the tokens used up by the if.

OK, I think the if statement is just about working. There is a small hiccup
afterwards leading to a segv in some cases, I think the stacks are not
cleaned properly. Perhaps I need to check the stacks before going into an
if statement.

============================================================================
23 June.
We get a segv every time any statement is executed after the 'if'.
Should check the working of the ev.Evaluate(start, end) function. It nominally
works during regular parsing, but let's see what happens within a
parse sequence.
============================================================================
18 July.
Testing the Evaluate(from, to) function more rigorously. 
Made a script function ts.m
Munged the main_block::Execute so that it calls various parts of it.
Handles it fine. Doesn't care about order. Doesn't care if the eval line
ends incompletely. Does care if it starts off at something funny.

OK, managed to replicate the core dump by putting in a fairly simple
expression involving braces towards the end
of the expression stuff. It dumps only when an earlier expression starts
off at something funny.


============================================================================
19 July.
Much cleaning up done. Current big concern is state of opstack and evalstack
when evaluating conditionals and other blocks. The state of the evaluator
should always start at EVAL_NAME, and the opstack and evalstack should
be cleaned out. Need to work out if they should always be empty at the
start and end of a block. I think so.
However, we can have nested blocks, such as ifs etc. Does the stack
extend beyond a single statement at all ?
OK, the opstack is tested to ensure it is empty.
And the evalstack should also be cleared at the end. The result is stored
	separately.
And the evaluator should start out as EvalName.


Getting closer. Problems:
	I don't know where or how the conditionals on doubles are being done.
	&& doesn't work
	Ifs still don't work.

OK, one major problem found: The evaluation on conditionals does not actually
happen because they are not terminated by semicolons. I need to find a way
of forcing the evaluation to complete in such cases. Perhaps the closing
bracket could do it.

Nope, but hacked in a temporary fix for that. 

Need to revisit the conditionals. They are not being evaluated
	properly. The above hack only helped with single value conditions.
	The control flow of ifs now work

OK, fixed the conditional evaluation, and now suddenly ifs work beatifully even
	with complex conditionals involving &&, || etc.
	test script: ts6.m


Move on to while.
That now works. Quite painless. test script: ts7.m

Now try sequential ifs and whiles.  test script: ts8.m
Oops, problems with simple ifs. 
now ts8.m handles most cases for simple ifs. Unfortunately they don't
yet work. The debugger says that control_flow.cc:54 is a problem. 
	NumTokens is only 28, which is far less than the correct number.
	What happened to the rest ?
	Looks like I am reading in tokens one line at a time, and
	immediately calling the main_block::Parse function .
	This causes problems here since we don't know a priori that any
	further stuff is coming for the else.
	
Next try nesting if within while. test script: ts9.m

============================================================================
20 July
I think I have tracked down the difficulty with the ifs. The tokenizer does
a good job of waiting till all the info is in for brace-enclosed statements,
but the else case is messy. This needs to be fixed and then it will be OK.

Well, I coded it but it is buggy. Basically the tokenizer now keeps track of
any pending if statements.

Slowly fixing bugs. The current problem is in ts8.m where it croaks on
30 if (b > 5) {
31     c = 90000;
32 } else
33     c = 100000;

But this may be due to a hangover from the previous if.
Nope, it is quite a self-contained bug.
Interestingly it doesn't happen if the else statement is put on another line.
OK, that provided enough clues. I think it is fixed. ts8.m goes through
correctly.

Tried nesting ifs. ts8c.m fails.

============================================================================
22 July.
Actually even the regular ifs are not working. There is a problem if the last
statement in the file is an if. This arises because the parser does not know
whether to expect an else there.
Saved a test ts8c.m showing this situation.

Now on to ts9, for nesting within control flow situations.
Oops, this broke ts8.m.
ts6.m still works.

OK, figured that out. In my adding the nesting code I had messed up the
original. Now ts8.m works.

ts9.m doesn't go into infinite loop, let's see how the eval goes.
Eval works for some cases, but cannot handle the case properly where 
neither if is enclosed in curly braces.

Now things are better, but there is a problem case in 
ts9.m. Here there is no line in the file coming after the second nested if. The
system doesn't parse the second nested if.

============================================================================
23 July.
Revisited the problem with ts9 a little more carefully. It is not a problem
with nesting, it is a generic problem with termination of if statements.
ts9b.m illustrates this.
- One answer is to assume that I will never just have an if-statement at the
	very end. Ugh.
- Another answer is to recognize an eof in the case of a file. 
- Another answer is to require the user to add a semicolon to tell the system
	of the end of an if. This would be useful in-line, though of course the
	user could just carry on with another statement and the parser would
	eventually fill in.
Implemented second option, seems to work. For interpretive functioning the
	second case would have to hold. It is just a limitation of using C
	as the base language.

Now it seems to handle the nested ifs. Good.
ts9c: Tested else if. Seems to work.

ts10.m tests an if nested in a while. Seems OK.
ts10b.m tests while nested inside if. Seems OK.
ts10c.m tests while nested inside while. Seems OK.

Wonderful. We have the most of the basics of the parser. Things to do,
in order of importance. The later items are more by way of filling up corners.
	*expressions
	*if - else
	*while
	Functions
	for loop
	foreach
	include
	return
	break
	continue
	* echo: Surprisingly tricky to do properly. May need instead to 
		use a temporary explicity type check followed by casting.
		Longer term: Require a string converter in the cid. So
		we'll put the conversion stuff here in the cid.
	switch, 
	do while.


Points for implementing functions.
	- Definition: TYPENAME NEWTOKEN(ARGS) then either { or ;
	- Operation: name(args).
	- Need to handle declaration as well as simultaneous declaration and
		definition
	- A function is a type like an int, a control_flow block, and also
		a msgdest with a VerifyFunc etc like the other funcs.
	- Primarily it has to be a msgdest, so that EvalOp knows how to deal
		with it. Also this will be useful for hooking into rest of
		moose.

============================================================================
24 July.
	Try dual inheritance from msgdest and ControlBlock
Slowly setting it up. The class is in func.h, should be created in the
main block of the control_flow.cc file.

============================================================================
25 July.
	Got to declare and define a function in a dummy manner. 
ts11.m illustrates this.

- Need to set up a data structure that can actually make the function usable
- Need to provide for separate declaration and definition of functions.
- Need to set up a system for variable scope so I can use argument names
	that already are defined in root scope.


Setting up the actual function creation stuff.
============================================================================
27 July 2002
Rearranging the code. Need to settle convention for returning errors when
parsing. Will go for returning zero on failure and line number on success.

Nearly done with the compilation of the scriptfunc, but the dual inheritance
isn't working.  May need to redesign.

============================================================================
28 July 2002
Possibly the problem with dual inheritance was actually simply the failure
to define one of the virtual funcs. It compiles now in the single-inheritance
form, but things are messy. I'll see if I can go back to dual inheritance.
Yup, works. Much better.

OK, another problem solved. The evaluator needs to bypass the scriptfunc
definition when doing the evaluation. This involved placing a dummy
scriptfunc in there to skip the lines. Now to the actual execution in line.
there are two ways to do this. One, which I have assumed, is to treat the
script func as a regular func. Fine, and I can get it to work. Note
that this will involve runtime verification of argument lists. Not fun.
Another, perhaps more interesting, is to put it in using the same function
blocks as for control flow.

Since I will be using the Evaluate() function anyway for message handling stuff
it would perhaps be cleaner to use it. Problem is that the scriptfunc needs 
a context, that is, the evaluator class, to perform the evaluation.
- Store ref to evaluator on function ?
	- Nope. May need to execute evaluator in a different context.
- Keep function context-free ?
	- This means that the scriptfunc needs to keep track of its own tokens. 
	- May need context of parent elm etc for the purposes of doing
	  local messaging
		- Parent elm is available anyway as the scriptfunc has
		the myeid field.
OK: store token list. Keep things context free, but myeid is available.

This raises issues.
- What about the parent block in control-blocks ? Turns out it is never used.
	Work on getting rid of it.
- Control blocks have worked by looking up indices in a master list in the
	evaluator. This will get messed up when the blocks are copied over
	and used within functions. For example, a function may get defined
	and then used long after the defining evaluator has gone on to
	other things. 
	- Evaluator no longer needed as an argument when invoking control
		blocks.
	- Place all tokens within the operating control block.
		- Clean up token sequence by excising introns of tokens
			belonging to other blocks.
			- This gets rid of the silly dummy scriptfunc to
			skip over tokens declaring and defining the function.
			- It also simplfies returning from all blocks, as they
			only need to go on to next line. The issues of 
			error handling become much easier.
			- History maintenance becomes a separate operation.
			Maybe that should store only the line strings.

OK, this looks good but it is a major overhaul. Will defer till I have
a block of time to convert and test. I will get functions to sort of
work now, and then check it all in as a tp11 version.


Well, the func is working but it led me round in circles because the program
wasn't recognizing a variable I had defined. Turns out that
type declaration has gone out the window. Need to fix.
By the way, Hoorah! I have gotten functions to work. Who cares that I'll have
to tear a lot of this down to do it again.

Type declaration problem identified, not solved. Tokenizer does not
recognize names declared until the evaluation has been completed. Two options:
- Do field declaration stuff in parse stage
- Handle NEWTOKEN in a manner which knows about recently defined objects.

============================================================================
29 July 2002.
Wrapped up version tp11. Filed it all away in its own directory. Now to figure
out implications of having tokens stored only in their appropriate blocks,
and related design stuff.

- Tokens should store: Symbol, token, block ptrs/ids if needed, line #.
	Drop parent block ptr.
- Blocks should store: Token list, source file name, local variable list.
- Blocks are created as ids when a file is read. Parent of all blocks is the
	session block which is associated with a given shell. Blocks are
	frequently nested.
- Although the parsed block structure is created once, there is the evaluation
	structure which is created on the fly and every time a block is
	executed. Parent is the shell. A given parse block can give rise
	to multiple evaluation blocks. Each evaluation block is destroyed when
	it exits.
- Local variables in an executing block are created as encountered. They
	are children of the evaluation block. They will obviously be destroyed
	when the block execution finishes.
	- One implication of this is that the NEWTOKEN issue above has to be
	resolved at tokenizer or parser stage so that the token is recognized
	as an existing name. We cannot create anything till it is executed.
	- Note that the use of block scope needs to tie into variable
	declarations. This will keep the variables declared within a block
	from becoming available outside it. 
	- Need a nested lookup scheme for variables declared in different scope.
	Anything declared in an ancestor of a block is available in the
	block scope.
	- Static variables are odd. They are available within block scope,
	but are not created with the block. In other words they are associated
	with the block and not the execution objects.
	- I will need a way of referencing all these variables rapidly without
	having to traverse a tree to find one declared closer to root in the
	execution tree.
	- How about having the execution object as the appropriate 
	language parser class.


============================================================================
4 Aug 2002
Most of the above can be implemented by having nested execution blocks holding
the local variables. The current implementation of test does not handle
parenting in ids, otherwise this could easily be tried out. In any event,
we need a clean way of dealing with variable scope.
- Stack scheme: Keep a stack of available variable ids on a stack. As we
enter and leave blocks the stack is updated. This does NOT natively deal with
creation and destruction of these variables, just a quick way of accessing
and identifying them at runtime.
- Can lookup be done at parse time rather than runtime ? Not easily if we are
doing runtime creation and destruction of variables.
- Can lookup refer to stack indices rather than namestring
comparisons ? This would be as fast as the parse-time lookup. I think this
should be possible. We anyway need to keep track of recurrence of newtokens
and this could be integrated into that mechanism.

Consider line 217 in tokenizer.cc. This is where the lookup for name to id
occurs. It will any way need to be modified for handling prior name
declarations. All that this function does is to return the
token-value, which is either NAME or FUNC under these conditions.
So the actual name lookup happens elsewhere,
at line 99 in evaluator.cc to be precise. Here I do a simple string-to-id
lookup. This will succeed in finding the most recent id of the appropriate
name, and in that regard would actually do OK for lookup of local variables.

In theory I could have stuck the id into the token itself. Only minor detail
is that the id itself is created only at runtime, not at parse-time.

============================================================================
5 Aug 2002.
More details about the namespaces. In the C-style parser, we actually have 3:
- Absolute: /foo/bar
- Relative to cwe: ./glug/zap
- Heap, created as local variables by parser: int i, j;
The first two are 'tree' variables - they exist on the element tree
independently of the parser.
The last is a parser or shell variable. It should be reachable from the tree,
	but is highly volatile.

I already had planned to have two ways of identifying a tree variable:
- to generate the id in the parse stage as a default.
- to force a full tree name lookup when the variable might be volatile.
- Possibly we need a third: to handle cases where the variable is not
	volatile, but is not created till after parse time.
	- Could we create an id for it at parse time, without filling in the
	contents ? This would let us use the id in the token list.

Ambiguity 1: Lookups of relative tree variables vs lookups of shell variables.
	- Obviously the shell variable names should hide the tree variables.
	- Creation of variables, alas, cannot be so resolved and will need
	the ./foo/bar format.
Ambiguity 2: Lookups of shell variables redeclared in different scope.
	- Obviously the innermost shell variable should hide the rest.
	- There is the bizarre possibility of retro-creating an out-of-scope
	shell variable. As sane languages do not support this, nor will I.

Key issue: Can we come up with id-based lookups for all variables, rather than
name-based lookups. This has enormous efficiency implications.

Example:
	Recursive func1.
	/shell/func1/i
	/shell/func1/func1/i
	/shell/func1/func1/func1/i

i is created inline.
Each scope can keep a scope_start index.
id for i is scope_start + 0
id for j is scope_start + 1
etc.

When exiting a scope, delete all ids down to scope_start.
Each control block has an array/map of local variable names vs this rel index.
Is there a separate token for local variable names vs. tree variables ?
Recap: control blocks are permanent entities, but there is a 'scope'
	that is created on the fly.
	- the 'scope' must have a scope_start field.
	- the 'scope' must know its parent.
The IdentifyToken function must know how to recursively query the parent scope
for a variable name not found in current scope.
	- How do we represent such a relative id ?
	- Yet another token subtype indicating parent depth ??
		- Note that the evaluator has to maintain a scope tree.
		- Is Parent depth a scalar as seen from any given end branch?
			- Fine so long as no recursion
			- Recursion happens only in functions. Functions are
				self-contained in variable scope, barring
				globals and statics.
		- Absolute position on tree is non-scalar.
	- Can we look up the appropriate depth of parent using a scalar ?
		- The alternative is to traverse the parents n times for
			ancestor local variables.
		- A stack of current scope pointers would do it.
			- Could it be maintained as a static variable in scope?
				- No, each function invocation needs a local
				stack.
				- The outer shell would be a function and thus
				have its own scope. Good for handling multiple
				concurrent shells.
				- Each control block invocation passes in
				this stack.
			- Push and pop when enter/exit control blocks
			- IdentifyToken cannot traverse call stack, but
				the Parse stage can. So, name lookup has to
				be deferred till then.
	- What does the data type for local variables now look like ?
		int parent_depth (0 = local, 1 = parent, 2 = gramps, etc.)
		string variable name (map index ?)
		int rel_index.
		id id.
	- What does the data type for tokens now look like ?
		- parent depth is implicitly coded in the Token_value enum.
			Or it could be an int, filled in at parse time. Cleaner.
		int lineno;
		Token_value tok;
		string s;
		int rel_index; // for local variables, filled in at parse time
	- What does the data type for the scope now look like ?
		array/map of local variables within scope
		link for parent scope
		ptr/pass in scope stack.

Other value types
	- Global variables are declared on shell.
	- Static variables need to be redeclared in functions for each
		shell.
	- Constants are just ids. They are children of the function, and
		can be shared between all running shells.


Plan Of Action:
- Convert current implementation into one using local storage of token lists
	within blocks. Test function.
- Implement constants as ids. Test function.
- Implement stack of variables based on functions. Function not changed
- Implement map of variable names to variable stack, within each control block.
- Fix problem with declaration of variables vs run-time creation.
- Implement scopes
- Implement variable scope
- Implement global variables
- Implement static variables

============================================================================
6 Aug.

Working on:
- Convert current implementation into one using local storage of token lists
	within blocks. Test function.

Some problem with the evalution for 'if'.
ifs and whiles nearly done, tested without nesting. Need to convert all
of it to be able to remove the legacy version and to handle nesting.

============================================================================
2 Jan 2003
If I give up the direct tie from id to object pointer I could do:
eid as index to 2 arrays: Container, data obj
Would have to allow namespaces for different id sets.
Within a given namespace, the same id and array applies regardless of where the 
	object is located on a distributed platform
	Need to ask container how to go to its parent
	Need to ask conatiner how to find index of id, and name.
/a[10]/b[5]
	Solution 1: Array type container only, has info only on start, n.
	The container could use the data obj ptr to figure out the index.
	Note that the container does not even need to store all the pointers
	Solution 2: Each obj has its own little container with index and
	name info. This is costly. Consider an array of shorts.
	Consider issue of non-uniform arrays. Would have to dereference,
		e.g., array of ids.
fid as index to 2 arrays: Accessfunc, class obj

============================================================================
3 Feb 2003
Found a fatal flaw with the idea of merging lmsgs and rmsgs. I really need
now to get back to basics of actual usage. The flaw is as follows:

Consider PROCESS or RESET method on pool receiving input from some 10 reactions.

There is a single active message operation: the calling of PROCESS.
	Usually single source
There are multiple passive message (argument lookup) operations: one for
	each of the incoming reacs, each with two arguments (A and B here).
	The  number of such arguments is also variable.

Other cases:
DELETE/CHILD: Single source, single dest, no args.
SET: 

Message type	#sources	Source args	# of args	Arg types
PROCESS		1 (clock)	dt, clock...	Many		doubles: A, B
RESET		1 (clock)			Many		doubles: A, B
DELETE		1 (parent)	-		-		-
LINK (child ?)	n (parent)	-		-		-
SET		1 (src)		value		-		-
PLOT		1		double value	1		double Time
XYPLOT		1		double value	1		double X
CREATECHILD	once off	str name, cid type  -		-
JOB		1		dt, clock	-		-
XVIEW		1 (clock)	dt, time	Many		doubles: val
								floats: x y z
XVIEWPOINT	1 (control widg) viewpt		-		-
GET		1 (some event)	-		1		any value


Can all arguments be replaced with active arg calls ?
- Avoid issues of updating evaluated fields
- Need either storage or immediate evaluation on targets.
- Good for passing to other nodes.
- Problem is clocking the updates. The arguments may only be needed
	sporadically. However, the updates could be clocked by a PROCESS
	rather than the object demanding the values.
- May entail a larger number of scattered calls. However, this may be
	symmetrical in the end if we consider scattered srcs for arguments.
- May need to split up scheduling into finer divisions. Multiple functions
	called by same src for same list, for example, RESET, INIT, PROCESS.

Can all arguments be replaced with calls to functions returning arguments ?
- Problem is bidirectional info flow. 
- Can this be replaced with a pair of msgs ? Of the list above, the
	graphic calls would be candidates for async (paired msg) requests for
	data.

Can I use something like the current msgargs arrays ?
- Nasty issue of wandering pointers, but as now, the actual msg info could
	be kept separate and used for the update.
- Same issue of updating the pointers esp. across nodes. Would need a
	way of identifying which clock is used by the object demanding
	the arguments. This would have to be explicitly available.


A serious concern with all the above is that things have to be fairly general
for the postmaster to be able to handle them. One option is to provide a 
general Execute function in the msgsrc that simply dumps the appropriate
number of bytes. Optimisation is less critical when the info has to go through
MPI. The remote postmaster now must be able to pick up the pieces.

I have a lot of ideas here. I think the best option is to make a test case
like the one in ELKS, where I try out these messaging options and further
do some node decomposition.

============================================================================
4 Feb 2003
Did some implementation. Got the simple version of the msgsrc::Execute to
compile and execute for the PROCESS:
const int Execute() const {
	return F(list);
}

Next, replace the reaction update stuff with messages.


Suppose we permit special types in the msgsrc and msgdest.
- General msgsrc/msgdest options still available
- Addition of msgs not a problem, as it happens within the msgsrc and types are
	checked.
- Problems mainly with postmaster. I think these are solved. At the
	msgdest end, one needs to write an accessory msgdest class for the
	postmaster to grab the info. At the msgsrc end, one needs a 
	virtual function (that can be defined at the base msgsrc level) which
	will take the postmaster data stream and make the function call.


Current status:
Implementing ReacPool msgs (src and dest) in reaction.h and molecule.h
Implemented but not tested the base classes for msgdest and msgsrc.
Need to implement:
*PoolReac msgs, trying to compile
*Clock object
*Clock msgs
*Reimplement Euler calculations
General field msgs ?
*PoolEnz msgs
*EnzPool msgs
PoolPool msgs (sumtotals)
Reimplement RK4 calculations
Implement bare postmaster
Partition onto nodes.
Fold back into Moose

============================================================================
5, 6 Feb
Slow progress on implementation due to other timesinks.
============================================================================
7 Feb
Implemented clock object and started setting up clock msgs. 
Finally got the clock messages attached to molecules and molecules,
and this loads up. 
============================================================================
9 Feb
Impelemented setting up messages between reactions and VariableMolecules.
Now need to decide how to handle the special cases: Buffered, Sumtotal etc.
The simplest would be to duplicate the MOOSE implementation.
This would be slow as I would have to put multiple checks in.
The faster version would be to retain multiple classes but create dummy
messages that do not do anything but do establish the presence of a link.
This is complicated.
Another version would be to allow messages to come in and execute dummy
functions that do nothing.

Implemented and tested Euler calculations for reaction-pool systems.
No enzymes or sumtotals yet. Those should be straightforward, perhaps messy.

Lessons:
	Too easy to make mistakes with typecasting of target msgdests.
	- Perhaps the arg checking with the full parser will fix it.
	- Perhaps specification of a preprocessed moose: block would help too.
	Often want reciprocal messages. Could this be optimised ?
	Often use stereotyped message pairs, like DoubleMsgSrc/DoubleMsgDest.
	Elks runs in 2 sec. The ssim version runs in 20. Even accounting
		for Exp Euler costs, this is good.
	msgdest base class should not have a vector of msgsrcs, there should
		instead be a singlemsgdest and multimsgdest
	msgsrc base class should not have a vector of msgdests, there should
		instead be a singlemsgsrc and multimsgsrc.
	Need a way of encapsulating the subclasses defined for the messages
		into a given MOOSE class.
	Could template stereotyped things like DoubleMsgDest derived classes.

I currently use a whole bunch of utility functions/classes to deal with
messages:
	AccessProcess()
	HandleProcess()
	ReacProcessMsgDest
	ReacProcessMsgDest::Execute()
	const int ReacProcessMsgDest::object_offset
	void AddSubstrate()
How far can these be merged ?

============================================================================
11 Feb 2003

Notes for discussion.

Overview of the messaging implementation, with examples
Still to implement and test:
	- Boilerplate for removal of messages
	- parallelization: data streams
	- generic messages: 
	- Pointer to id lookups
	- function calls
Lessons from current implementation
Issues for cleaning up implementation.
Possible directions for base-code development.
	- Automatic boilerplate coding, a	moose:	keyword
	- Messages for all field access ?
	- Tying in to solvers
Other base-code issues
	- Field and id lookups. Should we do another test case ?
	- Containers. What would we use them for ?

============================================================================
12 Feb 2003
Got the entire fb31b.g to work with the messaging stuff.  It takes 7 seconds
to do 100 sec at a dt of 0.0005. The EE method takes about twice as long
in kkit.
============================================================================
3 Apr 2003
Messaging revisited.
- Profiled the code. It is quite balanced.
- I could template <type>msgsrc and <type>msgdest. Most messages are in this
	category. If I also provide <T1, T2>msgsrc and <T1, T2>msgdest I
	think I will be set for 95% of messages. This templating should
	also handle the verification.

Stages:
- Implement postmaster dummy locally, pass messages through that.
- Implement general message creation functions. This should only need
	the src and dest, as all other info is internal. (Actually msgs
	already operate this way, it was the funcs used to
	set up msgs between pools and reacs that were specific.)

============================================================================
5 Apr 2003
Stages:
* Fix message base classes so they do not assume lists of messages.
* Use templates for messages. This is needed to be able to call
	their Execute methods with the correct arguments. It will eliminate
	the need to create individual definitions of the msgsrc and dest.
	I wonder if there is a way of defining a single class in the templates
	to handle both src and dest parts.
- Implent postmaster dummy locally, pass messages through it.
- reexamine load.cpp and see how msg setup can be done through
	postmaster in a general way.
- Implement and run simulation through postmaster.

============================================================================
6 Apr 2003
- Using templates for messages. Examining allocation of messages. We have the
following orthogonal sets of cases:
	- Predefined msg structs vs predefined pointers vs arrays of pointers
	- Storage on data class vs storage on container.
	- Msgsrc vs msgdest
Considering each.
	- Predefined structs, all cases: 
		- Gets rid of allocation, freeing, lookup speed problems etc.
		- Compilation headaches. This should not be a consideration.
		- Limits extra cases.
	- Predefined pointers, all cases:
		- Advantage in compiling and setting up. 
		- Advantage in storage initially
		- Advantage in the use of msgsrcn vs msgsrc1 and other tricks.
			- The number of msgs may actually be part of design.
			- Would need to handle case of extendable_msgsrc1
			vs fixed_msgsrc1.
		- Disadvantage in storage and speed if the class always uses
		the messages.
		- Need to handle alloc/dealloc stuff, should not be a concern.
		- Limits extra cases.
	- Arrrays of pointers all cases:
		- Yet further alloc/management issues, should not be a concern.
		- Great flexibilty for various cases
		- Serious speed and lookup issues.
		- Arrays of pointers, msgsrc:
			- Problematic because methods will need to invoke
			specific outgoing messages and should know their
			location at compile time. May as well use predefined
			pointers.
			- Murky utilty for handling generic updates.
		- Arrays of pointers, msgdest:
			- Additional storage needed now for dest data.
	- Storage on data class
		- Appropriate for specific messages
	- Storage on container
		- Problematic because the functioning of the data class
		includes messages, and this functioning should be local. 
		- Appropriate for generic messages
		- Storage on container, msgsrcs
			- Problematic because the data class messages will need
			to invoke specific outgoing messages and should know
			their location at compile time.
			- Is it needed ? Are there any generic conditions
			leading to message calls ?
				- Creation, destruction, generic assignment.
				Note that all of these could well be container
				msgdest calls too.
				- General update events, following any of the
				msgdest calls. Normally a specific msgdest
				call will have a specific set of outgoing
				calls, and should be handled on the data class.
		- Storage on container, msgdests
			- The trick for avoiding storage of the data field
				pointer won't work. Could manage otherwise,
				but slower.
			- Field lookup will be slow and/or complex.
			- Generic msgdest to handle updates ?

Conclusions
- Dual tier messages. Generics on container, specifics on data class.
- All messages handled as predefined data structs.
- Reasonably efficient:
	Msgsrc overhead = 8 bytes
	Msgsrc per message: 4 bytes
	Msgdest overhead = 8 bytes
	Msgdest per message: 4 bytes
	Msg call overhead:
		Iterated (dereference + offset + virtual func + arg stack)

============================================================================
8 Apr 2003
Implemented templating for all messages in MSG. Astonishingly, it ran correctly
first time after I got it to compile.

Stages:
* Fix message base classes so they do not assume lists of messages.
* Use templates for messages. This is needed to be able to call
	their Execute methods with the correct arguments. It will eliminate
	the need to create individual definitions of the msgsrc and dest.
	I wonder if there is a way of defining a single class in the templates
	to handle both src and dest parts.
+ Implent postmaster dummy locally, pass messages through it.
- Figure out how to batch messages from a given clock onto the postmaster.
- Figure out how to batch messages destined for different nodes.
- Figure out how to handle asynchronous messages
- reexamine load.cpp and see how msg setup can be done through
	postmaster in a general way.
- Implement and run simulation through postmaster.

============================================================================
9 Apr 2003
Thinking about the info for scheduling. Dependency sequence for messages should
be built into the objects that use the messages. I think sequence only needs to
know about incoming msgs. 

============================================================================
10 Apr 2003
Planning postmaster handling of outgoing messages.
- Need to bunch messages by target
- Need to bunch messages by clock tick.
- Various categories of messages:
	Lockstep, handled by clock ticks, usually small fanout
	Asynch, usually with a modest TTL, like action potentials, often large
		fanout
	Once-off function calls, variable TTL, variable fanout

Options:
- All pending messages go out each clock tick, block till complete.
	- Ensures sync on each tick
	- Cannot optimize by computing while data propagates
- All pending messages go out each clock tick, set up separate sync sequence
	for blocking.
	- Tie it to scheduling info for classes
	- Cannot optimize by deferring and clubbing messages with a large TTL
- Messages sorted by TTL. Do some history management to see if a given target
	is likely to be sent a message well before the next TTL. If so
	club messages, otherwise send ASAP. TTL 0 messages go immediately.
	Separate sync sequence for blocking.
- Messages subgrouped when the compute time in generating the messages itself
	is large, so that batches can be sent out as the computation proceeds.
	- Should actually be able to separate this into different clocks so
	that there is lots of compute time and relatively little time for
	dumping messages out. Should think.

Handling synchronization sequences. Goal is to allow as much computation as
possible before placing a block for return messages.
Example: 
reacclock --Process--> reac --submsg--> molecule
                            --prdmsg--> molecule

molclock  --Process--> pool --submsg--> reac
                            --prdmsg--> reac
                            --sumtotmsg--> sumtot_mol

Suppose we have reacs and pools on each node, and a few communicate
across nodes. The dependency sequence is:
Reac submsgs/prdmsgs from outside source must reach before local molclock.
Pool submsgs/prdmsgs from outside source must reach before local reacclock.

We can avoid having to do any bidirectional transfer if we know exactly
what is expected, and can validate its arrival.
The postmaster then sends a message to the relevant local clock telling it that
it can go ahead.

Each class must be able to provide info about this dependency.

Additionally, the postmaster needs a way of knowing that all local messages
attached to a given clock tick have arrived. This can be from a message
sent by the clock to the postmaster AFTER it is done with its local calls.
The data transfer out will usually start at this point.

Complications
- Higher order clocks involving multiple message types and targets.
	- The dependency analysis should be designed to sort this out.
- Messages coming from different jobs, async with each others clocks, going
	to same node.
- Messages with same info, going to multiple targets on same dest node.

Implementations
- All msgdest templated instances store access func to the msgdests
	they depend on. The former must block till the latter are done.
- All msgdest templated instances store access func to the msgdests
	that depend on them. The latter must block till the former are done.
	In the above list: 
		reac_Process <=depends on= pool->reac_submsg, pool->reac_prdmsg
		pool->reac_submsg <= reacclock->reac_process
		pool_Process <= reac->pool_submsg, reac->pool_prdmsg, sumtot.
		reac->pool_submsg <= molclock->pool_process
		pool->sumtotmsg <= molclock->pool_process


Conclusions:
- Postmaster knows what to expect and tells the clock when it has arrived.
- Classes must know dependencies between incoming messages and clocks.
	- Postmaster sends inquiry via messages from itself to dest objects
	- Objects refer inquiry to dependent messages
	- Dependent messages follow through to find src clock
	- Src clock and postmaster tie up to establish dependency.
	Note that we can also create clocks de-novo using dependencies:
	- Connect up messages
	- First object creates a clock for its process.
	- All objects of that class adopt the same clock.
	- Follow outgoing messages from Process to dest object
	- Dest object looks up dependent messages. If one is a Process,
		create a new clock, scheduled for after the first. All objects
		of the dest class adopt this clock.
	- Repeat this till dependent messages do not yield unclocked objects.
	- March on through object list till we find another one without a
		Process clock. If we find one, it is interesting as it is
		orthogonal to first set. Anyway, give it the first clock
		and repeat process.
- Clocks manage the I/O
	- All outgoing remote msgs track back to originating clock and 
		connect to the SendNode there.
	- In tracking back they also eliminate redundancy arising from fan-out
		of their msgsrc.
	- Originating clock triggers the Send when it has done its calls.
		- Could bifurcate the clock between local and remote msgs.
	- The RecvNode for incoming remote msgs is located on the 
		first clock with dependencies on those msgs. The clock blocks
		till recv is complete

============================================================================
11 Apr 2003
Slowly going on with implementation. Various messy bits, like having to use
dual inheritance with virtual classes to handle node information in msgdests
on nodes. The sending part is now done, need now to do a quick and dirty
implementation of the receiving part to start testing that.

Stages:
* Fix message base classes so they do not assume lists of messages.
* Use templates for messages. This is needed to be able to call
	their Execute methods with the correct arguments. It will eliminate
	the need to create individual definitions of the msgsrc and dest.
	I wonder if there is a way of defining a single class in the templates
	to handle both src and dest parts.
+ Implent postmaster dummy locally, pass messages through it.
- Figure out how to batch messages destined for different nodes.
- Figure out how to batch messages from a given clock onto the postmaster.
- Figure out how to handle message creation between nodes.
- Figure out how to handle asynchronous messages
- reexamine load.cpp and see how msg setup can be done through
	postmaster in a general way.
- Implement and run simulation through postmaster.


Let's design a test case that can scale to all the above levels. 
1 Not too big, so it can run on a single machine
2 Needs all cases: reac, enz, sumtotal, plots
3 Needs local messages
4 Needs messages going between each pair of nodes
5 Should be scalable to different numbers of nodes
6 Should be scalable to run in SMP mode
7 Should be conceptually simple so I can understand it and figure out when
	it goes wrong.
8 Should be set up from the script file.

Option 1: hard-coded
	Diffusion model handles 5,6,7. Scale to 1, 2 and 3 dimensions as needed.
	Central plotting handles 4.
	Internal set of reactions handles 3.
	Bistable toy model handles 1 and also gives some very interesting
		possibilities for propagation in 1, 2 and 3 dimensions
	For option 8, put in a comment line of the form 
		// dimension	x y z
	The x y z are the # of cubic grid points in that dimension.
		// diffuse	path1 rate1
	The path is the molecule to be connected up between all adjacent nodes
	on the cubic grid via a diffusive reaction created by the test on the
	fly, having the specified rate. The reaction doing diffusion
	is created on the lower numbered node.
	Case 2 is dealt with because we'll have 2 kinds of messages
	going via these diffusion reactions: reac->pool and pool->reac.

Option 2: Entirely script-coded
	The group name specifies which node things are on.
	Everything is hand-coded.
	Start with toy bistability model
	Options 1, 2, 3, 4, 8 are done easily.
	Options 5, 6, 7 will be a pain to set up, but not as much as the
	automated version I was contemplating. Also it avoids messing
	too much with scripting.
	
Should the stuff for sending and receiving extra-node messages be located
on the clocks ? 
	- Better coordination with the scheduling
	- Issues with multi-job and async msgs
	- Better coordination with SMP scheduling.


Current status:
Implementing the Send and Receive calls for the single-node version, but using 
postmaster calculations.
============================================================================
12 Apr 2003
Got it to compile. Remaining issue is to specify how to set up messages.

- Modify the msgsrc::Add method to identify parent nodes and send messages
	appropriately.
	- Need to implement only in one place
	- Would need to identify parents of all messages (which I need
		to do anyway)
	- Need to identify nodes of all objects (through name stored in
		Entry, but later ?)

- Modify the LoadModel and DoConnect operations to send node info along with
	message requests.
	- Need to change in multiple places
	- Anyway need to have node-selective creation of objects

- Load up on single node and then distribute out.

I am inclined to go with a more general approach to addmsg.

OK, framework in place. Needs set of virtual functions
+ Entry::GetMsgSrc(const string& type, const string& arg)
+ Entry::GetMsgDest(const string& type, const string& arg)
* msgsrc::MakePostDestMsg()
* msgdest::MakePostSrcMsg()
* postmaster::Get(int node)
* SendNode* postmaster::GetSendNode(destnode);
* SendNode* postmaster::GetRecvNode(srcnode);
* SendNode::AddMsg(msgdest* msg);
* RecvNode::AddMsg(msgdest* msg);

Lots of cool stuff to come, like telling the postmaster to convey the
request to target postmaster, using a msg call...

============================================================================
13 April 2003.
Compiled the mess. Possibility for cleaning up reference to parent
object from member. See pg 852 and 419. 

Got the mess to work. Sort of. Need still to sort out the scaling volume
issues. Should be a simple matter of scaling kf on RESET based on size
of the incoming REAC msgdests.

Next: Make test toy model on 2 nodes. This is reac2node.g. 
Immediately gives a segv. 
Many fixes later. Stuck in the NodeInfo part of the PostMasterDests.
Need to figure out how to access the dataptr of the PostMasterDest.

============================================================================
14 Apr 2003

We have two major classes of msgdest: those which are explicitly created
in their data classes, and those which are dynamically allocated later.
The former can do stuff to locate their parent. The latter need a pointer.
This pointer could be assigned either at creation, or as a utility function
of the msgdest. Utility functions make the msgdest interface fat, should avoid.
In addition many dynamic msgdests need information about what they are to
do, and where. For example, a pointer to an address to update.
- If I assign this information at creation, then I need a facility to 
	recreate with updated information, or to change. All msgs need
	a serializing feature to convert the message from the functional
	form to a portable definition, and back. This feature could
	also support recreation.
	Problem is that the msgsrc needs to be able to create the message,
	so the MakePostDestMsg() call must include information for providing
	pointers and offsets. Currently it provides src and dest node, could
	in principle look up.
- If I create a base virtual update function, then it has to take both the
	information about its parent (presumably an Entry*) and about the
	specific data it handles (an fid ? A pointer offset ? A raw pointer ?) 
- If I create a class with object lookup info, or even object and function
	info. It would be defined for each message and embody the Handler
	function as well as whatever lookup info is needed.
	Execute(const T arg) 

Conclusion:
	* Implement a GenericMsgDest template for each # of args. Each of these
	contains the arg pointer, the parent pointer, and handles a single
	msgsrc. All it does is assign the argument to the arg pointer.
	It applies for postmasters as well as forthcoming generic messages
	handled by containers.
	- Probably need to add a way to identify parent object from the
	msgsrc.


Implemented the first. Compiled. Ran. Messed up on different clocks
and msg types represented by different Sends and Recvs on the same post
master, otherwise seems to be getting there.
As a quick hack, I'll check the dest node type and base the clock/Send/Recv
assignments on that.

Some minor headaches still with setting up the node arrays.

OK, finally got it to work. Hooray. Next step is to clean up and set up 
via the clocks.
Saved current directory as apr14_2003_MSG

Stages:
* Fix message base classes so they do not assume lists of messages.
* Use templates for messages. This is needed to be able to call
	their Execute methods with the correct arguments. It will eliminate
	the need to create individual definitions of the msgsrc and dest.
	I wonder if there is a way of defining a single class in the templates
	to handle both src and dest parts.
* Implent postmaster dummy locally, pass messages through it.
* Figure out how to batch messages destined for different nodes.
- Assign incoming and outgoing messages to the clocks.
- Figure out how to batch messages from a given clock by back-tracing.
- Figure out how to handle message creation between nodes.
- Figure out how to handle asynchronous messages
+ reexamine load.cpp and see how msg setup can be done through
	postmaster in a general way.
- Implement and run simulation through postmaster.


============================================================================
18 April 2003
Implementing clocks with internode I/O on them.

The approach used with msdests (using object_offset) won't work because
msgsrcs are more generic. I need to specify a more precise template.

I want also a general system for automatically setting up clocks. 
It is good to do this depending only on the messages set up in a given
model.
- No need for a global database. Object-local info only.
- System can optimize clocks and model decomposition based on individual models

Implementation for identifying where clocks are needed:
- src back to calling msgdest.
	Each msgsrc knows if it has a required msgdest.
	If there is a dangling msgdest, assume it is a clock.
- dest to other dest
	Each msgdest knows if it is part of a sequence. Points to previous one.
	If there is a dangling msgdest, assume it is a clock.
- clock msgdest knows itself, knows dependents
	- Dependents are either outgoing msgs triggered by clock, or
	incoming msgs that need clock to operate.
	- If any of the dependents are used, set up clock.
- object knows clock msgdest(s) and its dependents (similar to above).

Implementation for identifying sequence of clocks:
- Want to set up clock cycles: A B C A B C, X Y B X Y B.
	If B is the anchor point we can collapse the others:
		AY B CX  AY B CX
- Assume all clocks on given msgsrc on same class are the same. (Definition ?)
- Set up placeholder clocks. Each clock marches through and finds
	target types, and ranks of each target. Assoc array. Build cycles
	starting from each clock. collapse cycles.


reacclock --Process--> reac --submsg--> molecule
                            --prdmsg--> molecule

molclock  --Process--> pool --submsg--> reac
                            --prdmsg--> reac
                            --sumtotmsg--> sumtot_mol
			    --plotmsg--> plot


- Each msgdest could have a rank indicating sequence, wrt ReInit or last tick
- Each object should be able to say which msgsrcs are triggered by which msgdest
	- Connections to that dest are followed 
- A global scheduling table as in the current GENESIS.
============================================================================
19 April
For now I just need to get the implementation with clock-based Send and RecvNode
to work.

Make all clocks from start.
Connect each object automatically to its clock.
Propagate clock id to msgs on creation ?
Follow the msgsrcs back to the clock ?

Basic problem: if it is going to be clock-based, I need to be able to find
the controlling clock from the AddRemote call. Now ideally the addmsg call 
using the ids of the message will also be able to identify the parent
object.
- Clocks may not yet be formed at the time of the message setup
	In fact this is likely if we are going to do automatic msg-based
	scheduling. 
- 



============================================================================
29-30 April
Generic get: Call to Arg2GenericMsgDest of container with fid of field and
	return id.  It calls a generic returning
	assignment call using ArgnMsgSrc1 to set the provided return id.
Generic set: call to Arg2GenericMsgDest passing fid and data.
setfield /foo/bar /zod
which is equivalent to 
	/foo/bar = zod
would use a call to zod's container with zod's fid, specifying the
	container should extract the value of zod and call /foo/bar with
	a generic set msg passing in the value of zod.
showfield zod
is equivalent except that the target is the console shell/tty.
So all get/set/showfield type commands have this general form.

To implement this:
- Generic Get neets to be able to find the ptr and type/msgspec
	for each field. 
	If we provide a class-based/static set of msgspecs for each field...
	And a lookup function by fid...
	Which could default to a simple index of the array of msgspecs...
	Which could also have a namewise static map lookup...
	Or create the msgdest on the fly.
		If it is a msgdest in its own right (static msgdest)
			then there is aproblem with Parent()
		If we create the msgdest on the fly, then we need to
			set up a msgdest creation templated class with info
			about the field from fid.
			The kind of msgdest we create should:
			- have internal ptrs for parent
				(Similar to the Arg1GenericMsgdest)
			- Be able to look up data (a ptr for that too ?)
			- include or create a msgsrc to the target
			- Access the target's Set msgdest.
	BUT
	This would amount to a fat interface for each data class
	This would modify simple classes like double and int, messing
	up their simple operations (though would one do simple ops anyway ?)

Using pointers looked up by fids:
- Generic Set needs the Arg1GenericMsgDest to be created for the target.
	This needs a pointer for the data field. For evaluated fields
	there would have to be a specialization of the Execute operation.

- Generic Get creats 3 msg parts:
	the Arg1GenericMsgDest for the target Set operation; 
	the Arg1MsgSrc1 for the source generation from the Get src
	An Arg2MsgDest<fid, id> to trigger the creation of the 
	above two, and to call the Arg1MsgSrc1 with the value from the
	fid. This would typically use ExecuteFromStream with a pointer
	to the data looked up using the fid.

Using msgs only:
- Need to define Set msgdest and Get msgdest for each field. The
	Get msgsrc is an Arg1MsgSrc1 with a special Execute that takes
	the pointer to the data as the argument, essentially it encapsulates
	an access function.
	The Set msgdest is simple but tedious, has to be individually defined.
	The Get msgdest takes args of the fid of src, and id of dest.
	id of dest is used to look up the Set msgdest. fid of src looks up the
	appropriate Get msgsrc and passes it the pointer to the data.

	Q: If we are passing around pointers to the main data, why bother
	with this msg stuff for fields ?
	- Access Functions for evaluated fields
	- Type safety
	- Uniform, single interface.

============================================================================
1 May 2003
Summary and conclusions of yesterday's efforts:
- The interface to Set and Get will be via messages.
- Don't worry about the implementation. It could be internal pointers,
	a bunch of messages, access functions, or other things. The interface
	is all that is seen.
- The interface for all data and fields, including messages, will have the
	ability to look up the parent and identify the id of the selected
	field. This interface is provided by a wrapper template, not by
	the objects. There are no fat objects.
- The user has to define the 'thin' data objects, but also has to define the
	wrapper so as to access the objects with all interface functions.
	The wrapper will typically be defined using templates.
- The two initial kinds of wrapper will be single value containers, and
	array containers.

Looking up a data field from a msgdest, uses a calculation for the offset of
the data field. Works for looking up local data. Does not work for looking up
parent container.  Options:
	- If we use any messages in a class, the class has to be derived from
	a Messageable base class which knows how to deal with container
	lookups. This means a fat interface... Note that pure data classes
	have their messages handled by the container anyway.
	- Put all messages in the container. The messages could use the
	object_offset trick to find their parent container, and it would
	know how to look up various children. This would add a pointer
	storage for the data field in the message, but the same messagedest
	would hold info for all the targets if it were an array.



Implementing multi-postmaster test.

* Loads create postmasters for appropriate nodes as groups.
* Each postmaster is the parent of all objects under that group.
* Default node is node 0. Any object not created under /nodexx/ is assumed
	on node0.
* Postmasters automatically create bunch of clocks as children
* Postmasters pass on the Reset to their children. The equivalent to
	Entry::BuildClock is used for each clock in the postmaster to
	connect up children. The postmaster now has to maintain a 
	child list.
- Then deal with the messages going into the clocks.

Got the code to compile, now on to messages and so on.

============================================================================
2 May 2003
- How do we know which clock to use for receiving messages ? For now just
	assign a destcid and look up the clock based on that.

Compiled the code, core dumps instantly. This is because of the ugly hack
where we create dummy versions of molecules etc for finding the offset.
These dummy versions have a null postmaster parent.
============================================================================
3 May 2003
Fixed the hack. The fix eliminates an ugly call to look up the msgdests,
but forces one to make the msgdests public. 
Compiles, runs, crashes with enzymes but runs without giving any output with
reactions.

* Get it to run and give results
- Compile on Falooda, debugging may be better
+ Fix enzymes (available enzymes pending)
* Implement multi-postmaster test
- Deal with messages going to clocks for automatic separation of messaging.

============================================================================
4 May 2003

Got it to run and give results, at least for the reacs. Looking at enz.
Enzy now compiles and loads, but the run goes into nans probably because
the connectivity is flawed.

Found problem - major. All entries are doubled.

Actually turned out to be more subtle. The entry list was OK, but I was 
calling Rebuild twice on the postmaster and hence its clocks. This led
to two entries for each object in the clock tables.

Trying multi-postmaster version. mr.g seems to work, where there are
multiple postmasters but each is quite independent. multireac.g is
almost the same except there are plot msgs from node_01 to node_00.

Errors:
* The plots used to have a ReactionCid. However, plots do not need a clock
	at all. Should schedule them with Molecules.
* Even with out the plot error, there are errors going between nodes.
	This happens at the DoConnect stage. Fixed. There was a check
	for this but I had put a semicolon right after the if.
* AddNode is not being called for the clocks so there are not enough
	nodes.

Still getting core dump.

============================================================================
5 May.
Traced problem to issue with creation of node lists in clocks. I think
solution is to create the entire set as soon as the clock is made. The
issue of incremental addition of nodes should be handled much later.

Finally got whole mess to run. It required the ability to look up the
parent of the msgsrc. This has been done in an ad-hoc manner using an
unneccessary pointer storage in the msgsrc, which could be done with
a more sophisticated template and the use of object_offset.

Next: 
- analyze if messages going to clocks is the best way to get
automatic separation of messaging.
- Clean up startup messages.
* Clean up enzymes, esp available enzymes
+ Run serious test case.
- Hand over to Ravi.

============================================================================
6 May
Got the fb31b.g run to work. The problem had been in the volume scaling
of rate constants. Currently hard-coded to work with vols of 1e-15.

Implemented available enzymes as a separate class derived from enzymes.

The main thing broken now is the volume scaling for rates. It handles
fb31b.g painlessly but gets stuck with other volumes.

Next:
* Clean up volumes
- Clean up startup messages
- Test on large multinode model
- Automatic message separation

============================================================================
7 May
Fixed volumes
Chopped up fb31b.g into fb31_4node.g, this gives lots of errors of the form
Error: received wrong amount of data: 240 bytes, expecting: 304
Shortfall
64
-56
48
-48
80
16
-8
240
It looks more like the system is splitting up batches of messages and sending
portions to the wrong dest, as well as a simple mismatch of numbers.

OK, problem traced to sumtotal messages (molecule to molecule) which
croaks with the current hard-wired system of assigning to clocks. See
cyclic_sumtotal.g

To revisit the clock specification issue. There are three problems here,
not all of which have to be solved at once, but if they could be all solved it
would make it possible to do some optimization.
1. Which clocks are needed in a given simulation (minimal set)
2. What are dependencies for message passing, ie, which clock info
	must be Recvd by which subsequent clock on target node.
	We know from the above sumtotal example that a given src clock
	may have more than one dependent target clocks.
3. If different nodes have different clock configs, match the clocks.

A really stupid but simple starting point would be to require each class
to have its own clock, and to require that all messages emanating from one
clock category (e.g., molecule) be recieved by the same clock on all target
nodes before it could finish execution.

The optimal situation is to have each clock first verify all inputs received,
then execute all the outgoing PROCESS actions, then send off the data,
then deal with later local PROCESS actions. If we also include the possibility
of async messages, this implies that there should be a buffer of data
correctly slotted, waiting for receipt. Further, the outgoing data should
be collapsed so that the same info goes only once to a given node.

Implementation:
* Each clock sends info to its identical type counterpart on dest node.
* Dependent clocks on each node do a blocking query to the recvnode entry on 
	the incoming clock. This is set up entirely locally. The first time
	this query ensures that the data
	has been received, and calls the relaying msgsrcs to distribute
	the data. If a subsequent clock makes the same query, it returns
	1 immediately.
- Info is sent only once. The first time it sets up the src and dest stuff
	on the respective nodes, subsequent messages simply add another target
	to the relay msgsrc on the target node.
	We need a hash table or other quick way to look up sources from the
	script and check if their msgsrc has already been created locally.


current status:
Simple models seem to work now with the multinode thing, but the 4-node
fb31_4node.g runs but gives the wrong answers.

Idea: use the dest node classinfo to work out clocks and dependencies.

Current problem with the multinode fb31_n_node.g runs and replicated
in the test cyclic_stenz.g: Enzyme roducts on different nodes do not get 
any output from enzyme.

Even better test: enz_3node.g, enz_2node.g, enz_2node_b.g.
Interestingly, all these fail comprehensively.
There appears to be something wrong with the 2-entry message transfer
used by enzs. Haven't found it yet. Or is the enzyme a problem ?

============================================================================
8 May 2003
Various ugly bugs. One was traced to a bad assumption about sizes of arrays
as returned by sizeof. The other was traced to trying to get a volume
term from a molecule on a remote node. That has to be done through
clean 'get' calls involving the messaging system. Hacked it in for now, but
these volume lookups will have to be generally fixed.

OK, now the fb31_4nodes.g also works. Phew.
I am very keen to be done with this phase. Unfortunately things are still
quite ugly on two fronts:
- Info being sent multiple times to the same node.
- The clock mess, with relationships between different clocks and their
	target types being defined in an ad-hoc manner.

The second point is dependent on the implementation of hierarchy, so I won't
pursue it.
The first is probably relevant, but I am rather burnt out by the messaging
stuff and I think I can defer it for now. Saved this version as 
may08_2003_MSG.

So on to hierarcy. Should I use the current structure ?
	- Good working test including stuff for building and using hierarchy
	- Baggage

============================================================================
9 May 2003

Implementation
Hierarchy - DELETE msgs to children
Hierarchy ops -
	CREATE - Message to parent, argument is classid ?
	MOVE - Message to parent, argument is new parent ? May need 2 
		steps.
	COPY - Message to new parent, argument is original
	RENAME - Set message to name
	OSSIFY - Similar to MOVE
Messages - All are on container. Specific messages usually are able
	to do a zero-storage lookup of field, and are built into
	the container.
Function calls - Transient Message connections.
Field access - All fields are distinct message classes of the
	Arg1MsgSrc1 type for Gets, and Arg1MsgDest1 for Sets. The message
	classes embody an access function to go from the container pointer
	to the field. None of these messages is instantiated unless needed
	for a long-term message. For transient calls the class info should
	suffice. The container additionally provides generic GetField/SetField
	messages which do fid lookup for the individual field messages.
	- Perhaps the generic messages do fid lookup for all messages.
	- TransientExecute as an operation which triggers the Get/Set transfer
		without doing the mutual storage of message info.
		Can it be done without actually creating msgsrc/msgdest ?
		At present both need to exist. May need to exist to
		get info through postmaster.
		For simple classes like doubles, the Get/Set message holders 
		may as well exist all the time.
	- We usually do not need a generic message source, as it would not
		have a generic trigger.
		
Class info - Static info as part of class
Containers - Combinations of
	(parent, arrayparent) X (singledata, arraydata, solver) X (Comput coords, array coords, inherited coords)
Creation of messages - Must be generic. Message to source parent with fid
	of srcmsg and id of destmsg ?

Start by making the simplest possible: parent singledata withcoords, for a
	VariableMolecule.  Start out by doing a vanilla implementation 
	which does all these. Then we can decide how to do generic
	programming.
Template vs dual inheritance vs accessory class


============================================================================
10 May.
	Compiled stuff on falooda. Unfortunately it dies with the kholodenko.g
and fb31.g tests.

- Get it to work
- Shift it back to the main tree.
============================================================================
11 May 2003
Testing the falooda/gcc3 compatible version of the code.
- enz.g works when compiled on gajjak, fails to produce any output 
	when the same files are compiled on falooda.
- kholodenko.g now works when compiled on gajjak.
- fb31b.g now works when compiled on gajjak.

I think the error on Falooda arises because of differences in how the 
compilers handle the lookups of the form
&HiddenEnzyme::cplxmsgdest.
Yes. Confirmed. It was just a case of setting the correction term for the
	object offset lookups. In Gcc3.2 the term is 0, in 2.9x it was 1.
This ugly term is now there in the header.h file. With this done I'll
copy the GCC3.2-clean code from falooda back into the main tree on gajjak.

Saved the previous version of the tree in may11_2003_MSG.

Next: try to compile in the test code.

Generic msg definitions:
Need to be created each time
Need to occupy zero space unless used
Need to be accessed by lookup from fid.
	How about a templated function returning the appropriate class ?
Need to be accessed also by lookup from name.
	So need a templated class which generates fid internally and
	generates the both the function that generates the msgdest and
	the one that generates the msgsrc.

The deletemsg operation should do the appropriate thing for a generic msg: 
	deleting the entire msg, as opposed to a permanent msg: deleting
	only the src/dest entry.

============================================================================
12 May 2003
Slowly getting the wrapper and related stuff sorted out. It is ugly.

============================================================================
13 May 2003
Finally able to compile it all. Still need:
* Test case of creation and calling process operation
+ Replace molecules with testmols
- Creation function
- Deletion function
- Other hierarchy functions
- Message setup
- Class info ?
- Message verification
- Test it
- Streamline it.
- Clean up the gaps.


Tried to run it using enz.g, gets stuck somewhere.

============================================================================
14 May 2003
Finally able to create testmol and call process. Got seriously side-tracked
by a silly bug where I had string& fields, which of course got messed up
as soon as their assignee vanished.

Lots of interesting things halfway there, awaiting time to work on them

- field assignment stuff using messages needs a simple interface
* GetField from the Entry needs to be implemented, cleaned out of finfo.
+ Then I can run the model with the TestMol

============================================================================
15 May 2003
Ran the model with enz.g and reac.g. There is a horrible hack in the
code for getting volume of substrates. This needs to be changed to use
a clean field lookup interface. It prevents the big model (fb31b.g)
from running.

============================================================================
25 May.

The data part is supposed to be the heart of the class. The goal is to
be able to specify everything from here and let the system figure out how
to plug it in to MOOSE.

The Entry portion handles the container stuff.

The Wrapper is doubly inherited from Entry and the data part. It 
handles the messages. The goal is to generate this wrapper
automatically. There is no crtical need for double inheritance, and
a void pointer would do the job but with some costs in speed and storage.

For test purposes it is pretty important to figure out how to do clean
field access for volumes.

I have rather a muddle of things to do:

- Get the test cases to work properly
	- Needs volume fixup
	- Needs field access API
	- Needs clean API for accessing fields on the Entry, like cid.
- Message argument verification.
+ Shift other classes over to the newer fieldinfo stuff
	* Fix the enzyme dependence on the old VariableMolecule
	* Other molecule classes: Bufmol and Sumtotal
	* Reac
	* Enz
	Plot
	Clock
- Creation of object
- Handling class info

============================================================================
26 May 2003

Got the Kholodenko model working fully. It was volume in the reacs that did it.

Working on field access. It is possible to get at the appropriate message,
but there are still some issues:
- The process of tracking the message down is not parallel-clean.
- The simple 'Assign' operation is infeasible for general messaging because
	it requires type info and cannot therefore be virtualized.
- Even if it were feasible, the call to Assign is not parallel-clean.

So to do general field access we would have to create a local double and
pass messages. Or, have a message dest in the enzyme itself for assigning
volumes. The latter is far more sensible. 
- It could piggy-back onto the existing msgdest list ? Probably,
	provided we insist on the ability to handle such a message for
	all targets of molecules.
- It could be a once-off call, but triggered by each molecule tracking
	along its reactant targets. Similar to above.
- It could be sent each dt along with n ? Easy to do and wasteful. Nothing
	new to learn there.
- It could be a separate message. Simplest, cleanest, wasteful of memory.
- Store parameters in volume-independent manner so we don't need this.
	- Compartmental requirements anyway.


We already have the necessary stuff at hand with TransientExecute. This
	can readily become a virtual function of msgsrcs. I need to start
	messing with enzymes anyway to get the target vol message incorporated.
	So let's start shifting other classes over with an eye to templating.

Did the reactions. Compiled smoothly. Just worked. Amazing. Completely
eliminated old reactions.
On the molecule front there are still many ties to the old-fashioned 
molecules.

Random ideas before I turn in:
- Would it help to replace the specific wrapper with a generic wrapper,
	having instead a pointer to the data part ?
	- No, lots of specific info is still needed for the data part.
	- One could base it off something more specific than the Entry.
- Could the msgdestinfos, which currently need independent tiny classes,
	be replaced wholesale with a class taking an object_offset as a
	const int field ? All we really need is to add the offset to
	the provided pointer.
- Likewise, could the msgsrcinfos, which currently rely on some ghastly
	templating, be replaced with a similar class using object_offset ?
- Can I get rid of the static Handlers and use local Handlers ?
- I should make a separate table to map from old-style messages to new
	msgfield names, rather than munge them together in the fieldinfo.

============================================================================
27 May 2003
Trying to get the variants of the molecule in.

Managed to compile all, and the kholodenko model works. Still need to
replace enzyme complexes with testmols and to remove the oldstyme molecules
entirely from the code.

============================================================================
28 May 2003
Got rid of molecules entirely. It works. Now to clean up enzymes.
============================================================================
31 May 2003
In process of trying to get rid of enzymes.
Enzymes are now replaced by testenz. Kholodenko.g works.


This was my list. I've added a couple of items

* Replace fieldinfo classes with a single class that takes the offset
	of the msgdest.

* Get the test cases to work properly
	+ Needs volume fixup
	* Needs field access API
	- Needs clean API for accessing fields on the Entry, like cid.
+ Message argument verification.
+ Shift other classes over to the newer fieldinfo stuff
	* Fix the enzyme dependence on the old VariableMolecule
	* Other molecule classes: Bufmol and Sumtotal
	* Reac
	* Enz
	Plot
	Clock
- Creation of object
- Handling class info
- Field access through ids and through strings.



Trying to implement the first item, to replace fieldinfo classes. Consistently
dumps core when I try.

============================================================================
1 June.
Messy compiler stuff, figured out problem with dumping core. Can now replace
specific fieldinfo classes. 
Replaced for enzymes. This saves about 50 lines of code in each class. Cool.
Replaced for molecules and reacs too, it was straightforward and worked
with the kholodenko.g test model quite easily.

Now I'll archive this version as
jun01_2003_MSG.

and then clean out the eliminated specificmsginfo stuff, and rename the
testmol etc as molecule.h as it should be.
Done. After all this upheaval, it is under 3000 lines of code. This is about
10% of the old genesis/sim directory alone.

Field access:
Needs to:
	- provide an argument to set/get into. 
		- Create a temporary field of the appropriate type ?
		- Use existing fields in target object ?
			- Advantage that type info is already known.
			- Problem when we want to assign absolute values
			- Problem when we want to assign values from script
		- Use a buffer like the postmaster, with ExecuteFromStream ?
	- interface to the field access stuff via messages
		- The msgdest code would be fine if we could use an 
			ExecuteFromStream type call, as otherwise we need
			to typecast the message which is dangerous. But then
			so is ExecuteFromStream.
		- Provide a set/get class whose job is to form and clean
			up the messages.
		- Provide ascii conversion for message data. This should
			really be the job of the class.
		- Provide through the fieldinfo a static msgsrc and msgdest
			interface where the dest object is explicitly provided.
			This is separate from the existing approach of creating
			a special-purpose msgsrc/msgdest in order to 
			connect up to the field in a more permananent manner.
			This should ideally also be able to access 
			regular messages.
	- Work through postmaster if needed
		- Should follow if we get the main implementation. 



=============================================================================
2 June 2003

Make a message type that is designed to live on a GenericMsgList, refers
to the list for its parent, and 

Make a wrapper message type for the GenericMsgSrcList. The wrapper handles
the src, parent etc, and the internals handle the type and argument stuff.
This could be generic for all messages. Something like this already
applies for msgsrcs. But we need a separate class for the internals,
possibly using dual inheritance. Once we do this we can setup a
GenericMsgSrcList providing multiple internals with parent info and
associating each internal with a src/dest.

Each of the internals would be a pointer to a static msg type. This static
msg type could also be used by Set/Get where the src and dest are provided
on the fly.

Should the field list do the spoofing of individual messages...?
Field list is static for each class. 

Should separate out the issues of field management from assignment.
Assignment, like any other message, is a matter of being able to call the
message method without having set up the message dest/src link.


Want to make a SetMsg and a GetMsg that can be used both for standalone 
assignments and for regular messaging.

For regular messaging, it needs to be created with the target object as
	Parent.
For standalone assignments would like not to have to create it, but no
	big deal if we do, provided there is a clear deletion step to
	avoid memory leaks.
Non-object assignments: Specialized, would come into play primarily when
	doing scripting.

Make an Assignment class ? When it is created it creates the msgdest/src.

GetMsg can be generic because it is a zero-arg msgsrc, so Execute is typeless.
SetMsg is typed. 

Either: first implement generic messaging
Or: Implement standalone method calls using existing messages.
The msgdest needs ExecuteFromStream and ExecuteFromAscii for generic
standalone execution. The former is too messy and I'll bag it. The second
is reasonable but the ascii conversion should be the job of the class wrapper
handling T, not the messages.

* Implement simple messaging to and from data fields
	Trouble because of multiple inheritance confusing the system.
	I rely on pointers to figure out field addresses. 
	Options:
		*Grin and bear it. Work out correct addressing.
		Make the object a pointer or a field in the EnzymeWrapper
			Need array of msgdests and msgsrcs for array wrappers.
		Put msgdests back on object
			- Problem accessing parent.
		Add a data pointer in the msgdests.
			- 33% to 50% increase in storage for single messages.
			- No increase for array messages. May use ptr for
				lookup of target index.
			- All msgdests can be collapsed into a single array.
			- Simpler implementation (?). Still need object_offset
				to find parent.
			- Faster ? One less operation. Lots less considering
				dynamic_casts.
			- Unifies regular and array messages.
* Implement messaging between data fields and method-messages
* Implement standalone method calls for existing method-messages

Somewhat to my surprise I think I have worked out the correct addressing
mechanism. I still need to get the values right, though.

=============================================================================
3 June 2003
Fixed the values. That too was handled by the dynamic_cast operation.
Got the regular messaging as well as TransientExecute to work. Liberal 
use of dynamic_cast was needed. I would prefer not to do this as it slows
things down.

Also tested the messaging between data fields and fixed messagedests. Worked.

Implemented a really simple DoSet function using function templates. 
For DoGet I need to reorganise the msgsrcs to give primacy to the arguments
rather than the number of targets.

OK, got it to work. Many hacks have been incorporated and should be cleaned:
- Using parent ptrs in the msgsrc
- Dynamic casts all over the place rather than a single cast on creation
- The whole data pointer issue discussed above.

But the key thing is that field access is now easy. Next to see how it 
applies to postmasters.

Set is fine.
Get is not fine.

=============================================================================
4 June 2003

This was my list. I've added a couple of items

* Replace fieldinfo classes with a single class that takes the offset
	of the msgdest.

* Get the test cases to work properly
	+ Needs volume fixup
	* Needs field access API
	- Needs clean API for accessing fields on the Entry, like cid.
	- Needs clean API for accessing parent object. Can't just use ptr.
+ Message argument verification.
+ Shift other classes over to the newer fieldinfo stuff
	* Fix the enzyme dependence on the old VariableMolecule
	* Other molecule classes: Bufmol and Sumtotal
	* Reac
	* Enz
	Plot
	Clock
- Creation of object
+ Handling class info
- Field access through ids and through strings.

Class info:
Currently we have the following things  static:
	- cid deplist
	- int ndep
	- fieldlookup
	- nfields
Would like to add:
	- Creation function
	- Access by name
	- Author and help info
	- Hierarchy info

Starting on the class info to provide the above set of things.

=============================================================================
6 June 2003
About to start converting all cids to a scheme using cinfos. Saved current
version as

jun06_2003_MSG

This version handles everything up to and including kholodenko.g correctly,
and can also do the simple set and get functions. Doesn't yet do 'get'
cleanly through pure messaging calls; that may require id and name lookups.


Enormous number of bugs/incompatibilities cropping up as I march through
the classes converting to cinfo and introducing the Wrappers.
Postmaster: needs lots of stuff to get it to work again.
Plot: Needs to reexamine printing.
msgsrc: need a way of handling pointers or references to large things like
	strings. The problem crops up with the conversion to data streams,
	which ought to be done more intelligently in these cases.
clock: deplist is terrible.
enzyme: How do we create it without a molecule parent ?
	Actually, it should be independent to be a good object. Should not
	be using pointers to other objects at all.
Postmaster: Likewise with the clocks within the postmaster. They should
	be removed anyway and put on the relevant classinfos.


During initialization time, each cinfo should figure out common clock
dependencies and build a clock, providing it with sequence info. The clock
should be visible locally
and I need to figure out how to prevent it from being called multiple times.

OK, got the mess to compile. Lots of cleanup to do before it will work.

To do for this phase:
	- Fix dependence on pointers to sub-objects, for postmaster,
		enzyme, clock. Each should operate through msgs
		- postmaster:
			- Get rid of child clocks, figure out how to
			attach them to the classinfos instead.
			- Clean up the silly hierarcy of post/clock/sendnode/
			recvnode
		- Enzyme: The molecule parent is used for generating the
			name of the complex, and for setting up a REAC msg
			from the prdmsgsrc back to the parent enzyme.
			- Name is trivial to fix
			- The REAC return msg should be done by the script.
		- clock: 
			- Clean up child sendnode/recvnode
			- Create Jobs to order things a bit better.

=============================================================================
7 June 2003

Suppose each class wants to make its own clock, during the 
cinfo::InitializeClassInfo() call.
Steps:
	Make list of classes/clocks
	Order by dependency: 
	- Bubble sort. Problem is that the system is circular.
		Put all classes in order between 0 and 1 (circular.
	- Num sort
		Give A a number of 0
		If B depends on A, B = A + 1
		If A depends on B, B = (A - 1)

		Now suppose C is between A and B, i.e., A <- C <-B
		C = (A + B) / 2
		We first set C = A + 1
		Then we find that C < B
		So we set B = C + 1

		Suppose A <- B <- C
		then C is first 

	- Link list
		- Start with A pointing to self
		- Insert element before or after specified position
			- If no relationship, just put it at end of list.
		- If order is to be A C B E F D A...
		Rule is: B, C depend on A, B depends on C,
		F depends on C and E, E depends on B, D depends on F,
		A depends on E.

		// To start put everybody in alpha/numeric order. Don't
		// worry about what A depends on; it is the first in a cyclic 
		// seuqence
		A < B < C < D < E < F
		// B is already happy as it depends on A
		A < B < C < D < E < F
		// B is shifted behind C because it depends on it.
		A < C < B < D < E < F
		// C is already happy as it depends on A
		A < C < B < E < F < D
		// D shifted behind F for dependency
		A < C < B < E < F < D
		// E is already happy as it depends on B
		A < C < B < E < F < D
		// F is already happy as it depends on C and E
		A < C < B < E < F < D
		// And at this point we could collapse it: Merge any
		// neighbors lacking direct dependency. Here there aren't any.
		A < C < B < E < F < D
		
		This looks good. How about a real example:
		Enz, Molecule, Reac, plot
		where Enz, reac, plot depend on molecule; molecule 
		depends on Enz, reac, stim; plot may depend on stim.
		(Implies that for new things I should be able to
		bidirectionally specify dependencies.)
		E, M, R, P, S	// Start off randomly.
		E < M , R , P , S // Ignore position of E vs M as it is cyclic
		E , R , P , S < M // M depends on R and S
		E , R , P , S < M // R is happy as it depends cyclicly on M.
		E , R , S < M < P // P shifted back as it depends on M and S 
		E , R , S < M < P // S happy, both M and S precede it.
		ERS < M < P // Collapse E, R, S as they do not interdepend.

OK, this solution looks promising.
Earlier I had another example
	Want to set up clock cycles: A B C A B C, X Y B X Y B.
	If B is the anchor point we can collapse the others:
		AY B CX  AY B CX
	Dependencies: A < B, B < C, C < A;  X < Y; Y < B; B < Y.
	To start:
	C , A , X , B , Y
	C < A , X , B , Y  // Ignore C. Start with A, which is cyclically OK
	C < A , X , B , Y  // X is happy as it is below Y
	C < A , X < B , Y  // B is happy as it is cyclically below C and above A
			   // and cyclically below Y
	C < A , X < B < Y  // Y is happy as it is above X, and cyclic above B
	< AX < B < YC	// Collapse it. C moves around to join Y. 
	Note that this solution differs from the one I had, but it also
	satisfies all rules.

	D C A B: D o C; C o D; B < C; B o D; A < B; A o D
	D < C A B
	D , B < C , A
	D < A < B < C
	For the purposes of a qsort:
		= means the two things do not depend or depend cyclically.
		- means that A < B
		+ means that A > B
We seem to have ended up with the sorting solution.
Do the sort, and any pair that does not depend (not even cyclically)
can be collapsed.


As a step toward all this fancy stuff, implemented clockjob as the
driver of the clocks, redid the plots, and actually got some results
(even though they were wrong).
Steps:
	- Immediate
		- fix results
		- figure out how to use elements as first arg to Handle
			funcs

Remaining in this phase
	* Fix dependence on pointers to sub-objects, for postmaster,
		enzyme, clock. Each should operate through msgs
		+ postmaster:
			* Get rid of child clocks, figure out how to
			attach them to the classinfos instead.
			- Clean up the silly hierarcy of post/clock/sendnode/
			recvnode
		* Enzyme: The molecule parent is used for generating the
			name of the complex, and for setting up a REAC msg
			from the prdmsgsrc back to the parent enzyme.
			* Name is trivial to fix
			* The REAC return msg should be done by the script.
		+ clock: 
			- Clean up child sendnode/recvnode
			* Create Jobs to order things a bit better.
			- Do proper dt assignment from the main.
		
=============================================================================
8 June 2003

Working on cleanups of yesterday's massive overhaul. Now the enzyme stuff
works and the kholodenko model is OK, but all the dts have been hardcoded in.
... Now fixed the dts.
... Now working on object creation and simultaneously, object hierarchy.
	and simultaneously, bootstrapping formation of classinfos, and
	class inheritance.
	Amazing. Did framework for all of the above, and it worked first time.
... Now to actually use the element creation stuff
	Used it in load.cpp. 
	- Most things (not plots) are loaded properly.
	- The kholodenko model loads but gives the wrong answers, possibly
	a volume scaling problem.
	- The interface for setting fields is nice but inside it needs
	cleaning to avoid memory leaks.
	- Molecules have to be able to set an evaluated field, the mode. This
	is not possible in the current messaging/fieldinfo framework.
... Need to put in an interface to pathname.
... Need to make a base class of element that has the abstract virtual 
	funcs, as element itself is something with kids and can be
	created as a neutral
--- Need to test inheritance

Status and remaining stuff:
* Replace fieldinfo classes with a single class that takes the offset
	of the msgdest.
* Get the test cases to work properly
	+ Needs volume fixup
	+ Needs field access API
		+ Get
		* Set
	- Needs clean API for accessing fields on the Entry, like cid.
	- Needs clean API for accessing parent object. Can't just use ptr.
	* Fix up dt assignment using field access API.
+ Message cleanup
	+ argument verification.
	- messages use pointers to dest data. See 2 June, 9 June.
	- msgsrc avoid using parent pointers
	- msgsrc needs a way of handling pointers/references to large objects
	- Need to sort out lots of stuff for evaluated fields.
+ Shift other classes over to the newer fieldinfo stuff
	* Fix the enzyme dependence on the old VariableMolecule
	* Other molecule classes: Bufmol and Sumtotal
	* compute classes: Reac, enz, plot
	* Clock
	- Recvnode, sendnode
+ Creation of object
	* Use a named object creation routine.
	- Decide on ptr vs dual inheritance handling of data objects
	- Implement array wrappers
* Handling class info
	Currently we have the following things  static:
		* cid deplist * int ndep * fieldlookup * nfields
	Would like to add:
		* Creation function
		* Access by name
		* Author and help info
		* Class Hierarchy info
+ Field access through ids and through strings.
+ Clocks and scheduling
	+ Create clocks automatically from classes
	- Merge and sequence clocks
	- Create jobs of various kinds
	- Create scheduler
	- Use threads
- Revisit postmaster and SMP
	- Allow creation of multiple postmaster trees on each node, for
		testing, or set up MPI-based scheme to do the equivalent.
	- Build manually decomposed test cases
	- Provide for remote message passing
	- Enable SMP optimisations within clocks
	- Work on SMP optimisations in solvers
	- Enable once-off remote calls
	- Enable sporadic remote messages like action potentials
	- Enable moving objects back and forth
	- Synchronise clocks and class ids on different nodes
	- Enable automatic decomposition using skeleton model building
- Merge in parser(s)
- Rebuild the system
	- Merge in existing classes
	- Merge in solvers
	- Merge in graphics

=============================================================================
9,10 June 2003

Message redesign:
- Msgsrc:
	- Take no args. Internally provide the known args to pass to msgdest.
	- Use Type of args anyway, to be able to connect and verify msgdest.
	? Replace parent ptr with data ptr. Use offsets for parent ptr.
		- Are there cases where the argument needs to come from the
			parent ? e.g., name ?
			- Would it work to have different data ptrs ?
			- Would it work to have ptrs directly to the field ?
			- How about multiple fields ?
			- How about multiple fields, some on data and some
				on wrapper ?
			- Many of these can be solved simply by providing
				as template the arg lookup func(s) from the
				data reference.
		- Use offsets for >1 data slot. Or templated lookup funcs.
		- The data ptr means that array calls can use the same msgs.
		- Uses 1 extra memory location for non-array cases.
		- Possibly, marginally faster.
		- I don't always need field variables to send in msg args.
	? Replace parent ptr with offsets.
		- Handles all cases of wrapper and data fields
		- Uses less space
		- May need a little extra time ?
		- Can do a static lookup for fields, given the parent ptr.
	- Provide a static function that takes the (typed) data ptr as an arg,
		and does the field Get. Can't work with msgs with predefined
		data ptrs.
	- Dual inheritance for # of targets and for data execution ?
		- Problem with iterating.


- Msgdest:
	- Use data ptr.
		- The data ptr means that array calls can use the same msgs.
		- Uses 1 extra memory location for non-array cases.
		- Possibly, marginally faster.
		- Many msgdests need to access non-data fields, also msgsrcs
			which by definition are non-data.
	- Continue with object offset, but make F(element *)

- element: Should it use data ptrs too.
	- Avoid dual inheritance complications
	- Possible cost of extra storage
	- Possible cost of lookup time, 
	- Possibly offset by faster lookup from msgs.
	- Array and other containers simpler.
	- May not even need data ptr for classes too tightly tied to wrapper.
	- Update container as needed, e.g. go from element to parent to
		linkable parent (for multiple parents)
	: Use container outside of wrapper.
	- Ugh.
	- Would lose most of the savings for arrays. Bag it.


Trying to set up a new msgsrc file. Stuck on a static function for 
GetMsg. 
Do I really need it ? When getting a local variable to a data object:

DoGet(T ret&, id i) {
	if (!i->verify(T))
		return;
	// Arg1MsgDest0<T> dest(ret);

	ret = i->GetField();
}

When getting a remote variable to a data object:
DoGet(T ret&, id i) {
	if (!i->verify(T))
		return;
	// Arg1MsgDest0<T> dest(ret);

	ret = i->GetField(); // i points to postmaster; the GetField is on it.
		Internally it can look up field info or find where the
		target lives.
}

=============================================================================
11 June 2003
Working on path names. Implemented stuff, need to update the 
main so that we create the / and /kinetics object, need to update element
to provide element::Root().

Going full steam on path stuff. Many things need changing.
* cinfo bootstrap code
* Need to verify that element can handle kids. The base element cannot.
* Need utility function element::AdoptChild().
* Need to make derived class of element that can handle kids, a parent class.
- Need to work out about multiple parentage, as in hard links in Unix.
* Need to update Load.

Working on the load. Lots of headaches to do with Create function.
Currently stuck because the parent it finds is zero: load.cpp:41

=============================================================================
12 June 2003
Successfully got all of the above path handling stuff to work. We now have
a proper navigable element hierarchy. Kholodenko.g loads but gives the
wrong answer, as before.
Updated the task list from 8 June. Shifted it over to the STATUS
file as it should be updated in parallel to this file.

Specific target: Fix volumes. Needs several steps:
	- Message creation from molecule to reac and enz for vol
	- Update on RESET
	- Update when vol changes
	- Messaging fixes.
		- Should volume go along with Conc in each message ?
		- Can molecule/volume piggyback on the REAC target list ?
		- Likewise, can RESET/REBUILD piggyback on the clock msgs ?
		- Should I use a permanent message or do it dynamically ?

For the field msgdest and other rarely used msgdests:
Have an instance of the msgdest, derived, for example from Arg1MsgDest,
in the fieldinfo. Or create one on the fly.
This instance does NOT maintain 'personal information' and cannot execute
the regular Execute(const T arg) command because it does not know what the
parent element is. However, it can execute Execute(element* e, const T arg).

Given this, I can also make a lightweight wrapper for all rare msgdests,
to be stored in genmsgdest. Each DestWrapper is derived from an OrphanMsgDest
(I could use a pointer to the original, but it makes no space difference
and is messier). It also stores the src and the element pointer.

Conclusion of several days of intermittent design work:
* Update the Arg1MsgDest to provide a virtual Execute(element* e, const T arg)
	function.
- Update the msgsrc to provide a Piggyback(finfo* src, finfo* dest) type 
	function. This uses the Execute(e, arg) above.
- Update the fieldinfo to keep an instance of the OrphanArg1MsgDest type
	class, used both for the Piggyback and for once-off message calls
	and field assignment.
- Update the genmsgdest of the element so as to handle WrapArg1MsgDest
	for the rare messages.
- Replace all F(char*) functions for msgdest execution with F(element*)
- Completely restructure msgsrc 
	- Execute() function takes zero args, and instead uses
	T (F*)(element* e) internally to generate the args.
	- Note that the F can also evaluate the field on the fly.
	- Eliminate the parent pointer. It is now evaluated through offsets
	similar to those used in the msgdests.
	- Provide an Execute(element *e) function. This is used both for
	on-the-fly calls and for array msgs, when the same msgsrc is used
	in a wrapper.


Before launching off on this, I copied the functioning code over to 
jun12_2003_MSG.

=============================================================================

14 June
Massive message reorganisation in progress. Can't try to compile till all
done. Have redone the msgsrc.h and msgdest.h.

Slowly starting the compilation process. One headache is that when there
is dual inheritance from A and B, Class B cannot contribute directly to
functions of the same name required for class A.
Should find a way around this as the header files are already awful.
I vaguely remember that templates offer specialisation.

=============================================================================
15 June
Horribly ugly recompilation process. I wonder if the conversion of 
msgsrc::Execute to find its own arguments is worth it. The resulting
code is highly repetitive and inflexible. I should only use this approach
for fields.

OK, redid it and got the whole mess to compile. Of course it dumps 
core instantly. Let's design up the postmaster and the field assignment
stuff.

Doing this I see one major flaw with not having msgsrcs know their own
arguments: you cannot spontaneously call msgsrcs, but somehow need to
provide them with the arguments they want. This is a problem for
Piggyback calls too. I could derive a class from the ArgnMsgSrcn and specify
the arguments within that, but it would make an already complex system worse.

- Bidrectional message creation across postmaster:
	Here the system reads a script file on both the src and dest nodes.
	The file has enough info for the nodes to independently set up either
	end of the message on their local postmasters.
	- Faster, zero communication at the time of setup
	- Simpler to do with current scripts
- Source-side message creation across postmaster:
	Here the source node sets up its message and tells the destination
	node to complete the connection remotely.
	- More correct. No assumptions about how the message request is made.
	- Better for future scripts where the model is set up across nodes
	and the targets are not always known
	- Equivalent to above if the request is passed in the form of a 
		script line, either raw or semi-parsed.
	- Equivalent to sporadic messages below.
- Regular messages across postmaster: Arg<n>PostDest created to postmaster.
	This has a data ptr for the stuff to be transferred, which it fills.
	On the destination postmaster, a regular msgsrc can do an
	ExecuteFromStream to call the target msgdest.
- Sporadic messages (action potls) across postmaster:
	Send info along a separate channel (tag), the target polls periodically.
	Info consists of size, msg identifier, any arguments. 
* GetField calls from data field to variable: directly in fieldinfo
	- Templated function
	- Create a temporary msgdest (Arg1PostDest<T> works well).
	- Set up the return field to be handled by this msgdest.
	- Get hold of the msgsrc handling the field
	- Call ExecuteTarget(tempdest) on this src. It will internally validate.
* SetField calls from variable to data field: directly in fieldinfo. 
	- SetField(msgdest* , T arg) and SetField(elm, field, arg):
		templated functions.
	- Various levels of validation
	- Simply call the Execute(arg) function of the msgdest.
- GetValue calls from one data field to another field :
    	Call(srcelm, destelm, destinfo)
	- Only works with fieldinfos
	- Argument type checking
	- Fieldinfo looks up value
	- destinfo assigns target on destelm value.
- Once-off function/method calls: Call
	- Uses ExecuteSrc and only works with fieldinfo as src.
	- Argument type checking
	- Fieldinfo looks up value
	- Destinfo/destelm finds target msg (or creates one on the fly)
	- Calls Arg1MsgDest<T>::Execute(e, arg)
	- Multi-arg Call should also be feasible, need multiple fieldinfos.
	- Actually it is simple: Create a separate Arg0MsgDest1 to the src
		element that does the call.
	
- Once-off function calls across the postmaster: 
	- Call reaches postmaster, creates a suitable PostDest, gives it a
		data slot to put request into.
	- Postmaster sends info along separate channel. As before, target
		polls periodically. Info consists of 
		size, target identifier, arguments.
- GetValue calls across postmaster
- SetValue calls across postmaster
- GetValue calls from one data field to another, across postmaster


At the end of the day:
- The msgsrc and msgdest are taking shape.
- Field Set and Get are taking shape.
- I need to sort out the API for finfos, try to avoid ever making the
	msgsrc and msgdest externally visible.

=============================================================================
16 June 2003
Finally sorted out fieldinfos as well. In the process of getting the
mess to compile.

Got it to compile. Went through the obvious errors. Now it does not
complain anywhere, but does not produce any output either.

I need to check that some interesting dynamic casts in SetField are not
causing problems. Should just make some elements in main and try them out.

=============================================================================
17 June 2003
Type casting nightmare. static_cast seems to be causing problems.

Did a massive conversion for all msgdests to simply store their parent.
This, miraculously, worked right off. The Kholodenko model still has its
problem with volume. I suspect that a minor hiccup with the object_offset
was all the problem before.

To get the volumes out to the enzymes, it may be nice to have a
reverse-piggyback function which goes back to the source and requests a value.
The current piggyback over to the enzymes has the nasty drawback that 
all kinds of messages are present in submsgsrc.

Tracked it down. The enzyme does not yet recognize modes. The Molecule does.
Both of them need to assign it using a virtual field. Then much will be
sorted out.

Virtual fields worked easily, and MMenz works, but oddly the kholodenko
model is still refusing to work. I have tested a lot of intermediate-complexity
models, varied timesteps etc. In all cases the moose and the genesis outputs
are essentially identical.

OK, finally sorted it out. The km was being calculated at creation but not
later when I updated the enzyme rates. I have temporary hacked in an update
when the mode is set to internal, but this is not sufficient. I will need
to add further stuff to the assignment functions for all of k1, k2 and k3
to deal with this.

With this the messaging makeover is done. I need to refine scheduling and
revisit the postmaster, and these may entail small changes to messaging.
I may also want to retry the object-offset approach, if nothing else, for
checking if it speeds it up. All this will have to wait till I am back
from my July trips.

=============================================================================
18 June 2003
Copied the current version over to jun18_2003_MSG.
This version works, and has the current best implementation of messaging with
a lot of checks and features now incorporated. I do not think I will be
making any major changes to the programming interface now, perhaps some
implementation changes internally.

Wrote up a little document on the current design of MOOSE, called
MOOSEDOCS_JUNE2003

=============================================================================
2 September 2003
Finally starting to return to development.

Analyzing threading. I now plan to create threads on start of a simulation
job, rather than on each clock dt. The threads will proceed each using
the entire MOOSE tree for data, and do syncing after each clock phase.
The guarantee of independence within a given clock means that the entire
clock contents can simply be split up. There may still be minor overhead
for syncing the clocks, but I suspect the tradeoff will now occur at about
5-10 reactions rather than hundreds.

Options: Build separate clock tree, vs have microscopic (within messaging)
decision about which objects to call.
- Separate clock tree:
	Conceptually clean in that the threading is done explicitly.
	Faster: the identity of the thread is specified simply by the root
		of the clock tree, and then never needs to be looked up.
	Will need to rebuild clocks each time model is scheduled. However,
		we have to do this anyway. May also help to have this
		explicit since the # of available CPUs may be graded, or
		the model may need to be decomposed on different nodes.
	Clock creation messy: Earlier each class just built one clock. Now
		it has to go through entire sequence outlined in MOOSEDOCS,
		every time rescheduling occurs. At this stage some kind of
		count of scheduled objects has to be done to decide on
		node decomposition.
		Another problem is that when the user wants to explicitly
		specify scheduling, the system needs a reference serial
		schedule to base the actual sequence upon. Unless the user
		doing this has to also do the explicit parallelization.
- Same clock tree but multiple msgsrcs, one per thread
	Conceptually mixed: clock tree structure preserved but messaging
		messy, and the threaded flow of actions is obscured.
	Speed compromised as the correct msgsrc will have to be looked up.
	Will need to rebuild clocks each time model is scheduled.
- Microscopic threading: 
	Conceptually clean in that the clock tree structure is independent of
	node decomposition.
	Slower, but minimally so: Will have to look up the identity of the
		thread every time we enter a process loop for objects. The
		lookup should be a single function call.
	Clock structure does not change.	
- Single clock tree but distinct messages and msglists.
	Conceptually clean both as the message calling heirarchy is explicit
		and the clock tree structure is the same in all cases
		Note that the extension of this is to have the same
		clock as logically equivalent on all nodes.
	Fast (and clean): No lookup of current thread, it is passed in by
		the calling action.
	One-time clock rebuilding should be possible, but will need a way
		of accessing the internals of the messagelist in order
		to select subsets for each thread.
	Clock structure has two pulls: Want separate clock per target type
		so that threading load is even. But want lumped clocks
		for sending messages efficiently to other nodes.
		Worry about it later.

Looks like the separate clock tree is the way to go. However, a clear first
step is a cleaner scheduling implementation.

Sequence:
	- Clean up scheduling:
		- Create a scheduler
			- Sets up separate threads for each job.
		- Dependency search
		- Clock tree creation based on SMP and node availability
		- Irregular clock timestep sequencing. 
	- Implement SMP
		- Thread count logic
		- Separate clockjobs for each thread
		- Mutex or spinlock, whatever, to ensure that all threads
			sync after each clock.
		- Benchmark to see when it is worth splitting jobs
	- Implement parallelization
		- Job for managing MPI
		- For SMP, another spinlock, for the off-node messages to go
			in one batch
		- Lots of message mangagement logic.

=============================================================================
3 Sep 2003
Scheduler just has to be a parent. Each job looks after itself.

Scheduler: parent of lots of jobs.
If we have SMP, then there would be N clock_jobs, one for each CPU.
Clock_job: parent of timeseqs.
timeseq: Each has t, dt, and ordered list of clocks of same dt.
clock: Each has list of elms to be processed


=============================================================================
4 Sep 2003.
Scheduler or something like it can be an object set up to deal with the 
rebuilding of the schedule.

Still not sure of how to structure things. Both the explicit separate clock
tree and the unified tree have their attractions.

Step 1: will just implement an explicit build of a separate clock tree and
2 threads.

- Redid scheduling, permits multiple clock trees to be formed.
	Current implementation of scheduler should perhaps be one level
	deeper. Depends if we can allow a separate simulation on same tree.

- Implemented skeleton of threading. Yet to compile or test.

=============================================================================
5 Sep 2003
Compiled and tested first pass at threading.
Results are fine. Speed is rather disappointing. It goes
about 4 times slower than single threading.

For a 250 pool model with dt=0.0001, 1 thread  it sims 10 seconds in 17 sec.
For a 250 pool model with dt=0.0001, 2 threads it sims 10 seconds in 63 sec.

For a 15 pool model with dt=0.0001, 1 thread  it sims 10 seconds in 0.92 sec.
For a 15 pool model with dt=0.0001, 2 threads it sims 10 seconds in 4.0 sec.


Some nice statistics on thread context switching on RH7.1 (gajjak, single
CPU machine):

Model		npools	dt	runtime	cycles	threads	CPUS	user time
On gajjak, alternate sequencing of objects
kholodenko.g	15	0.0005	100	2e5	1	1	25
kholodenko.g	15	0.0005	100	2e5	2	1	35
kholodenko.g	15	0.0005	100	2e5	3	1	43
kholodenko.g	15	0.0005	100	2e5	4	1	55

On Gajjak, sequencing in blocks of objects, optimized O3
kholodenko.g	15	0.0005	100	2e5	1	1	10.4
kholodenko.g	15	0.0005	100	2e5	2	1	18.5
kholodenko.g	15	0.0005	100	2e5	3	1	25.6
kholodenko.g	15	0.0005	100	2e5	4	1	35

On Gajjak, sequencing in blocks of objects, optimized O3, tried later
kholodenko.g	15	0.0005	100	2e5	1	1	1.8
kholodenko.g	15	0.0005	100	2e5	2	1	5.8
kholodenko.g	15	0.0005	100	2e5	3	1	8
kholodenko.g	15	0.0005	100	2e5	4	1	13.5

On Falooda, alternate sequencing of objects
kholodenko.g	15	0.0005	100	2e5	1	2	1.85
kholodenko.g	15	0.0005	100	2e5	2	2	7.5
kholodenko.g	15	0.0005	100	2e5	3	2	8
kholodenko.g	15	0.0005	100	2e5	4	2	10

On dbc head, alternate sequencing of objects
kholodenko.g	15	0.0005	100	2e5	1	2	1.55
kholodenko.g	15	0.0005	100	2e5	2	2	5.8
kholodenko.g	15	0.0005	100	2e5	3	2	6.0+-0.5
kholodenko.g	15	0.0005	100	2e5	4	2	7 +-1

On Falooda, alternate sequencing of objects
ns3_merged2.g	235	0.0001	10	2e5	1	2	17.5
ns3_merged2.g	235	0.0001	10	2e5	2	2	62.2
ns3_merged2.g	235	0.0001	10	2e5	3	2	62.1
ns3_merged2.g	235	0.0001	10	2e5	4	2	68

On Falooda, sequencing in blocks of objects
ns3_merged2.g	235	0.0001	10	2e5	1	2	17.5
ns3_merged2.g	235	0.0001	10	2e5	2	2	38.7
ns3_merged2.g	235	0.0001	10	2e5	3	2	42.5
ns3_merged2.g	235	0.0001	10	2e5	4	2	47.6

On Falooda, sequencing in blocks of objects, optimized O3
ns3_merged2.g	235	0.0001	10	2e5	1	2	9.1
ns3_merged2.g	235	0.0001	10	2e5	2	2	29
ns3_merged2.g	235	0.0001	10	2e5	3	2	28.5
ns3_merged2.g	235	0.0001	10	2e5	4	2	36

Gajjak timings are suspect. I redid them with a stopwatch. There was a very
large system time, sometimes larger than CPU time.

Did some accuracy tests.
On a single node (gajjak) the output is identical for 1 to 4 threads,
confirmed by md5sums.

On Falooda the output is different for all #s of threads, and obvious
garbage for the 4 thread case.

Some slow and tedious debugging. Turns out that there is some rare error that
increases in frequency with # of threads on a SMP machine. The bug is very
rare for 2 threads, gets more common for 3 and 4.
Aha, managed to get the bug for a single CPU machine as well.
moose kholodenko.g 0.1 10000 4 | md5sum
gives a different answer every other time. Suggests something about the
logic of the system, rather than just the SMP, is the problem.

=============================================================================
6 Sep 2003
Looking for the problem, by simple printf debugging. Using Falooda
(2 processors) and 4 threads, monitoring dconc and conc on MAPK-PP in
kholodenko.g. Every so often dconc jumps to a somewhat large and implausible
value, rather close to conc itself. Looks like a pointer is wandering off 
during a context switch, but doing so in a way which doesn't just point
to some random part of memory but to another reasonable value.

Molecule ops during Process:
	conc += dconc * dt; dconc = 0;
	submsgsrc.Execute(conc) -> enz->s *= conc
	prdmsgsrc.Execute(conc) -> enz->e = conc
	plotmsgsrc.Execute(conc) -> currtime += dt; if (currtime >=nextt) ...

Enzyme ops during Process:
	pA = B = s * e * k3 / (s + km); s = 1.0;
	submsgsrc.Execute(sA, B); -> mol->dconc += sA - B;
	prdmsgsrc.Execute(pA, 0); -> mol->dconc += pA - 0;

Reaction ops during process
	submsgsrc.Execute(B, A); -> mol->dconc += B - A;
	prdmsgsrc.Execute(A, B); -> mol->dconc += A - B;
	A = kf; B = kb;
	


=============================================================================
7 Sep 2003
Tried recompiling on falooda to ensure that it wasn't some subtle effect of
libraries. The recompilation was entertaining in its own right, as the
new compiler version caught some errors that got past the older one on
gajjak. But the result is the same: rare and small numerical errors that
occur more often with more threads.

Clues:
	Happens more often with more threads
	Happens, but much more rarely, on single node machine.
	Happens with a low probability _during runtime_.
		- Is barrier working ? Early debugs suggest yes.
	Numbers jump by finite values, as if the arguments to a msg get
		changed from dconc to conc.

I think one possible problem is when 2 messages come in both trying to 
update a variable. For example
mol->dconc += B - A
mol->dconc += A - B
If another thread kicks in with the old value after mol->dconc has been 
updated by the first line, then the second line will get the wrong value. 
So I need to partition the contents of threads so that no thread
contains any msgsrc that may write to an identical msgdest.
	- Go through all msgdests for that timestep
	- Scan back one msg to find srcs
	- Put both srcs on same thread.
	- Scan forward from assigned src to find dests
This may also improve cache thrashing between two processors.

=============================================================================

8 Sep 2003
Clean up algorithm for thread assigment.

- Go through all msgdests
     ->-- Skip where dest is committed and all msgrcs accounted for
     |  - Identify cases where there are > 1 msgsrcs
     |  - Select a thread. Possibly the one with least occupants. Committ dest
     |  - Scan through all msgsrcs
     |          - Committ all msgsrcs to this thread
     |          - Scan forward from msgsrcs to additional dests.
     ------<----- Scan back from additional dests in recursive loop.
                - Return
        - Return
- Go back and fill in any missed out msgdests/srcs.
- Check if the thread distribution is reasonably even. May want to 
	reassign in order of decreasing size of unit.
- Reallocate objects on different threads to different pages of memory.

It will be interesting to see if commonly built models are easily decomposed
in this manner or if they are too highly connected.

Went through the Kholodenko model by hand. Turns out it is modestly connected,
but is still tricky to decompose. On clock 1 (reacs->pools) there are
three sets of 2, 4 and 5 entries resp. On clock 2 (pools->reacs) there are
three sets of 5 each. However, if the model were to use a shared
phosphatase even at each level of the cascade, or if it were to use
enz-complexes, then the whole thing would merge into a single set.
I think if we have pure reactive coupling there is no way to avoid
a completely interconnected set. Enzyme coupling with a unidirectional
reaction makes it possible to separate some pathways, probably. I should
frame the decomposition in terms of those few molecules/reacs which are not
going to give rise to full interconnectivity.

If all this analysis is correct (and I will have to verify the correctness
of the solution to be sure) then the design of the clocks will have to
be a little more sophisticated. Beyond the obvious and necessary decomposition
by dependency, we may have to insert extra clocks to break dependency
chains when we want to do threading.
Possibilities:
	- generically split inputs to a given object into two clocks
	Depending on connectivity, this should fragment most webs.
	- Keep pathways intact and on 1 thread. Target inter-pathway
	nodes for splitting between clocks.
	- Change code so that distinct inputs do not alter same locations.
	- Peeks rather than pokes

=============================================================================
9 Sep 2003.
Before launching into a complex scheduling test, let us verify that the
problem with the threads is indeed the dual input to an object from different
pools. I will test this using the existing approach by making a model that
does not have dual inputs. Since such a model will not do anything exciting
and the numerical error may be too small to see, I will provide an interesting
input through a table. The provision of a table is also a step towards 
getting the system to handle complex real simulations.


* Create table
* Load table
* Connections to table
* Build model using table
* Test threads using table.
Tested with 1 million cycles:
m3 threadtab.g 0.0001 100 4 > r4
m3 threadtab.g 0.0001 100 1 > r1
etc.
Works for 1, 2 and 4 threads. 3 thread run is slightly off. Prd1 is the culprit.
	Thing is that the 3-thread run is consistent from run to run. So it has
	something to do with the node decomposition.

OK, looked at the levels of the enzymes. See bar.g.
These have multiple values for the starting point of enz. Further, I get
the deviation for starting enz for nthreads=2 as well as 3, but the 
deviation for subsequent points persists only for 3.

=============================================================================
11 Sep 2003.
After much messing around, finally tracked down the problem  with the table
test to a missed initialization in molecules and enzymes. Now it works
identically for all #s of threads, on falooda (2 processors) or gajjak (single
processor).

moose threadtab2.g 0.0001 100 1 | md5sum
0b9cb7f9f1192cf847233f1ebd375b06  -

Now to return to the problem with the kholodenko model. Sure enough, it
still persists. As before, it is far more common on falooda, but can 
be persuaded to occur on gajjak if I try enough.

Trying to work out thread allocation.
Looks like I need an associative lookup (hash_map ?) to handle the list of
elements in the path for a given clock. This will both enable checks as to
whether a tracked down element is on the path and also filling in the
status of the element by its address.

I have the implementation done, but there is some strange compiler problem.

=============================================================================
15 Sep 2003.
Cleaned up most of the compiler errors, still have remaining the one 
where the 'find()' function elicits such problems.
=============================================================================
16 Sep 2003
Got compilation to work, by eliminating hash_map and replacing with map.

Need now to establish a general format for defining message dependencies. 
For example, PROCESS will typically call msgsrc::Execute() for several
msgs.
- All fields in principle can be tied to messages, so we need
	a way of following call sequences. In other words, which msgsrcs are
	tied within an object to which msgdests, and vice versa.
- A given msgdest can invoke multiple msgsrcs
- A given msgsrc might be called by multiple msgdests.
- We might want to be able to configure such linkages dynamically
	so that when you set a field something else happens. But this info
	has to be local, not shared within a class.

Implementation options:
	- NxN matrix where N is the number of fields.
		Easy to initialize statically
		A bit messy if either if we use indices or ptrs.
		Bit wasteful to traverse
		Symmetrical for traversal
	- Multimap
		Difficult to initialize statically
		Same messy problem of indices or ptrs
		Rapid to traverse one way, very slow other way.
	- Each fieldinfo has an array of inputs and another array of outputs 
		Messy to initialize statically
		Same messy problem of indices or ptrs
		Rapid to traverse both ways.
	- A string with dependencies that gets parsed when the cinfo is created.
		Easy to initialize statically
		Clean, implementation hidden
		Can make rapid to traverse either way.
		- Make on cinfo: Single place, cinfo can handle easily
		- Make on fieldinfos: Multiple places, cinfo can still scan
			through fieldinfos to build dep list. 

Make fieldinfo functions for finding dependence:
   fieldinfo::UpstreamElms(const element* e, Vector<element* >& elist) const
   fieldinfo::DownstreamElms(const element* e, Vector<element* >& elist) const
   fieldinfo::UpstreamElmsRecursive(const element* e,
   					Vector<element* >& elist) const
   fieldinfo::DownstreamElmsRecursive(const element* e,
   		Vector<element* >& elist) const

Also, to traverse multiple levels of dependence, need a back-lookup 
   function from a given msgsrc/msgdest to its fieldinfo.
   	finfo* element::LookupFieldInfo(const msgdest*) const;
   	finfo* element::LookupFieldInfo(const msgsrc*) const;
   	int fieldinfo::IsMyMsg(const msgdest*) const
   	int fieldinfo::IsMyMsg(const msgsrc*) const

Bonus: These functions can be used for traversing element trees too.

Steps
	* Get rid of old GENESIS hacks in fieldinfos. This should be in 
		load.cpp.
	* Fix load.cpp so it still works.
	* Put deplist on fieldinfos for msgsrcs called from each dest.
	* Put internal vector of inputs on fieldinfo
	* Put internal vector of outputs on fieldinfo
	* Put function for filling up these vectors, with the help of cinfo
	x Put in IsMyMsg on fieldinfo.
	x Implement msgsrc::MyFieldinfo, msgdest::MyFieldinfo.
	x Implement UpstreamElms
	x Implement DownstreamElms
	+ Implement ConvergingInputsToDownstreamElms
	- Print out thread assignment
	- Implement the thread assignment code.

	- Get rid of vestigial deplists in cinfo.


Current status: code compiles but dumps core.
=============================================================================
17 Sept
Revisiting algorithm for thread assignment. The current one requires too
much message traversing and identifying message types. Lets see if we
can do a simple iterative approach.

- Keep map of target elms. This could exclude elms which are not clocked.
- Keep map of src elms. 
- Iterate through all src elms
	- Assign a thread holder to the src, called srcthread
	- Iterate through all msgsrcs emanating out of PROCESS.
	- Get the thread id of the target elm.
		- If it is UNSET, set it to srcthread
		- If it is already set, merge srcthread and this thread.
			This means set a linker between the two threads.

- Iterate through all srcthreads.
	If they are linked, add to an existing threadlist
	If they are not, create a new threadlist


Implementation in progress.
=============================================================================
18 Sept 2003

Much messing around later, I have what appears to be a working implementation.
There is still the problem that it is overcautious. Any input to a target
elm is treated as potentially clashing, even though there are cases were
distinct inputs cannot affect each other. It is perhaps OK to use this
anyway to avoid cache thrashing.
Test 1: does the Kholodenko model decompose properly: OK
Test 2: does the big model decompose properly: Looks like it.  All in one lump.
Test 3: What happens if the big model is split between 2 clocks: Still
	all in one lump
Test 4: What happens if the big model is split between 3 clocks: Suddenly
	everything is in nice little pieces. Out of 88 in the path, 
	the max on one thread is 22.

Test 5: What happens for the ip3 model split between 3 clocks:
	Fails again. The horrible stuff with the ca-sequester kills it.

Test 6: What happens for the mega model (diffusion in 10 compts, 1350 pools):
	Fails again. 

Test 7: Repeat the whole lot using 4 clocks:
	Almost always works. There is one marginal case in the mega model
	and one in the IP3 model.


One interesting option: Instead of randomly splitting the path up, we
should start by splitting up the stuff as computed by the threading
algorithm for a single node. Everything in the big lump should be split
first. This may give more effective thread partitioning.

Next: Test out the actual thread assignment using the kholodenko model.
- Logic to decide if nthreads is silly
- Logic to decide if increasing num_clocks is silly
The above two are policy and I should not deal with it yet.

- OrderThreads should split up the model into different elists
	- Start with the largest lump, assign to a thread
	- Put next largest lump in next thread
	- Continue till all threads are full as close to evenly as possible.
- Use these paths to add to the clocks.
- Also look at implementing desired numbers of clocks.

Some design first.
The scheduler should examine the dependencies and figure out how
many clocks should handle each path, given the # of threads. It should
generate these results in a neutral manner and let the user decide or
apply a policy.
The scheduler then spawns a number of clockjobs, each corresponding to
a thread. The clockjob maintains a series of clocks to execute in sequence,
accounting for subdivisions of each path, as well as different paths.
Note that the same thread will be executing different subsets of the total
path at different times, and may even take over elements used on other 
threads at different phases.

The threadsched manages:
	- Calculation of thread decomposition
	- Handling policy
	- Generating sched for policy.
	- Paths for each clock, corresponding to nthreads * nclocks within
		a particular phase.

=============================================================================
19 Sept
Cleanup of threadsched and implementation of the critical routine for
assigning clocks. Still need to complete and test.

Got it all together, but it gives the wrong answers for 2 threads.

Next: Implement exp euler integration in chemical stuff.

=============================================================================
20 Sept 2003
Got the thread stuff working for the kholodenko.g model. Now need to
get the basic code working for bigger models so we can stress-test the
threading.

Fixed the problem with lookup of src vs dest messages. Still cannot handle
even nonscaf_syn6.g. Is it a dt issue ?
Doesn't look like it. Still get nans with a 1 usec dt.

I would like to sort out the errors
Aha. Regular enzymes give nans even with the kholodenko model: see k2.g.
Now I can track it down.

Saved this version of moose in its own directory as this is a good
reference point.

Fixed the problem, it was due to the changes in the field names. It works
for a single enzyme and for k2.g. Unfortunately the big models still fill
up with nans. Still need to track it down.

Possibly a volume problem.

Messing around, seems like the threading is also a little messed again.
I have the saved version, fortunately.
=============================================================================
21 Sept 2003
Ok, turned out that the threading had not been touched, but I had done some
cleaning up on the enzyme so that a set of messages suddenly appeared. These
were the messages pertaining to the complex. These messages are invalid anyway
for the kholodenko model, so I fixed it so that the complex is never created
unless the available_enzyme mode is set. The next problem was that the
removal of the enzyme complexes reduced the number of computed elms and
revealed a problem with the AssignClocks. Put in a failsafe option there.
Implemented a TEST.bat file in the testsuite. 
Current status:
Works for all # of nodes on kholodenko.g
Works for all # of nodes on kholodenko_explicit_enz.g
	Works for both the above on falooda too.
Works for only 1 node on acc4_1.6e-21.g
Higher # of nodes seems to hang at zero CPU load. Looks like a deadlock.
Fails for nonscaf6_1.6e-21.g : nans.

I've backed up the current state of the system in mus_21_sep2003.tgz.
Three main cleanups pending before I can declare the current version 
functional with SMP:
* Fix hang on acc4_1.6e-21.g
	This hung because it could not be decomposed cleanly. The fallback
	case was wrong, now fixed.
* Fix nans for big models
	Partly numerical. The rate on the stoch input to Ca needs to be 1
		rather than 100.
		The CaM module needs to be deleted. Tried extensive messing
		with it, but it causes problems even when [CaM] = 0
	May need to use exp Euler
- Fix volume scaling.

Then do some benchmarking.

After that I need to move on to parallel messaging
Then merge in parser
Then do backward-compatibility conversion of simple classes
Then do bc for hsolver and gsolver

=============================================================================
22 Sept 2003
Implemented the exp Euler. Piece of cake. Tested with kholodenko.
But the big model still gives nans. There is some other problem.

Looks like it may be bad vibes between the SUMTOTAL and other msgs
to the Ca_input. Yup, there is a possible clash in the messaging.
The SUMTOTAL message should override.

OK, now moose can tackle the bigger models without nans. Even mega.g.

Did a little benchmarking. Moose runs a tiny bit faster than GENESIS,
which is a bit disappointing. Profiled it, not much to pick at. The
most heavily called routine is MoleculeWrapper::HandleReacMsg and
there isn't all that much flab in this 2-line function! Anyway, cleaned it
out a bit by the simple expedient of creating and InternalHandleReacMsg,
and this speeded it up by another few seconds.

Tried to get the bigger models to go on multiple threads. Found a bug
in the thread calculation code. Leads to an issue with 
threadsched.cpp:31.
Can't concentrate.
=============================================================================
23 Sept 2003
Finally got a case where threading helps. Ran mega.g for a runtime of
10 sec on falooda.
It takes 46 seconds with 2 threads, and 66 seconds with one. All this is 
using the -g option, and using the 2.4.18-14smp kernel on a dual athlon
2100 MP. There is a similar speedup with optimisation: 33 sec vs 50.
For the 2-thread case it decomposes the molecules into 2 clocks
and the reactions into 4.  It looks like the leeway of having some asymmetry
was critical in making this work. The current default limit is 1.4.
There is a small discrepancy now with the output of these models, 
I think due to sumtotals.
The nonscaf6_1.6e-21b.g model (which is about 1/10 the size of 
the mega.g model) takes 26 seconds with 2 threads and 13 with one, in a
similar test.
Interestingly, the old scsim18 takes 40 sec for the mega.g model. Should
do profiling to figure out how to improve single-thread moose to this level.

- Sumtotals should be triggered by a separate clock, could be equivalent
	to the reaction clock.
- Fix RESETs and related phenomena
- Fix volumes at RESET
- Fix continuation loading of tables
- Numerically validate big models
- Numerically validate threading in big models
- Move onto parallel messaging.

Volume: Molecules should propagate out message using piggyback.
	Should be possible to do dynamically, without reinit,
	but between cycles of anything else.

REINIT:
	Molecules: conc = initialconc, A, B, C = 0, propagate out volume,
		propagate out sumtotals. Sumtotalled molecules set
		initialconc = sum, after all results are in, on a later tick.

	Enzymes: Set sA = k2, pA = k3 etc.

	reactions: Just call reaction::InternalHandleProcess.

	Plot: Zero out time

	Table: Zero out time

RESCHED:
	Nothing for these fellows. The scheduler has lots of stuff to do.



Implementing REINIT runs into a problem: when we use piggyback the system
wants a pointer to the desired fieldinfo. However, we don't know in
advance what fieldinfo to use. Piggyback is used both for calling 
resets and for more specialized things like volume and other updates.
The first case needs a general name-based lookup. The second case may
go faster with a precalculated lookup. From an interface viewpoint, it is
possible to make a lazy-evaluation fieldinfo that simply looks up the
actual field at the last minute. This avoids messing with any of the other
piggyback code.

Also need a way of selecting a path for elms with a particular field set.
In this case the mode of the molecule in sumtotal.

Implemented a lazy_fieldinfo class. Actually quite simple.
Now need to get molecule::Reinit worked out.

=============================================================================
24 Sept 2003
Reinit stuff finally implemented skeleton. Seems to correctly propagate
down to the molecules. Don't need it right now.

More important: Implement separate clock for sumtotals. Should have
one clock coming in to update the pool (PROCESS), and another to propagate
out the sumtotal values. The second clock would go into sumprocmsgdest.

This messes up the current version of FindDependencies, which uses the name
of the procmsgdest (in this case sumprocmsgdest) to build the dependency list. 
I also need a way of generating a list of elements using a field,
in this case the value of the mode of the molecules.

OK: Molecules need to send out updates at process time. This would have
to include molecules acting as sources of SUMTOTAL messages. So it would
be a problem to do the PROCESS for the sumtotal targets at the same clock.
Note that this also eliminates an extra outgoing message in the molecule.

The SUMTOTAL molecules now need to be updated on a separate clock, 
between the regular molecules and the reactions.

This may not need any further elaboration after all. We will have to
find a way of building an element list with rather fancy conditions.
Also need to change the update rules for molecules. SumTotal molecules
don't do any internal calculations during the regular process.

Lots of little fixes in molecule to get this set up.

Compiled. Runs but fails to work properly in ElistCompare. Seems like
it is getting garbage from the function GetField at line 147.

=============================================================================
25 Sept 2003
Need to clean up field access stuff especially for variables.
Currently:
- To get the value of a field:
	fieldaccess.h:GetField(T* ret, const element* e, const string& field)
		Makes a temporary msgdest, sets up ret ptr in it.
		Get the fieldinfo srcfield for the field.
		call srcfield with the temporary msgdest.

	fieldinfo.cpp:Call(const element* src, msgdest* d) const
		Gets the msgsrc s using GetSrc(src)
		Calls s->ExecuteTarget(d)

	The msgsrc s was of msgsrc.h::GetMsg type.
	In ExecuteTarget(msgdest*dest) it 
		does a dynamic cast for checking type, then 
		simply executes dest with its value.
		
	The messy point of all this is the GetSrc call:
		After typechecking it creates a new object of msgsrc.h::GetMsg
		class. This will need to be cleaned up later.

msgsrc.h also provides a very simple template function:
	 template <class T> T GetValue(msgsrc* m)
	 However the key function, Assign, is no longer defined.
	 Also it too requires the msgsrc, which is the sticking point above.

Reimplemented GetField (now called GetFieldValue) to use 
base_fieldinfo<T>. This excludes the use of functions for msgsrcs but does
allow the use of virtual and regular fields. Not clear yet how it would
handle parallel stuff, but we'll get to that shortly.
Also the SetField is still messy.

Implemented a cleanup for sumtotals. This is now more rigorous than in the
old GENESIS, because the sequence of updates is well defined. It has also
set up the system for clocking multiple kinds of sequences, not just proc
messages.

To get moose to handle production kkit models, still need:
	- Continuation tables
	- Volume fixes
	* Fixes for the fact that table inputs come as n.
	- Automatic conversion from SLAVE messges to sumtotals
	- Stochasticity
	- Channels

For now the key thing is to be confident that the threading is done right.
The testsuite has been most useful here and I have extended it all the way
up to the mega model. Then I'll move on to parallel stuff in the base code
as that is more fundamental. Along the way the production functionality
can be spruced up. 
The testsuite passes on all models. Saved current version  in
	moose_sep25_2003
On to parallelism.

The postmaster should send out stuff just after the incoming clocks have
cleared their barrier. This could be a subsequent clock. All outgoing
targets should be triggered off this.
Postmaster should set a barrier waiting to receive information during this
intervening clock. Each incoming node has to reach the barrier.
Each incoming node is on a thread ?

So we want a tree structure similar to that of a regular clockjob,
one for each of the target nodes. Alternatively we could use a 
single tree if there is automatic ordered target entries in an array.

After some discussion with Ravi, the design looks like this:
- The postmaster has a tree of node-handlers
- Each node-handler has a set of buffers coordinated with the clock array.
- Each buffer has space for incoming as well as outgoing messages.
- There are clocks inserted into the sequence to control the parallel msgs
	- After each set of clocks corresponding to a single path.
	- We try to split up the clock:
		1 Portion feeding INTO postmaster (to send data soon)
		2 Portion independent of postmaster (to complete it)
		3 Portion receiving input FROM postmaster (to finish the calc)
		- Note that this is probably at odds with the organisation
		for threading.
		- Note also that it is quite likely that a given element may
		be in both categories 1 and 3. We can only optimise for one
		at a time.
		So this refinement is probably premature.
	- We put a clock after each path set. This calls irecv for each node,
		and then isend for each node. The order is to avoid deadlock.
		- This clock does not need a barrier at the end. It leads
		straight into the next path set.
		- There is a 'wait' clock, preceeded by a barrier, at the
		point where we begin to need the off-node recvs. The clock
		checks through each of the postmaster/buffers using the
		blocking 'wait' call. This is not threaded.



		- Portions feeding into the postmaster are updated first.
			This goes through a barrier.
		- Then we insert a clock to trigger the incoming / outgoing
			message transactions
		- Then we continue with the other clocks in this path
		- Then we split
=============================================================================
26 Sept 2003

Implementation. One problem is that the scheduling/clock structure is 
set up after the messaging is complete. However the organisation of the
internode messaging at this point is highly dependent both on the node
structure and on the clocking structure. Clearly I want to avoid this
dependence, as the node structure may alter, targets may occupy different
nodes, and so on.
Options:
	- Make all the messages on the parent postmaster, and later shuffle
		them to the appropriate place.
	- Make an initial splitup of nodes, put messages on the appropriate
		node, later split up to the correct parbuf.
	- Make and delete messages once the final locations are known.
	- Make parbufs invisible and the node objects handle them internally
	- Have visible parbufs but they really only manage the clocked inputs
		and point back to the internal message lists on the node.
	- Update the parent pointer of the messages after they have been
		put onto the parbuf.


Let's just put the arrays initially on the node and continue.

Stages:
	* Get the incoming messages connecting to the parnode.
	Get the outgoing messages propagate between nodes, and then
		connected on the far side
	Get the kkit-parser to partition onto different nodes
	Make the parbufs
	Use Rebuild to partition the messages onto the parbufs.


Designing parnode and parbuf. I have decided that for now all messages
will be initiated from the src node and necessary info sent over to the
dest node, even if the message script is available on both nodes. This should
make it easier later to coordinate messaging.

Starting off on first compile. Too tired to think.
=============================================================================
27 Sept 2003
Compiled, got over assorted segvs, made model 
kholodenko_2node.g
to act as a preliminary test. Now need to get MPI going.

=============================================================================
29 Sept 2003
Need to handle Verify across nodes. Seems like best way is to take
	typeid(*msg).name()
as a character string uniquely identifying the msgsrc, and send it across
along with the messaging command, so that the far side can verify that
the target msgdest is compatible. Obviously it is not an issue with
Arg0Msgs.

=============================================================================
2 Oct 2003
Put in a msgdest::Signature() virtual function that is handled by the 
argument portions of the message. This means that the postmsgdest on the
src node will be able to generate a signature to be tested on the
target msgdest on the dest node, even before we make the postmsgsrc.

Put in msgdest::Signature() and msgdest::AddSrc()
The simulations are still going on. Stoch simulations all, as
far as I can see.
=============================================================================
7 Oct 2003
Struggling to compile new version. There have been some minor (I thought)
changes in msgsrc.h and msgdest.h but these have led to a flood of
compiler errors.
OK, it was a syntax error. Finally sorted it out in the definition of the
MakeSrc functions. Now there is a link error.
=============================================================================
8 Oct 2003
Gave up trying to compile it with the mutual dependencies of msgsrc and
msgdest templates. Redid it to eliminate the need for the
msgsrc* msgdest::MakeSrc(element *) 
call. Replaced using a single postmsgsrc that calls
virtual void msgdest::VoidExecute(const void* data) 

This also eliminates the msgsrc::ExecuteFromStream call and is more
efficent.

Some more cleaning up of functions is still possible.

Stages:
	* Get the incoming messages connecting to the parnode.
	- figure out why we seem to be making elms for both nodes.
	Get the outgoing messages propagate between nodes, and then
		connected on the far side
	Get the kkit-parser to partition onto different nodes
	Make the parbufs
	Use Rebuild to partition the messages onto the parbufs.
=============================================================================
9 Oct 2003

Design:

Initializing MPI and nodes
	Need to do from command line. The initial MPI command should
	load in the base stuff and create a postmaster. Postmasters
	should not be created at all for serial versions of the program,
	as they include OS dependencies. (Could have dummy postmaster).
* Loading objects
	The script file should be loaded on all nodes. Depending on 
	whether there is any postmaster at all, and on the identity of
	mynode, only objects pertaining to that node should be loaded.
	This is a policy matter and the script should provide directives
	on how to handle it, as well as a reasonable default. The current
	default is to load everything onto node 0 except stuff that is
	indicated by 'group' name to be on other nodes. I think a better
	long-term policy would be something like the automatic SMP 
	decomposition that analyzes the network and decides whether it
	is worth decomposing at all, and does a reasonable job if it is asked.
Loading messages
	Messages are done asynchronously on local nodes. Message info is
	queued up on the postmaster/parnodes. The first reset
	is a barrier: Nothing happens till all nodes get to the reset.
	See below for Completing messages.
Setting up schedule
	This is entirely local. The clock sequence is determined by the
	multiprocessing needs and the scheduling needs. Each clockjob is
	responsible for one thread. On each clockjob we have a number of
	clocks that depend on how the stuff is partitioned. We need an
	intermediate layer here to handle different dts:

	sched/clockjobs(threads)/clocktick(dt sequencing)/clock(list of targets)

	The clocktick also identifies a set of messages for the postmaster.
	In parallel mode, we insert two extra clocks on each clocktick
	(note that this guarantees barriers). The first is placed before any
	objects execute and sends a blocking call to the parnodes to ensure
	that all pending data has come in. It also triggers the non-blocking
	recv (if needed) for the objects that receive off-node info from 
	this clocktick. The second extra clock is placed after the
	clock that handles off-node connected objects, and triggers the
	non-blocking send operation on their parnode. This architecture
	assumes that we can partition sends and recvs and waits between
	threads.

	We need to update the clock subdivision code to preferentially put
	off-node messages into the first clock.

Completing messages
	Messages are done asynchronously on local nodes. Message info is
	queued up on the postmaster/parnodes. The first reset
	is a barrier: Nothing happens till all nodes get to the reset.
	Then the queued up message info goes out to target nodes and the
	internode messaging is completed. A barrier ensures all messaging
	is complete before going further. Note that this happens at all
	resets, though there may not be any queued message info.

Hierarchy on postmaster
	Postmaster: Handles all OS-specific parallel stuff. Provides
		interface for # of nodes, mynode, and data transfer.
		Is not created at all for single node simulations ?
	Postmaster-/parnode[for all remote nodes]-/clocklist[for all clocks]

Contents of message
	We only send message info for messages that were triggered on
	a given timestep. As the internode traffic is the limiting step,
	we condense outgoing data maximally. Should be a way of identifying
	synchronous messages and ordering them in a chunk so that this
	condensation can be done efficiently. The message info is like this:
	Header: # chunks. Each chunk: starting offset, target clock, size, data.

Comm infrastructure
	Messages go between specified methods, so we can pass any kind
	of information by appropriate messages. The only distinctions are
	between sync and async messages. The predefined internode messages
	include
	(Bootstrap: this is not really a message, but it sets up 
	communications)
	Message creation (from one postmaster to another)
	Object creation (Between shells)
	Script function calls (from one shell to another/parser)
	Object movement (between postmasters)


=============================================================================
10 Oct 2003.
Doing the implementation.
* Need to initialize the postmaster with the desired number of nodes for the
	current running configuration. Parnodes need to be created for
	each remote node.
* Set up most of the kkit loading stuff to recognize different nodes.
	The # and identity of nodes is now set in main.cpp. In the
	MPI case the postmaster will find this out from an MPI call.
- Need to now queue message info in the parnode so that later (at reset)
	it can assign it to a clocktick and send info out to the target node
	to complete the message.
- Need also to design in a trigger function in the postmsgdest, since
	we only should send stuff that has been triggered recently. Adds
	to the scheduling headache.

I seem to be able to set up the Postmsgdest but there is some problem
with the rest of the simulation as a result. Might just be the 
problem with the unfilled message to the diffusion reac.

=============================================================================
14 Oct 2003
Attempting to display the strings to be sent to the next node.
=============================================================================
15 Oct 2003
Got stuck on rather silly bugs related 1. to identifying the object (mycinfo)
and 2. a problem with the element::Path() function. Now these work and
the info stored in the parnode is accessible. 
- Next: redo the scheduling so that clockticks are known to the parnode.
- Then we need to have a way of finding forward dependencies so we can tell
the destination node when a message is due to be handled.

=============================================================================
22 Oct 2003

Immediate sequence:
	* Get rid of cinfo::deplists
	- Fix GetMsg for fields.
	- Build clockticks
	- Handle arriving messages by setting up the messages first, then
		simply going through dependencies of the proc. Anything 
		it depends on gets put into the appropriate list for the
		parnode receipts department. After all messages are built
		we put these postmsgsrcs onto the appropriate specialised
		clock to be inserted on the clocklist
	- Install MPI

=============================================================================
24 Oct 2003
See 7 March 2002:
Algorithm
	- At 0 time, all clocks are ordered by increasing dt and nextt is dt.
	- Each time a clock is called, it increments nextt.
		- if x.nextt > y.nextt, swap x and y. Ripple down list
	- Call first item in list.

This is fine, and works, and I could do it using clockticks that are both
children of the clockjob as well as pointers in the array that manages the
call sequence.
Problems:
	- I need a way of defining the scheduling from the script,
	and this includes specifying dts for clocks.
	- The entire clock structure looks like it is replicated for 
		each thread. Fine, but the single point of dt definition
		is lost.
	- In addition I should also handle the case of asynchronous objects
	like the gsolver.
		The async objects fit rather neatly on an individual clock.
		Some may need to talk to each other when their calculations
		are upset by an earlier async object.

=============================================================================
25 Oct 2003
The scheduling hierarchy may need some change. Current:

sched-/clockjob-/clock

Sched: Manages thread creation at a logical level (no
	system dependencies). Builds schedule. The details of this may change
	but the functionality has to remain.
	
Clockjob: Runs on a thread. One clockjob per thread. Has system dependencies.
	Could encapsulate dependencies elsewhere. Handles
	list of clocks. Multiple clocks may be created to handle a single
	clock tick. The whole lot live on the same clockjob, and there is
	no clear boundary between clocks for one tick and another. No way
	to do different dts.

Clock: Handles a list of targets. Half-hearted unimplemented attempt to
	handle dts. Not the right place for dts. The threading barriers
	operate between clocks but are implemented in the msg handling code.


Proposed:
sched-/clockjob-/clocktick-/clock
Major issues here with architecture. See 2 Sept 2003. The addition of
clockticks adds another layer to the tension between
the explicit subdivision of clocks between threads, and the desire to present
a single uniform interface. The previous solution had been to have the 
explicit handling, but present a uniform interface by using a single scheduling
call from sched. Here this interface would be stretched because the user
may want to control dts individually and on the fly.

Clockticks will maintain a wildcard list of targets as well as a dt to
associate with them. They also handle the interface to the parallel code.
The individual clocks sit on each clocktick.

Option 1: Single tree up to and including the clockticks. Now the clockjob
	becomes a single thread like the graphics and tty jobs, and within
	the compute job the threading is managed by clockticks. May even
	want another layer of objects to cleanly separate the clocks onto
	different threads. So the clocktick would manage multiple clockthreads,
	which would have the actual clocks on them. The clockthreads would
	be pretty similar to current clockjobs.
	Problem: The threads need to be set up low in the hierarchy, and 
	only once when the execution starts. 

Option 2: Parallel clockticks. Feasible but messy. Would have to 
	guarantee that any change to dt was shared. Turns out to be easiest
	to manage in terms of threading. Don't need a layer of clockthreads
	here.

Option 3: similar to option 1 but the scheduler actually sets up 
	multiple threads for the single clockjob in
	clockjobWrapper::StartThread. We need to execute the
	dt handling stuff on only one thread and then spread out to the
	other threads below the clocktick. In clockjobWrapper::RunThread
	the pointer will have to pass in both the thread number and the
	pointer to the clockjobwrapper.
	The dt handling stuff will be done just on a single thread.
	This should normally be done by checking for the return value of the
	barrier::Wait(). However:
		- The barrier is hit multiple times within each clocktick
		- It is hard to pass back info about the Wait return value
		- I would have to put another barrier in to ensure that the
			dt update was finished 

	One solution would be to create a special message from the zeroth
	clockthread back to the clockjob so that the update happens within
	the clock.
	The clockjobwrapper::procmsgsrc.Execute will call the clocktick for
	all threads, passing in the thread num to use. This threadnum
	determines which
	of the clockthreads eventually gets called. These clockthreads
	are the ones that do the BarrierExecute for the individual clocks.

None of these are nice. Somewhat surprisingly, Option 2 looks easiest 
from the viewpoint of threading. It would be nicer still to have a single-point
interface, but for now we'll use the info on thread0 to set up the others.

sched-/clockjob[one per thread]-/clocktick-/clock

Roles:

Sched: Manages thread creation for the jobs. Keeps track of # of threads
	available.

Clockjob: Runs on a thread. One clockjob per thread. Has system dependencies.
	Could encapsulate dependencies elsewhere.
	Manages dts and call sequence of the clockticks.

Clocktick: Handles list of clocks. Updated by clockjob according to dt.
	The dt and path for scheduling are maintained here. The 
	clocktick on thread0 is used to rebuild the schedule.
	Also handles coordination between nodes.

Clock: Handles a list of targets. The threading barriers
	operate between clocks but are implemented in the msg handling code.




Immediate sequence:
	* Build clockticks
	* Set up 'standalone' test for clockticks in relation to clockjobs,
		checking for sequencing.
	* Make a routine for wildcarding
	- Derive SMP sequence from clocktick info
	- Merge clockticks into SMP code
	- Test
	- Handle arriving messages by setting up the messages first, then
		simply going through dependencies of the proc. Anything 
		it depends on gets put into the appropriate list for the
		parnode receipts department. After all messages are built
		we put these postmsgsrcs onto the appropriate specialised
		clock to be inserted on the clocklist
	- Install MPI

Status:
	Working on setting up standalone test for clockticks. Seems OK.
	Implemented preliminary version of wildcarding. Haven't tested.


=============================================================================
26 Oct 2003
Status
	Wildcarding slowly taking shape. As usual it is a pain.
	Looks like it is working pretty well in its limited context. Now
	need to put in commas for separating parts of the wildcard.
	Done commas. Wildcards are now usable for setting paths.

	Did a little extra checking. There was a minor glitch with the
	wildcarding, now fixed. More seriously, there is an unresolved
	problem with the clocktick ordering where identical dts get
	sequenced bizarrely. Really need them either to be locked together,
	or to have a tie-breaker when dts are too close.

Saved this version in mus_oct26_2003.tgz

Looking now at putting in the SMP sequence. The code has been done
in a pretty modular manner, so it should not be a problem. However there
is an architectural point: what to do about different scheduled blocks ?
In the old code these were represented by the call 
	schedWrapper::AddClockToSchedule.
Each such block represents objects that do not share dependencies and can
therefore be scheduled together. While some of this can be worked out 
automatically, issues of relative dt also crop up. The obvious thing
would be to put them on different  clockticks which is also what had
been planned for the parallelization stuff. If we do it so, then each
clocktick handles its own chopping up of the path onto different clocks.
The key thing is to ensure that such equivalent dt clockticks work well
together without the ordering issues.
Two things happen:
	- Roundoff errors. Could be addressed by having the clocks as
		multiples of a base clock (usually integral)
	- Sequence inversion, esp. for identical dt. This condition should
		in any case be handled specially because of the inefficiency.

=============================================================================
27 Oct 2003
Options for fixing clocktick sequencing:
	- Have clockticks only deal with dt stuff, and clockscheds be
	  in between to handle path and the array of clocks for scheduling
	- Have multiple clockticks and sort out the problem with dt.
	- Have a handler class on clockjob (invisible to user) that controls
		all clockticks with the same dt. The handler also fixes the
		dt problem by using an epsilon fraction of the smallest dt.
		In all cases the clock with the smaller dt goes first.

Option 3 looks cleanest for the user. Wish I could say the same for the 
scheduling of threads.

=============================================================================
28 Oct 2003
Came at it with a fresh look, and fixed the clocktick/dt problems, without
messing with the structure of the code. Each clocktick handles a single path
and there can be multiple clockticks with the same dt. Also the roundoff
issue seems fixed. On now to SMP using info from individual clockticks.

Saved current version as mus_oct28_2003.tgz

Implemented most of the SMP rearrangement. Still need to clean up some
stuff in the threadsched. Will also need to handle deletes when I need
multiple rescheds. Haven't yet recompiled.

OK, put in most of it and begun compilation. Much testing to come.

=============================================================================
29 Oct 2003
Compilation finally worked. Need to fix up the way main calls the scheduler,
and then start major testing.

Got the single thread version to work. Now on to SMP.
Messy management of clockjobs by scheduler. Should get rid of individual
function calls and go to messaging.
Need to look up threads book to see how one can set off threads that dangle.

Current status: Slowly converting direct calls between sched and clockjob
into message passing. Currently want to use piggyback on the kidlist
to call Resched and Rebuild from sched to clockjob.

=============================================================================
30 Oct 2003

First pass of conversion of direct calls done, tested. Code smaller and
better, fewer dependencies on other objects and fewer direct calls. On again
to SMP.
This requires that we sort out the Copy operation.  Options:
- Use the default constructor foo(const foo& f);
	Update constructor as needed.
- Provide a virtual Copy(pa) function that uses the default constructor.
	The virtual function handles child creation as needed.
- Provide separate Copy and DeepCopy functions.


Working on this. Also made element a pure abstract base class.
=============================================================================
31 Oct 2003.
Still working on it.
=============================================================================
1 Nov 2003
Still working on it.
Design decision: Should p_element be a pure abstract class ? This would
save some errors later, and I could make a 'neutral' to be what it is
now in Genesis, that is, an initializable p_element. On the other hand,
any subclasses that are derived from existing elements have to worry about
the Copy() and MyCinfo() functions anyway. It would be nice to be able to
template the subclasses to guarantee the inclusion of these, but it might
put off other developers.

Got the stuff to recompile and run with the usual test, now to test out the 
DeepCopy.

Need now a way of going through all messages on an object. Obvious
approach is to use fieldinfos.

Two ideas, quite unrelated:
1.	Change fieldinfo so that regular fields are distinct from messages
	and it knows the difference. For sending messages to regular 
	fields have a msgdest like the VoidExecute that just dumps the value.
	For getting info from regular fields have a static msgsrc in
	the fieldinfo itself that handles the typing. Or something.

2.	Have a general way of tying inputs to outputs for any pair
	of messages. Simply need a lookup table from field#x to output field(s)
	whose messages are triggered by the event.


DeepCopy starting to work. There is something funny happening when I try
to hook up the messages: It looks like it goes to the same element twice
(or possibly more). So the messages pile up in the duplicates. Also weird
stuff in running it, though the original model should not be affected.

=============================================================================
2 Nov
3 ideas, to follow up.

1. 	Field sets and gets: Make a field msgsrc/msgdest class that
	has a ptr to the relevant fieldinfo and uses it to perform the
	conversion. On the element put the usual
	kind of vector to make a msglist of these fieldsrc/fielddests.
2. 	As before: Have a general way of tying inputs to outputs for any pair
	of messages. Simply need a lookup table from field#x to output field(s)
	whose messages are triggered by the event.
3.	Provide a simple interface for reverse piggyback, otherwise known
	as a return value for a message query.

If these are set up we should have tied up some of the big loose ends.
Remaining are arrays and the use of solvers, and parallel stuff.

Now to fix up the silly details with copy.


Copy seems to work but testing it throws up a bunch of other problems
	- WildcardFind is messed up.
	- Plotting is messed up.

There are some problems it seems with children and parents in the DeepCopy.
I think that there is a problem in p_element::WildcardRelativeFind,
where we traverse the tree more than once.

The STL unique function barfed. I wrote a little unique function that seems
efficient enough and finally, it all seems to work. Need to do much more
extensive tests.

OK, I am convinced. I changed the CoInit of MAPK in the copied version to 0.31
and compared the responses - there is a small and entirely sensible difference,
fairly good evidence that we have two independently functioning parts of
the model.

Next step to go through the SMP stuff and get it working.
Then final step before wrapping up for now: Try out the 3 ideas above.

Saved the current version as 

mus_nov02_2003.tgz

=============================================================================
4 Nov.
Stripped out the assorted test stuff, and got the code in shape to test the
threading. Easy now with the DeepCopy() function. Compiles and segvs very
nicely.

Finally seem to have the smp stuff going again. Lots of cleanups needed.
Doing test suite on falooda.
I also get the impression that the threading is faster on RH9 (my laptop)
than falooda. I would like to try the 2.6 kernel too.
Test suite runs failed for some of the models: errors in the SMP versions.
Interestingly the speedup is over 2 fold in the big model: a cache issue ?
Or is it whatever error is there ?
OK, a clue: the clock a1 does not seem to be made in some of the runs.

After an initial set of runs which looked good, many things fell apart when
the testsuite was run.
- Enzymes had gotten broken. This was a nasty bug. Turned out that the
	enzyme-substrate complex was not adopted by anyone and was therefore
	not scheduled. Cleaned up, works.

	Most of the models match with the original set of md5sums. Oddly,
	the kholodenko_explicit_enz.g does not. The order of the plots
	differs, for one. Fortunately, after sorting the file and doing an
	md5sum it matches.
- The clocktick a1 vanishes for higher thread numbers.
	This is confusing. On my laptop (RH9) there is no problem.
	On falooda (RH8) it loses the clocktick for 4 threads for one model,
	and for 2 or more threads for other models. On
	dilkhush (RH7) it loses different clockticks for different # of
	threads. I have checked, the threads are created _after_ all the
	clockticks are set up.
	- Checked that the dynamic cast isn't losing the clockticks.

Finally, with much printf debugging, tracked it down. I had not initialized
	the key parameter maxclocks. It was being set to zero in some runs.
	Now the SMP seems to be working, all thread counts give the same result.
	Doesn't seem to speed it up, but will try again with
	optimisation on. Also seems that someone else was bashing on one of the
	CPUs on falooda.

So, SMP is working again.

Some preliminary benchmarks from Falooda (dual Athlon 1800 MHz/2100+)
Linux version 2.4.18-14smp (bhcompile@astest.test.redhat.com)
(gcc version 3.2 20020903 (Red Hat Linux 8.0 3.2-7)) #1
SMP Wed Sep 4 11:55:37 EDT 2002

/newplot
/plotname kholodenko_15_molecules
1	1
2	9
3	12
4	45

/newplot
/plotname kholodenko_complex_enz_25_mol
1	1
2	17
3	32
4	88

/newplot
/plotname acc4_98_mol
1	2
2	12
3	20
4	28

/newplot
/plotname nonscaf6_199_mol
1	7
2	23
3	28
4	51

/newplot
/plotname mega_1990_mol
1	101
2	69
3	87
4	73

Another view: Consider the number of ops by each run vs # of molecules 
kho: 3 Mops
Kho2: 5
acc4: 10
nonscaf: 20
mega: 40

Approx # of molecules * time / dt.
/newplot 
/plotname 1thread
/xtitle nmol
/ytitle Mops_per_sec
15	3
25	5
98	5
199	3
1990	0.4

/newplot 
/plotname 2thread
15	0.33
25	0.3
98	0.83
199	0.87
1990	0.57

/newplot 
/plotname 3thread
15	.25
25	.15
98	0.5
199	0.71
1990	0.46

/newplot 
/plotname 4thread
15	.067
25	.05
98	.36
199	.39
1990	.54

Yet another view: All the above scaled by their performance on 1 thread.
/newplot 
/plotname 2thread
15	0.11
25	0.06
98	0.166
199	0.29
1990	1.43

/newplot 
/plotname 3thread
15	.0833
25	.03
98	0.1
199	0.23
1990	1.15

/newplot 
/plotname 4thread
15	.022
25	.01
98	.07
199	.13
1990	1.35

Interesting how horrible the big model is: It must be running out
of cache. Interesting directions:
	make the objects really tiny and efficient
	compare with more recent Linux kernels especially on SMP. 
	Relocate portions of models to avoid cache invalidation.

This version is saved in 
mus_nov04_2003.tgz

=============================================================================
From 2 Nov: 3 ideas, to follow up.

1. 	Field sets and gets: Make a field msgsrc/msgdest class that
	has a ptr to the relevant fieldinfo and uses it to perform the
	conversion. On the element put the usual
	kind of vector to make a msglist of these fieldsrc/fielddests.
	Problem is that the msgsrc/dest does not know what field it is, so
	all the Verify and related commands wont work.
	- Use the fieldinfo to make a virtual msgsrc/dest. As far as the
	user is concerned the msgsrc/dest exists. Well, this is already
	what we try to do. The problem comes because many functions use
	the msgs directly so we had to make an allocatable little class,
	and then there were memory handling issues.


2. 	As before: Have a general way of tying inputs to outputs for any pair
	of messages. Simply need a lookup table from field#x to output field(s)
	whose messages are triggered by the event.
3.	Provide a simple interface for reverse piggyback, otherwise known
	as a return value for a message query.
=============================================================================
8 Nov 2003
I have pretty much had to freeze development at the nov04 stage. The 
ideas above are OK but will need a solid block of time. Currently a minor
problem regarding compilation on other architectures. Looks like non-gcc
compilers cannot handle pointers to member objects as template arguments.
May need to put in some ugly reinterpret casts to deal with this.

=============================================================================
15 Nov
Looks like SetField could be cleaned up to avoid having to go through the 
msgdests, but instead use stuff from the fieldinfo.
Then I could put a very restricted set of operations to use GetSrc/GetDest,
where they are only used in actually creating message links. Thus avoid
memory leak issues and hopefully also fix some issues with compilation on
other platforms.
=============================================================================
22 Jan

Step back and look at fields and messages.
Four goals:
+ Replace field info with messages
- Put in relay table (to specify propagation from msgdest to ongoing msgsrc
+ Avoid fancy templates, so things will compile
- make it easy to understand and setup

Separate function calls from the msglists.

API
For the equivalent of the fields: These are info and static/class based things.
msgdest				msgsrc	

				Verify(msgdest *msg)
					- Just type info, can template.
Execute(T arg, element* e)	Execute(element* me, msgdestlist *dest)
	Subclass it or		Same options as msgdest execute.
	pass in templated func
	or pass in as arg
	during creation.
				DataSize()
					- Sizeof type info. Can template
				msgdestlist* MakeDest(element* dest_parent)
					- Type info. Can template.

Related fieldinfo stuff:
Name()
Call: same as the msgdest Execute.



msgdestlist			msgsrclist
				const element* Parent()
int Add(const msgsrc*src)	int Add(msgdest *dest)
int Drop(msgsrc* src)		int Drop(msgdest* dest)
				Execute()
				Execute(msgdest *dest)
				Piggyback(const finfo* srcinfo, const finfo*
					destinfo)
unsigned int NSrc()		unsigned int NDest() const
const msgsrc* Src(uint i) const	const msgdest* Dest(unsigned int i) const
Execute(T arg)
	(uses internal info to find elm.)
Deplist()

msgdestlist is derived from msgdest or has it inside.
	Problem with storage if it is a regular field
	Problem with uniqueness if it is a static field
	No point deriving it, as the derived part would be static but
	we want something unique to each object instance.
	Need a distinct class for each msgdestlist to work.
		Can't just template of class, as there may be multiples.
Have the field know how to do the execute for the msglist, and have only
	one kind of msglist?
Have the msgsrc store target element ptr directly, and some sensible way
	of scanning through target fields ?


Deplist
Each msgdestlist optionally
calls a linked list of msgsrclists
after it is done.
The linked list is maintained
whether or not the option is
used, since the msgsrc may be
invoked internal to the function.

Going recursive: the permanent msgdestlist and msgsrclists themselves are
fields. Each has add and drop and other operations, no problem. Internal
use can go directly.

Handling non-permanent function calls and field acceses.
Once-off field access
- Setting values: Use the msgdest::Execute. Simple.
- Getting values: Look up field, call special msgdest::Execute(dest) =>
		msgsrc::Execute(dest), passes the dest.
	Will need to provide a type-templated msgdestlist for handling free
	variables, otherwise provide a temporary field msgdestlist for elms.

Generic messages (permanent msgs between things that do not have built-in
	msglists)
- Generic msgdest table
	- Each entry has single msgsrclist ptr, msgdest ptr, way to
		lookup parent (possibly some special trick of table),
		deplist.
- Generic msgsrc table
	- similar, but no deplist unless we need reverse deplists.

Calls across nodes.
- Deal with later, already know it will fit in general context.

Building and testing.
Try standalone version for field lookups and ensure it compiles across
platforms.
Set up simple messaging, again ensure compilation.
Then bring in baggage.


=============================================================================
23 Jan
Decide if we should overload stuff to use a single fieldinfo with virtual
functions both for Get and Set.
- Sensible for fields
- Reduces number of base classes
- Verify gets confused because the field may not actually accept a message
	even if it is the right type (src to src)(But verify could be extended)


Distinction between msgsrcs which take a value out of object (eg field)
and ones which are strictly called with passed in args.
- Former need to look up their own value
	- Don't need templating
	- Don't need any further args to trigger.
	- Can be generically triggered using the reconfigurable deplists.
- Latter need to be able to rapidly pass args in
	- Need templating off msgsrclist
	- Could be more efficiently organized as directly doing the transfer,
		rather than having a fieldinfo.
	- Could in principle be set up using a specific msgdest that calls
		with the appropriate arg. Ugh.
- Can rather easily and cleanly have distinct kinds of msgsrclists for
	fields vs for general calls.
	- Piggybacks become very easy in either case
	- Clear separation good for handling reconfigurable deplists

Minor issue over whether to have fields for all msgsrclists
	- With field
		- need to define a dummy in all cases
		- In all cases the Send() will work though it may send default
		- Verify and Send will be uniform
		- Always need field storage
	- With separate templates
		- Never need dummy
		- Send() will only work for fieldmsgs
		- Need to uniquely verify each addmsg, Verify could be defined
			as a general op
		- Need field storage only for fields.
		- Faster, no indirection off the virtual function.

=============================================================================
24 Jan

Fieldlookup needs to become a class, and the lookup function encapsulated.
It is clear that at some point we will need derived versions of it in order
to handle different kinds of composite objects.
Actually this is already handled OK in cinfo.

To do:
	* Implement field access functions.
	- Decide how to control msg add, drop and other operations. Ideally
		each of these should go through the usual fieldinfo access
		system and be receptive to message-based execution.
		- If the cinfo is smart enough to interpret the type of
		the msg fieldinfo and magically create the appropriate
		hooks for access, this could be done using just a single
		entry in the fieldlookup table.
	- Implement generic msgdest/msgsrc. If this is not done then
		fieldaccess will need direct access to pointers of the
		elements and their fieldinfos. Won't work across nodes.


Prelim stage: compiled and linked, but did nothing other than creating
a reaction.

=============================================================================
25 Jan.

Prelim Set and Get working, quite clean. Still need to do the SetField
via msglists, but that will depend on an idea of what to do with the 
parallel code.

Stuff to do
+ Test msgdest and msgsrc in current system.
	* Implement molecule
	* Messages between pool and reac
	* Sending messages through a generic msgdest
	- Triggering generic msgsrc actions by relays. 
		Builtins are not allowed to be so triggered.
- Clean up msgdest/srcfieldinfo. It should automagically set up the 
	access functions rather than have those require separate fields.
- msgdst/srcfieldinfo should be subclassed separately so that they can be
	identified using dynamic cast.
+ Implement general msgdest and msgsrclists.


Random ideas
- Get rid of specific typed msgsrclists, use fields for this info.
	- Simpler structure of msgsrclists
	- Encapsulate all field information in fields alone.
	- Possibly slower.

- Provide fields for msgdestlist and msgsrclists not as part of the 
	structure, but as part of the msgdestfieldinfo/msgsrcfieldinfo
	- Would work at setup time, but not during runtime, when
		we don't refer to the fieldinfo.
	- Actually could work at runtime too as the fieldinfo would
		be known to the calling function.
		In fact the fieldinfo can be global unless it has a
		lookup func.
	- Minor overhead of 4 bytes if fieldinfo is stored on msgsrclist.

- Pass in field arguments at creation time for msglists. 
	- Wont work because then we would need to create the entire field info
	for each msglist, rather than just keep a pointer to a static
	version.

- Keep target element info, not destlist info, in msgsrclist, and vice versa.
	Will need finfo for target also to be stored in msgsrclist. Dangerous.
	Target-type-specific. Won't really work. Best to stick with 
	msgdestlist and msgsrclist pointing at each other and accessing the
	other info.

In progress: switching over to non-templated msgsrclists.

Partly works. Stuck because msgsrcinfo does not have the Send(elm, msgdestlist)
method. Needed to be able to do the GetField call.


=============================================================================
26 Jan.
Fixed up the msgsrcinfo stuff.
Moving on to setting up messages. 
* In order to do a Verify, I need to either pass the fieldinfo in along
	with the srclist, or to fix the srclist to be of a particular
	type by putting in fieldinfo into its creation func. Done.

+ Commands needed:
	* srclistinfo->Add(element* src, element* target, finfo* destlistinfo)
	* msgsrclist->Add(element* target, finfo* destlistinfo);
	* msgsrclist->Drop(element* target, finfo* destlist);
	- msgsrclist->Piggyback(finfo* srcfield, finfo* destfield);

- We have perfectly good Send(const element *e, msgdestlist* dest) syntax
	already for the msgsrcfieldinfo to use for the Addmsg function.
	Only problem is that the element is actually modified.
	Actually it would be too cute.
* We also have a good syntax Recv(...) for the msgdestinfo. Here it may
	make sense to treat this as equivalent to a 'Call' of the 
	same fieldinfo that the msgdestlistinfo stores.

Some rationalization of names.

msgsrcinfo should just be msgsrc. It is assumed that they are all finfos.
msgdestinfo should be msgdest
msgsrclist is OK.
msgdestlist is OK.
msgsrcfieldinfo should be msgsrclistinfo, and is the base class for the
	templated versions which are called msgsrclist_f
msgdestfieldinfo should now be msgdestlistinfo and msgdestlist_f

Fixed message passing, it works as shown by the simple reaction set up.
In the process, also fixed up the Call function.

Now to set up generic field msglists.
- Msg goes from a regular srclist to a field
- Msg goes from a field to a regular msgdest
- Msg goes from a field to a field
Latter two cases would also need the dynamic relaying to be useful.

Nearly working on this. Stuck with a coredump apparently because the
typecasting on the target field gets confused and mixes up the
Send function and the Recv function. Bizarre.
I suspect I will have to somehow establish a unique base class.

One option is to go back to the idea of common finfo with type specifier
and both Send and Recv as required methods.
	Cases:			Send()	Send(T)		Recv(T)	Recv(0)
	Regular field		OK	OK		OK	Plot(for relay)
	Readonly		OK	OK		-	Plot(for relay)
	msgdest			-	-		OK
	msgsrc			-	OK		-
	fmsgsrc			OK	OK		-
	msgsrc0			OK	OK		-	Relay
	srclist			Plot?	-		-
	destlist		-	-		Call.

There are 3 sets of classes right off finfo, each of which is an abstract
	virtual base class of the rest: field<T>, msgdestlist, msgsrclist.
	Later field<T> is split into msgsrc<T> and msgdest<T>

Before getting too creative here, lets try something... Changed the
base finfo to the msgdest.
Yes, the above suspicion is confirmed. It now works.


=============================================================================
27 Jan.

For today:
- Implement msgrelay
- Convert to common finfo
- Reorganize fieldinfo file into separate files.
- Optimize msgloop, use iterators
- Fold into big moose.

To do a msgrelay efficiently without the overhead of the extra pointer and
and the check to see if it is occupied, we should keep it as a separate
class of the msgdestlist. When a call comes to put in a msgrelay we need
to replace the msgdestlist with another version that uses the link list of
relays. This in turn requires retrofitting lots of existing messages, but this 
cannot be done for the compiled in messages.
For now, as always, do a compromise where the cleanness and simplicity of
the implementation takes priority. Just have a pointer in each msgdestlist.

Ravi has just compiled and tested the current version of jan27_2004_msgtest
on the Param using both gcc and the AIX compiler. Windows is in progress,
but it looks like the new code will work across platforms. We are in business.
Ravi has also compiled and run it now on Windows. Hooray!

Leave it with some silly compilation problems due to definition order, in
attempt to get the version with msgrelay to work.

=============================================================================
28 Jan.
Working on msgrelay. Messy. The target msgdest (as opposed to the msgdestlist)
has no way of knowing how to get to the relay to trigger the target msgsrc.
However, the target msgdest is all that is activated. Options:
	- Use a special target msgdest acting as a wrapper to the original,
		when a relay is added. 
		Nice. Doesn't incur any overhead either in space or in time.
		Could use a simple vector if I do have relaying, as the
		extra overhead is not likely to happen often.
		The fieldinfo, note, would now be element-specific rather
		than a static.
	- provide the original msgsrc with an extra zero arg msg going to the
	selected msgsrc. Problem is that won't work for func calls. Needs:
		- msgsrc can handle extra zero arg msg going to field
		- relayed msgsrc can recv incoming msg.

OK, the first option is quite elegant looking at first glance.
Now to clean up the ugly attempts so far at this.

The main remaining issue is how to do the verification. I will need to
devise another verification scheme for the new version of the finfo.
Could be as simple as:
CanRecv(finfo<T>* )
CanSend(finfo<T>* )


Working slowly through the last trial stuff before beginning this finfo 
switchover. The compilation is a pain.

Compiled. Fading. I think I have everything in place for relaying stuff
from Process to say a field that can then print... need to fiinsh
implementing tomorrow.
=============================================================================
29 Jan

Finally got relaying to work. Bodged together with ad-hoc type conversions,
necessitated because of the schism between finfo types. But proof of
concept passed. 

What I was going to do on 27 Jan was:
* Implement msgrelay
	This still needs some cleanup. In particular this shell game with
	nesting the original finfo is not a great idea, and should be improved.
* Convert to common finfo
- Reorganize fieldinfo file into separate files.
* Optimize msgloop, use iterators
- Fold into big moose.

=============================================================================
30 Jan.
Began work on new_finfo.
=============================================================================
31 Jan

New class hierarchy for fields.

msglist	<-	msgsrclist
	<-	msgdestlist

finfo	<-	field<T>	<-	msgsrc<T>	<-	fmsgsrc1
				<-	msgdest<T>
				<-	ffield<T> // Field access via funcs
				<-	pfield<T> // Field access via ptr
				<-	vfield<T> // Field is a regular value
	<-	src_field	<-	srclist_f<T, C>
	<-	dest_field	<-	destlist_f<T, C>

	Cases:			Send()	Send(T)		Recv(T)	Recv(0)
	Regular field		OK	OK		OK	Plot(for relay)
	Readonly		OK	OK		-	Plot(for relay)
	msgdest			-	-		OK
	msgsrc			-	OK		-
	fmsgsrc			OK	OK		-
	msgsrc0			OK	OK		-	Relay
	srclist			Plot?	-		-
	destlist		-	-		Call.


Can we map the msgsrcf and msgdestf more cleanly onto regular fields ?

Recv(args) -> msgdestf::Call(args). Calls a target function. However, could
	do better to call it directly.
Send(args) -> msgsrcf::Call(args). Calls all targets of msg. Reasonable.


Method			field	msgsrc	msgdest	msgsrclist_f	msgdestlist_f
AddRelay(msgsrclist*)	Relay	-	Relay*	-		Relay
DropRelay(msgsrclist*)	Relay	-	Relay*	-		Relay
Send(e, msrclist)  	OK	OK	-	OK if field?	-
Send(e, mdestlist)  	OK	OK	-	OK if field?	-
Send(T, mdestlist)  	OK	OK	-	OK if field?	-
Recv(e, T)		OK	-	OK	-		forward to field

* Needs to create a singlemsgdest to handle it.

So should the Add and Drop be done by the msgsrclist_f or by the
msgsrclist itself ? The msgsrclist_f does some additional typechecking which
is needed. Fine.


Doing the finfo conversion. Tedious. Done finfo.h, msgsrc.h, msgdest.h
and about half of fieldinfo.h. Still to do msgdestlist.h and msgsrclist.h

=============================================================================
1 Feb.
fieldinfo done.

Now cleaning up files and trying to compile.

Compiled, barfs when runs.

Now runs OK, but barfs if it gets a typo in  field name. Need to fix.
Simple fix.

What I was going to do on 27 Jan was:
* Implement msgrelay
	This still needs some cleanup. In particular this shell game with
	nesting the original finfo is not a great idea, and should be improved.
* Convert to common finfo
- Reorganize fieldinfo file into separate files.
* Optimize msgloop, use iterators
- Fold into big moose.

Also should now look at Automatic generation of wrappers.
Options
	- Each field needs 
		- simple_field
Auto			- stuff in .cpp. Easy.
	- Each msgdest needs 
		- destlist
Auto			- Declared in Wrapper header
Auto			- Initialized in Wrapper create func
		- destmsg
Auto			- Declared in Wrapper header as a static
Auto			- Passed in as arg to Wrapper create func
Auto			- Declared again in .cpp
		- destfunc
Need it			- Declared in Wrapper header as a func
Auto			- Passed in to destmsg declaration in .cpp
		- destlist_f
Auto			- Initialized in .cpp
	- Each msgsrc needs
		- srclist
Auto			- Declared in Wrapper header
Auto			- Initialized in Wrapper header
		- srcmsg
Auto			- Sometimes declared globally, if not declare here..
Auto			- Initialized global decaration
Auto			- Passed in as arg to Wrapper header for srclist
		- srclist_f
Auto			- initilized in .cpp

Other things:
			Copy()
			Cid()
			Delete()

So it looks like most of the wrapper could be automated. Templates seem
too complicated to do it.

=============================================================================
2 Feb
Confusion on the CanSend/CanRecv/Verify/Relay front. Let's be systematic.

			Lookup	Take	Accept	Relay	Relay
			by self	Arg	arg	trigger	target
Cases:			Send()	Send(T)	Recv(T)			Notes
field0			OK	arg0	dummy	OK	@ OK	Also need
								msgsrclist
field1<T>		dummy	arg1	dummy	OK	-
field2<T1,T2>		dummy	arg2	dummy	OK	-
func_field<T>		OK	arg1	OK	OK	OK
simple_field<T>		OK	arg1	OK	OK	OK
ret_field		OK	arg1	OK	OK	OK
dest_field		dummy	dummy	dummy	?	?	
destlist_f<T, C>	dummy	dummy	dummy	?	?	Has field ptr,
								might be usable
src_field		dummy	dummy	dummy	?	?
srclist_f<T, C>		dummy	dummy	dummy	?	?	ditto
msgdest0		-	-	arg0	OK	-
msgdest1<T>		-	-	arg1	OK	-
msgdest2<T1, T2>	-	-	arg2	OK	-
msgsrc1<T>		dummy	arg1	dummy	*	-
fmsgsrc1<T>		OK	arg1	dummy	-	OK
msgsrc2<T1, T2>		dummy	arg2	dummy	-	-



@ Looks like a relay target needs to include both a msgsrc and a msgsrclist.
For generality could also permit piggybacking, where it would need a msgdest
to match the msgsrc. Just to round it off should permit a function call,
either a builtin or a custom one.

* I need to be able to make dummy msgdestlists with zero args to handle 
relaying without any pre-existing msgdest. One option would be to put the
targetted msgsrc directly on the msgdest. Other option is to provide a
dummy field0 target like zminfo for a generic msgdest, for use in relaying.

- Eliminate option to recv without args.

For verification: CanSend() is true if (Send() is OK || Send(T) is OK)

For func_field<T>
CanSend(finfo* f) {
	return dynamic_cast<field0 *>(f) || dynamic_cast_<field1<T> *>(f)

			
		CanSend()		CanRecv(T)	Relay
Cases:		field0	fieldn<T>	fieldn<T>	Trigger	Target
field0		1	1		#		#	1
field1<T>	0	1		#		#	0
field2<T1,T2>	0	1		#		#	0
func_field<T>	1	1		1		1	1
simple_field<T>	1	1		1		1	1
ret_field	1	1		1		1	1
dest_field	0	0		0		0	0
destlist_f<T, C> 0	0		0		0	0	
src_field	0	0		0		0	0
srclist_f<T, C>	0	0		0		0	0	
msgdest0	0	0		1		1	0
msgdest1<T>	0	0		1		1	0
msgdest2<T1, T2> 0	0		1		1	0	
msgsrc1<T>	0	1		0		0	0
fmsgsrc1<T>	1	1		0		0	1
msgsrc2<T1, T2>	0	1		0		0	0

# The recv doesn't do anything, but could be implemented. Would be useful
for triggering relays, but if it isn't to do anything should perhaps be done
in a specialized way.

Overall: 
- CanSend(0) is equivalent to being a Relay target.
- CanRecv<T> is equivalent to being a Relay Trigger.

Revisit relay goals.
- Trigger changes in local and remote object following value changes.
	- simple_field->send self out.
	- func_field->recalculate stuff -> send assorted fields out.
	- Alter geometry -> Send changes to graphical things. (builtin ?)
- Monitor values, eg., plot
	- Plot->dummy msgdest->desired field out
- Overlay extra functions on regular operations
	- Process computes middle-compartment Vm -> sends value out
- Handle extendable messaging.
	- Pool changes its coords and vol in response to a pressure -> Passes
		pressure on to next pool

Some common attributes: 
	- Can always think of in terms of sending out one or more fields.

class rinfo {
	const msgsrclist* srclist;
	const finfo* srcfield;
	const finfo* destfield;
	const moosefunc func; // func(element *e, const finfo* srcfield)
}
relay(const T* orig, rinfo& target, bool do_drop);


- Cleaning up relay to handle additional parts of arguments.
- Still to clean up CanSend and CanRecv.
			
		CanSend()		CanRecv(T)	Relay
Cases:		field0	fieldn<T>	fieldn<T>	Trigger	Target
field0		1	1		#		#	1
field1<T>	0	1		#		#	0
field2<T1,T2>	0	1		#		#	0
func_field<T>	1	1		1		1	1
simple_field<T>	1	1		1		1	1
ret_field	1	1		1		1	1
dest_field	0	0		0		0	0
destlist_f<T, C> 0	0		0		0	0	
src_field	0	0		0		0	0
srclist_f<T, C>	0	0		0(?)		0	0	
msgdest0	0	0		1		1	0
msgdest1<T>	0	0		1		1	0
msgdest2<T1, T2> 0	0		1		1	0	
msgsrc1<T>	0	1		0		0	0
fmsgsrc1<T>	1	1		0		0	1
msgsrc2<T1, T2>	0	1		0		0	0

Src		Possible targets
field0		msgdest0
field1<T>	msgdest1<T>, func_field<T>, simple_field<T>, ret_field<T>
func_field1<T>	msgdest1<T>, func_field<T>, simple_field<T>, ret_field<T>
simple_field1<T> msgdest1<T>, func_field<T>, simple_field<T>, ret_field<T>
ret_field1<T>	msgdest1<T>, func_field<T>, simple_field<T>, ret_field<T>
dest_field
destlist_f<T,C>	
field2<T1,T2>	msgdest2<T1, T2>
src_field
srclist_f<T,C>
msgdest0	
msgdest1<T>
msgdest2<T1,T2>
msgsrc1<T>	msgdest1<T>, func_field<T>, simple_field<T>, ret_field<T>
fmsgsrc1<T>	msgdest1<T>, func_field<T>, simple_field<T>, ret_field<T>
msgsrc2<T1,T2>	msgdest2<T1, T2>


Slowly working through Verify stuff. Above tables suggest simpler approach
may work well. 

=============================================================================
3 Feb.
Provide 2 funcs: CanRecv() is a func without any args, just says if class is
able to handle incoming msgs. Verify(finfo* f) works at 2 levels: Checks
first that f is of a matching type to current class, and then checks
CanRecv() for f. Not enough. Incoming data is the one that needs specificity

Seems the verification stuff is being asked to do too many things.
- Handling verification for messaging. The only extra stuff here from earlier
	is that not all target fields can usefully receive funcs. In principle
	multiple inheritance could deal with it all cleanly, in practice the
	number of intersecting combination is so messy that we may as well do
	it this way.
- Deciding if a given field can send messages. Actually all but msglists can.
- Deciding if a field is a src_field or dest_field to manage msglists.
- Deciding if a field that can send messages can look up its own data. Need
	if we want it to be a relay source.

CanRecv(finfo* f) determines type of incoming fields, also knows internally
if it can handle receives at all. As there is only a single argument type
permitted for the receiving func, this is simple. Actually, should split into
CanRecv() and IsA(finfo* f) (below).

IsA(finfo* type) is self-explanatory.

CanLookup(): Can find its own args, hence can respond to a Send() call.


Let's see if we can deal with relay goals using messages creatively.
		Add a generic message from a msgdestlist to a msgsrclist
		with the field ptr/name as argument. The msgdestlist calls
		Send() as soon as it completes its local calculations.
		- Could even pass in its own args. Great for debugging.
		- Cannot respond to once-off Call operations if they
			dynamically make a msgdest_f.
		- Likewise, cannot respond to SetField.

- Trigger changes in local and remote object following value changes.

	- simple_field->send self out.
		- Create msgsrclist, then send msg to it requesting value.
	- func_field->recalculate stuff -> send assorted fields out.
		- Create msgdest that changes values. Create destlist to
		trigger changes.  Create msgsrclist to report changes. 
	- Alter geometry -> Send changes to graphical things. (builtin ?)
		- Same as func_field
- Monitor values, eg., plot
	- Create msgsrclist from plotfield to plot. Send message from
	plot process msgdestlist to this msgsrclist.
- Overlay extra functions on regular operations
	- Process computes middle-compartment Vm -> sends value out
		- Create msgdest that does extra functions. Create destlist
		for it. Create srclist for middleVm, connect this to targets
		for middle Vm. Send message from Process dest to this destlist.
		- Create separate func object that does extra functions. It has
		its own destlist and output options. Send message from
		Process destlist to the destlist of the func object.
- Handle extendable messaging.
	- Pool changes its coords and vol in response to a pressure -> Passes
		pressure on to next pool
		Similar to above, except that the destlist can be triggered
		externally.

- To handle the issues with SetField and Call above, the thing to do is to
	make a new func object with the same name as the target field, set
	up the messaging. All calls to SetField will now be directed to the
	dummy, and whatever redirection is needed can be done.

Well, this looks even better than relays. Further, it keeps the API uniform.
			
		
Cases:			CanRecv	CanLookup	
field0			0	1
field1<T>		0	0
field2<T1,T2>		0	0
func_field<T>		1	1
simple_field<T>		1	1
ret_field		1	1
dest_field		0	1 Send0 as well as msg args
destlist_f<T, C>	0	1 Send0 as well as msg args
src_field		1	If passed in field CanLookup.
srclist_f<T, C>		1	If passed in field CanLookup.
msgdest0		1	0
msgdest1<T>		1	0
msgdest2<T1, T2> 	1	0
msgsrc1<T>		0	0 Should be deprecated, as field1 does it all.
fmsgsrc1<T>		0	1
msgsrc2<T1, T2>		0	0 Should be deprecated, as field2 does it all.


OK, before implementing I should get the current version to compile and then
save it.
Too much mess compiling current version. I had begun changing the Relay to
deal with additional information and it has cascaded. Will back up and save
anyway, as I want to get on with the non-relay implementation.

The plot thickens. In order to efficiently handle the Recv that eventually
triggers a relayed message from its msgdest, I need to implement something
much like the Relay anyway. Fortunately the interface to this Relay stuff
is now via regular messaging calls, so this little excursion was worth it.
- Can do either the regular arguments of the msgdest, or zero arguments,
	depending on the target msgsrc.
- Recv() first deals with its original function, then calls the target
	msgsrc and its msgsrclist directly with or without args as appropriate.


- Can I merge msgsrcs with srclist_f ? Would allow elimination of one pointer
	from srclists.


OK, compiled and ran without the relaying stuff in. Now to forge ahead...


Relaying stuff getting there. I think I can make a simpler implementation
that also does the decision between using lookup and the destmsg args
cleanly.

Implemented. Compiled. Ran with generic stuff. Not yet tested with relaying.

Slowly wrapping up the relaying code. 

=============================================================================
4 Feb.
Relaying code seems OK now, tested in simple case and it works. Much more
still to be done, but I think the framework is adequate. Saved as
mus_feb04_2004.tgz. 
Time now for the merge-back with the rest of moose.

Slowly merging things in. cinfo has been done and seems to be working including
the initialization. element in progress, needs p_element too in order to
build the tree.

Brought in element and p_element. Will also need neutral.

=============================================================================
5 Feb.
Neutral not used in old moose. I think p_element fits the bill.

Create implemented. Now main does not have any dependencies on any 
specific type.

Handed over to Ravi to compile on Windows. Worked right off.

Should I shift over to using IDs:
- Machine independence
	- Complication of coming up with new ids on non-communicating nodes
	- If eid has a node identification portion, then need extra map for
		elements moved off-node.
- Moving, filing, and redefining elements
	- Messages need to be swapped to id form
- Message speed
	- Use pointers normally.
- Size of ids/ptrs may be incompatible
	- OK in 64 bits
- Garbage collection
	- What happens to old ids or ids that have been moved around and need
	to be redefined.
- How does all this differ from the ability to redefine pointers ?
	- Machine independence.
One good thing is that all communication is now through messages. That is the
only thing that would need idification.

	msgsrc:
		- parent and field are distinct pointers, could be eid and fid.
		- msgdestlist is array of pointers. Would expand in size
		to handle array of ids, as it includes both element and field
		info. However, if msgdests have an id it is ok.
	msgdest:
		- Mirror image of msgsrc.
- What would it affect to make the change
	- Need to make eid array
	- Already have fid arrays. I believe the idea was that fids are unique,
		so I would have to take some offset of fid based on cid.
	- What about dynamically created things like generic messages ?
- Could probably retrofit. Don't deal with for now.

Implemented about half of the mpp, the moose preprocessor. Still need to
complete the wrapper.h specification and then the wrapper.cpp. Then to
put the wrapper files in a subdirectory so that the main directory can
concentrate on essential files, and then deal with the Makefile.
- Fold in main moose. To the extent that most of the remaining stuff is
	class definitions, this wrapper stuff should speed it up.

=============================================================================
6 Feb

Almost finished .mpp
	- func_field
	- Eliminate trailing comma after last initializer in wrapper.h creator.
	- Still have problem with naming of msgsrclists. Sometimes it has
		a _ms suffix
	- In enzyme_wrapper.cpp still am naming msgsrc rather than field.
	* Fix the .h retaining of msgsrc placeholders.
	* Single slashes are lost
	* colon after declaration of creation func in wrapper.
	* msgsrc1 and others should be field1, both in wrapper.h and .cpp
	- Need a way of identifying fmsgsrc1 and 2.
	- Most handlers in the wrapper could be single line rather than put
		the function on a separate line.
	* Make the wrapper a friend class or make fields protected.
	? in wrapper.h could get rid of zero arg _mdi static field.
	* # of args in msgsrc template defs always seems to be 1.
	+ Do and test enzyme
	- The field for the funcfield mode is missing. This involves setting
		up a corresponding function in the wrapper. Also issues
		of constness, will need to provide mpp with a way to deal
		with this. The get_field part must be const.

OK, was able to compile enzyme without human intervention following the
translation from .mh to the other 3 files. Now we test the compiled enzyme
and then go from here.

=============================================================================
8 Feb.

Enzyme throws up some interesting headaches. It has this func_field which
specifies which mode the enzyme runs in. In one of the modes it needs to
create a molecule for the enz-sub complex. This is obviously a job for the
wrappers, but there is currently no provision to pass this kind of thing
down to them. I want to minimize the need to write anything in the wrappers,
but I also want to give the users the flexibility to do stuff with moose in
their object definitions. Maybe provide a separate .cpp file for such things.
Or, better, as the enzyme.cpp is designed to remain untouched, provide it
with the extra info.

Still working on the above. Turns out that the func_field stuff was not even
included and the final implementation will need a separate wrapper function
for the func_field, in addition to whatever happens in the core function.
This is where such issues can be handled.

OK, fixed up func_field stuff as far as it goes. Will need extra
post-processing by the user to get all the bits in, for some cases.
Would be nice to include a directive for code that has to go in a specific
place for the .mh file. Later.
- Now implement and test the func_field stuff for enzymes, and then turn
the whole mess over to Ravi.

=============================================================================
9 Feb

Looks promising. Karthika has turned up and will work on this version for
trying to fold in the parser. At this point I can step back a bit and let the
others work on this, and in due course:

- Fold in rest of old moose
	- Scheduling
	- SMP
	- Plots
- Fold in new stuff
	- Graphics
	- Parser
- Fold in new objects
	- compartments
	- squid channels
	- Other kinetics constructs
- Put in additional computational tools
	- Gsolve
	- Hsolve
	- Lsolve
- Put in additional facilities
	- Multinode parallelism
	- Arrays
	- Array messages
	- Event-triggered messaging
- Back port old stuff
	- kkit
	- neurokit
	- major demos
- Put in new demos
	- SoN
	- Demonstrating all features
	- Test suites
- Write a book.

=============================================================================
25 Feb 2004
In order to handle buttons and other things, the parent element has to
be of a defined type and pass in a form pointer. One way of doing this is to
pass the parent in as an argument to the createwrapper function, currently
declared as:
	element* (*createwrapper)(const string& n);
The createdata function may also need information (typically null, but in
this case it is the form pointer. Currently it is:
	void* (*createdata)();
What is worse, the type of the pointer passed to createdata is unknown.

=============================================================================
2 March 2004.

Set up createwrapper to pass in parent info. It may be generally useful.
Want to partition stuff into distinct subdirectories to avoid clutter.
Later, after scheduling is redone.

Started on conversions. Made sched.mh. Need to put in extra layer, 
call it process.mh. This will hold the clockjobs, which will hold the
clockticks. When multiprocessing, the clockjobs will replicate.
The scheduler anyway puts each job (in this case process) on a separate 
thread. need to have it so that the scheduler keeps track of the # of things
already busy before allocating numthreads to the process.
=============================================================================
3 March 2004
Qs:
	- Do we need barriers at the sched level or are all jobs going to
	be completely independent threads ?
		All jobs emanating from the sched are independent threads.
	- What does the call to the blank barrier do in the multithread case ?
		This tells the thread to terminate. Ugly.
	- How does the thread-aware messagesrc work ?
		Calls the barrier->Wait() after every Execute of each elm in 
		list.
	- How do we handle regular execution as things are added and removed
		from the execution list of different jobs ?
	- How do we safely pass messages between objects running on different
		threads ?

=============================================================================
4 March 2004
Structure for scheduling.

Build up structure, then set off.

/sched: Called from main(), calls process for child jobs, then
	blocks till all child threads are done.
	Can be restarted to add a new child thread.
	Special calls can initiate operations
	on children, such as cancel, restart, and setting off the procjob.
	Fields: Nothing yet.

/sched/job: Called from /sched. Starts off a new thread, calls a process list,
	terminates when the process list is done. May be never, if the
	process list is an infinite loop for graphics or something similar.
	Fields: die_when_done, running

/sched/procjob: Called from /sched, subclass of job. Starts of thread etc.
	Knows about # of processors and other info for controlling SMP sims.
	Fields: Duration, running.

/sched/procjob/clockjob: Called from /sched/procjob. Starts of a new thread.
	One clockjob handles each SMP thread.
	Conrols a bunch of clockticks

/sched/procjob/clockjob/clocktick: Called from clockjob. One for each dt.
	Each has a msgdestlist of objects to call for PROCESS and other
	periodic funcs.
	

Would like to use piggyback for calling children from sched. The kids are
all job subclasses. Problem is that there is currently no guarantee
in Recv() that the element is of the correct type. Worse, there is no
way to compare the type of the parent of the msgdest to the type desired.
the element extracted from the targets of the msgsrc->destlist.

Let's test if it is possible to do something terrible here.
Yes, was able to call the reac 'proc' with the function for the enz.
OK, fixed it. I now require the class info to go in the template for all
fields that can receive info. This is easy to check for.

Re piggyback: It gets nasty because target class and func may differ for
different entries in dest list. So I can't specify a single msgdest for
all targets. Would be nice to have equivalences between msgdests.
There was also the lazy-evaluation JIT msgdest... This could stick with
current msgdest while OK, and then reevaluate when needed.
Another option is to do the piggyback only using the string lookup.  

=============================================================================
5 March.
Threading complications.
For the /sched, the following operations seem relevant and obviously need
coordination between threads:

- Alter states of existing child jobs: start, stop, sleep, pause, wake
- Add/delete jobs
- Terminate entire system.

On a general level, we need to have control over which threads are allowed
to change things, and when. Dumb approach is to serialize all structural
calls like Copy, Delete, and Create, so we don't have conflicts on that
(dangers of deadlock conditions though). We also may need synchronization with
the controlling threads so that these ops don't clash with other calls,
for example, a delete in the middle of a call to execute that object.
Smarter approach is to be able to find if a given object is busy, and wait
till it is free before doing anything to it. Again, need care with deadlocks,
for example, the gui has issued a call to make a gui object so the gui
job is obviously busy.
Put this bigger issue on a background thread. Let's first get the basic
scheduler going.

Perhaps should put generic start/stop/pause into the jobs.

Created sched and job, got to compile. Still to test. Need a sleep object
to play with. 

Created a tty and a sleep object. All play nicely together. Onwards to
clockjob, clocktick.

To do:
The clockjob takes over from where sched used to be in the nov2003 version:
handling all SMP stuff for clocked simulations. 
Need to insert a layer then after clockjob: call it clockproc. This
replaces the old clockjob and is what gets duplicated for each thread.
Finally the clocktick is as before.

=============================================================================

6 March 2004
Parser notes.
C parser is in gajjak:/home/karthika/ss_interact
It has been set up using the yacc and lex tools.
Run using the command 'sli'

The directory called testfiles has various C parser tests.

sli parser is in gajjak:/home/karthika/parser
	Cannot get it to work standalone.
	The ss directory is where you compile it.
	The ss.o is created. Q: How to link this to create an executable.


Current best approach: Have a single global yyparse chunk of code, but
call it from a specific object on a thread. 

Adding a new function like echo or create:
Go to eval.c, figure it out. do_function


Other parser generators:
ANTLR: specify grammar file. handles c and java. Need to find grammar file.
Generates C++

OpenC++, also a parser generator. Would be hard to link moose objects.

=============================================================================
8 March 2004.
Stages for this week :
	+Set up scheduling
	*Separate into subdirectories
	Fold in parser.

Scheduling getting there. I have implemented and compiled all the key
pars of the sched structure: /sched/clockjob/clockproc/clocktick/simclock
Still need to activate piggyback to deal with reinit.

=============================================================================
9 March.
Still working on scheduling. Headaches with clockjob, related to 
problems with handling inheritance cleanly.

Some cleanups needed
	- Implement piggybacks.
	* Implement plots
		Do a test where the plot is at a different dt and sends
		a message to a field to tell it to give the plot a value.
		In other words the msgsrc is the dest.
		Implemented using ReversePiggyback.
	* Get rid of special message for barriers. Do it in the object.
	- Jobs should be cleanly haltable. Should have a way to pull the
		plug on the thread, but cleanly.
	- Should we have barriers passed to all jobs ?
	* Report when a process is done.
	* Report when a job is done.

ReversePiggyback would be nice for handling plots. Go back
to source, trigger the Send(), and collect info. Problem when
we try to schedule such stuff, specially in parallel. Need
to put it in dependency list ? However, should always be readonly
so SMP should not be problematic.  Should I just deal with it when
it comes up ?

Current version saved and backed up. This version seems to have the
basic scheduling working and several of the classes are implemented.
Next stage is to set stuff up in subdirectories and then to try to 
get the parser and graphics going.

=============================================================================
10 March.
Subdirectory compilation working.
kkit_parser compiled. Not yet tested.

Would like to moosify it. Set up the LoadModel method to handle one
line instead. Add a few extra commands like create, addmsg, call, setfield,
showfield, step, stop, quit and include.
This should give a lot of flexibility and help in many ways.

=============================================================================
11 March 2004
Looks like the kholodenko model loads! Still to test running.
Now need to backtrack and fix the teststuff.cpp file because I have changed
a lot of field names to fit with the old ones. reac::sub, reac::subout,
plot::plot

Fixed.
After much fumbling and assorted headaches due to not initializing things,
got the kholodenko model to run. Other models don't work ... yet.

Went through. All the enz models work except the enz1e-15.g model.
Kholodenko_explicit_enz.g gives errors. Shape is OK but values are not.
	Turns out to be due to initial fastdt used only in the reference sim.
	After that it matches well. Need to implement fastdt.
	Did a little benchmarking. Optimized Moose takes 30 sec. 
	scsim18 without graphics takes only 18. Serious improvement needed.
Kholodenko_sumtot.g fails too. Sumtot does not work at all.
Partly fixed sumtot. Mostly involved messy stuff with paths.
Still issues when sumtot is an enzyme parent. Made test case 
	testsumtot.g
which confuses moose. Perhaps the reset is needed.
Fixed the testsumtot.g problem. Moose still gives nans with acc4_1.6e-21.g,
even when the dt is reduced.

=============================================================================
12 March 2004

Now working on gui stuff. Yesterday's  problem is still unsolved.
Today was able to make form with button and to get a message from the
button to terminate the simulation.

=============================================================================
13 March 2004.
Yesterday's version is being ported to Windows. Should it compile then
we'll be all set to go ahead with the more complex stuff.

For now:
	- Put in a little more ability in the kkit_parser. Should provide
	it with the regular portfolio of commands other than the arithmetic
	ones: create, delete, move, addmsg, deletemsg, call, quit, reset,
	show, get, set. Should do through a table, which all parsers can
	access. The finfo approach is a good one for doing this as it is
	uniform. How to do arg checking? How to handle global and
	templated functions ?
Create: strings
AddMsg: Strings.
SetField: Will need to look up field info to figure out how to do the
	conversion. Would like to use SetField but it would mean that we
	need already to know the type. How about RTTI ?
Call: If I set up the fields with Recv and Send using string args, it
	will work. Will need a way though to convert composite fields.

Problems with doing this at the level of finfo:
	- Applicable really only to fields (single args)
	- Does not specify # of args (Could easily be a finfo method though)
	- Call, though rarely used with multiple args, needs to specify #.
		Call(/foo/bar, /zod, int("1"));
		Want ability to pass in elements, including for ints.
	- Showfield: March through list of fields. Many are complex,
		and will need specialized info output.

Another approach: Specify type of each arg. This is not simple, because
we do not require that args are moose classes or even fieldinfos. The
fieldinfos are instead about functions relating to sets of fields.
Is this dissociation a problem ? It is nice to be able to tie things together.
If we can tie types to args, then we could use only the ret_field class
to communicate with everything else through existing mechanisms.
We could even specify the kind of args required by emitting ret_fields
for arg1, arg2 and so on.
In an older version we had the concept of arglist, which had nargs and
then a set of fieldinfos for each arg. Here we could have an arglist but
instead of generic finfos use retfields or something similar, that knows
how to convert to strings. Then our Recv and Send will need to be extended/
altered to deal with an arglist instead of a string right off the bat.
Alternatively, the arglist itself could figure out how to call the funcs?

Recv(element* e, arglist* al) {
	Recv(e, al[0], al[1]) // overload al[] to return value of arg?
}

Send(element* e, arglist* al) {
	al[0] = val1;
	al[1] = val2;
}


bool al::CallRecv(element* e, finfo* f) {
	if (CanRecv(e) == 0)
		return 0;
	if (Verify) { // Ensures Nargs and argtypes match up.
		switch (Nargs()) {
			case 0: 
				f->Recv(e);
			break;
			case 1:
				f->Recv(e, al[0]); // Ooops. How to do typing here?
			break;
			case 2:
			break;
		}
	}
}

al::Verify(finfo *f) {
	return al.Verify(f->Args());
}



=============================================================================
14 March 2004.

Have arglist refer to elements.
All fields provide arglists.
Have elements able to provide string conversion to and from contents. Recursive.
	- Equivalent to simdump
	- corollary: need way of specifying field sequence: simobjdump
	- For it to be recursive, need either for fields to know how to
		make an element, or elm needs to explicitly know sub-elements.
		- Could specify number of fields to use from fieldlookup.
		- Or simply use all simple fields and func_fields.
		- Or flag all fields with info about whether they are core.
	- Must work even if we don't have every possible type defined in elms.
	- Could be func_field of each elm. strval, fieldlookup[1].
Have conversion between elements and fields.
	- Allow arglists for Send and Recv.
	- Have a simple_field for all elements with the basic type of the elm.
		(use regular finfo stuff for it, call it self, also provide
		access func within element to get at it (fieldlookup[0]);
(Added later, on 21 March:)
	- Other possible default fieldlookup entries:
		cinfo: fieldlookup[2]
		Name
		Index
		Path
		Parent (or get it from the msgdestlist parent)

Sequence of steps:
	+ Implement tty-based parsing for simple commands
	* Clean up scheduler to handle start, stop, reset.
	x Implement above arglist stuff.
	- Implement portfolio of commands using arglist stuff.
	- Implement C parser as an object

Status:
tty now talks to the kparser. Successfully halts it.
Starts and stops done, both for jobs and clockjobs including processing.
Implemented as a queue in the scheduler, which is filled in thread-safe
manner by calls to start and stop methods. The queue contents are then
despatched to the jobs. Regular jobs are cancelled, clockjobs terminated
gracefully at the end of a cycle in a manner that supposedly will restart
cleanly. Still need to do much testing on this.
Resets still to come, depend on piggybacks. Piggybacks would also clean up
several aspects of stop. 

Gave up for night. The system seems to have a race condition. Can get it
to stop, cannot get it to run (start)

=============================================================================
15 March 2004
Took about 5 min to sort out, with the help of being awake, and Butenhof's
great book. I was using pthread_cond_wait incorrectly. Also figured out that
the problem of the system sometimes continuing to hang after being told to
quit is due to blocking of IO. May need to explicitly kill the tty thread.

There was a problem in restarting runs where they left off. This is now
fixed.
	Still have to fix:
		- specify runtime as additional runtime rather than total
		- Step
		- plot prints after every run. Should print more selectively.

Extremely fragmented work time. Implemented piggybacks and used them at
once in the stop function. Seems to work. Ran the kholodenko model with
a couple of stops and restarts, and compared using md5sum to the equivalent
using a single run. Identical.

Thinking slowly about reinit. Needs thread safety. Needs to call Stop, or
a brute-force instantaneous version of it. Needs to ensure that it is complete
before passing the reinit message along.

Putting a brute-force reinit in. Fails at clocktick.

=============================================================================
16 March 2004
Reinit is still a headache. Seems to percolate through mostly, but is
not updating plots.

Fixed reinit. The clockticks were not being properly reinited.
Fixed quit. The 'stop' msgdest had not been initialized for jobs.

=============================================================================
18 March 2004.
Fixed Nans on acc4_1.6e-21.g, output is reasonable but not identical to
the genesis output. Nans were because I did not initialize reactions,
in particular their A and B values. With that done it worked at once.
Difference in values is probably 2 things: Volumes and variable dt.

=============================================================================
19 March 2004
Worked with Ravi on port to Windows. Compiled, ran, tested kholodenko model.
Issues:
	Need compiler flag for replacing <unistd.h> with <windows.h>
	Need definition of index(char*, int) within kparser.
	A very annoying compiler bug that does not recognize a static const
		member as allowed for array sizes, again in kparser.
	FLTK GUI does not yet draw its window contents.

=============================================================================
21 March 2004
Putting in fixes for windows compilation. Done, using ugly #defines.

Trying to set up variable dt runs. Boils down to blocking while run is
in progress vs restarting automatically once fine_dt part of run is over.
Also, would generally like info about when a run is over.

Much messing around later, variable dt seems to work now. Use a restart
function so no blocking. Still need to fix something causing problems in acc4.
Turns out sumtots still messed up.
Sumtots needed a prior reinit. That done, things are better, but
acc4 still does not give the same answers. Possibilities: more sumtot
problems, volume problems.

Tried ip3.g: Stuck with INTRAMOL messages
Tried nonscaf6: Dumps core due to tables.

Spent some time fixing molecule stuff so it now uses n as in kkit.
voltest works.
Need to test acc4.
Qualitatively OK now, but PKC and many other molecules still differ. Odd.
OK, tracked it down to the CONSERVE messages which I simply ignore in the
moose version. If I use a sufficiently small dt of 0.0005, about 10 times
smaller than before, then the two sets do match.

Saved stuff in mus_mar21_2004.tgz. This version does the following:
- Loads and runs most kkit dump stuff.
- Handles tty as a separate thread
- Handles basic run commands from tty to kparser. 
- Handles variable dt runs by sending a message when the inital phase is done.
- Handles plots efficiently using reverse piggyback calls.
- Is set up to compile on Windows.

Just for fun, here are the comparisons of runtimes on my little laptop, a
1GHz Pentium M. Moose is compiled with -O3 and I think so was scsim18.

				Moose		scsim18 in text mode	
kholodenko.g for 100000 sec	12.83		13.4
acc4_1e-21.g for 2000 sec	40.27		22.22

So we clearly have some issues in the performance of Moose. Need to do
a few more checks for big models, and then some profiling. All that for later.
Now the priority is field and element access including strings.

Proceed by implementing these using mpp for int, double, string.

=============================================================================
23 March
Muddling along looking at doing argument lists. But why? The specification
of field[0] as the element value and field[1] as the string value of the
element should be sufficient. Also need way to associate each field with
an elm to do the above conversion, otherwise it will have to be done at
the single field level. This was where arglists came in. But I shouldn't really
be using arglists, instead one element per arg. What I really need is not
an arglist as much as a way of associating field with element type. Could
do at startup: Scan through all fields and find matches among defined
classes.

On the other hand, it is easy to do the string conversions at the field
level too. Will need to provide operators though for each class used. Also
not general and recursive.

Setfield from shell: Identify elm corresp to field. Create it. Set its val
	from string. Use it to SetField the target.
	Shortcut: Can the elm provide direct conversion between
		field[0] and [1].
Getfield from shell: Identify elm corresponding to field. Create it. Set its
	value from GetField. Show its value as string.

Showfields: Do above for each field.
Simdump: Do above for each required field in a specified order.

Implemented startup scan to find matches for fields.
Next to implement string assignment and extraction from fields.


=============================================================================
24 March 2004
Preliminary version of show and set working. Set works both from typed
values as well as from one elm to another. Show is OK for a restricted subset
of fields which are of known types, haven't yet gotten recursion going.
It is still messy in that it creates temporary objects and doesn't yet
clean them up.
Still need to be able to show * and to list children (which should be
a case of showing the contents of a message list).

=============================================================================
26 March.
Yesterday tried out Moose on Athirasam, now sporting a 64-bit Athlon 3400+.
Didn't run. Compilation worked (had to change some ints to longs where they
were used in comparison to string::npos). But moose did not run, not clear
why.

Do I really need the string conversion stuff for objects ? If I can use
the type equivalence info, it should be enough to allow the parser to figure
out how to typecast the Get and Set values.

=============================================================================
27 March 2004
About to look at parsing. I think the best approach is to first write a
little parser of my own, understand how it works and how to merge it with
Moose into an object. Then I should be able to understand the rules and
plug in the grammar for the old sli as well as the new C parser.

Also, flex turns out to have C++ compatibility hooks. Will use those and
try to merge the old SLI parser into MOOSE directly. Will also gain reentrance.

test1: echo program
	make with flex test1.l; gcc lex.yy.c -ll
test2: identifying words
	make with flex test2.l; gcc lex.yy.c -ll
test3: Symbol table so that words can be added on the fly. C version
	make with flex test3.l; gcc lex.yy.c -ll
test4: Symbol table so that words can be added on the fly. C++ version
	make with 
	flex++ test4.l; g++ lex.yy.cc -ll
test5: Symbol table so that words can be added on the fly. C++ version,
	this one using appropriate classes to encapsulate what used to
	be global variables.
	make with 
	flex++ test5.l; g++ lex.yy.cc -ll

OK, good going. This shows I can use flex to get a cleanly encapsulated 
parser going. I have also identified the language definitions Dave Bilitch
used.
Remaining:
	- learn about bison.
	- encapsulate the sli language definition
	- Locate a C language definition somewhere, try to get that implemented.

=============================================================================
28 March 2004

test6: Including both .l and .y files: Lexer-Parser (flex/bison) combine,
C version. Corresponds to example 1-6 and 1-7 from the book
(Levine, Mason and Brown)
	make with
flex -otest6.yy.c test6.l
bison -d test6.y
cc -c test6.yy.c test6.tab.c
cc -o test6 test6.yy.o test6.tab.o -ll


test7: Including both .l and .y files: Lexer-Parser (flex/bison) combine,
C version. Corresponds to example 1-8 from the book Levine, Mason and Brown.
	make with
flex -otest7.yy.c test7.l
bison -d test7.y
cc -c test7.yy.c test7.tab.c
cc -o test7 test7.yy.o test7.tab.o -ll

OK, done and works. Now to do this in C++.
flex++ -otest8.yy.cpp test8.l
#bison -d test8.ypp -p "lexer->"
bison -d test8.ypp
mv test8.tab.hpp test8.tab.h
g++ -c test8.yy.cpp test8.tab.cpp
g++ -o test8 test8.yy.o test8.tab.o -ll

=============================================================================
30 March 2004

Looks like I have the bare bones working. Wrote a little makefile to automate
the compiles. Got the C++ wrapped parser to work, sort of. Still have globals
floating around esp at around line 516-524 of test8.tab.cpp. Will need to
capture them and convert to fields of the myLexFlexer team.

=============================================================================
31 March 2004

Preserved test8, now it has Makefile8.
Set off on the next stage with version 9 where I try to encapsulate all the
globals.

Well, looks like it works. Now to take better control of the input/output
and pass it stuff from char strings rather than the current stuff.
Design issue: How to get stuff from the parser? Simple is to have a loop
which passes arriving stuff into a stream and reads off another stream,
each bolus goes round the loop once and the output stuff can be read off in
time to go to the tty or wherever.

Need to think a little about streams. I think a stringstream (which handles
both directional input) should do it both for yyin and yyout. The input
stuff from the tty >> yyin >> lexer; and tty << yyout << lexer.

Well, the string stuff turned out to be remarkably difficult. Messed around
for quite a while to get something that worked.
Then needed to go back to figure out how to insert characters into the
streambuf. It may be easier just to create an istream each time and
then reassign it to the parser.

Much messing around later, rather depressing. The parser always emits parse
errors though it does the right thing. However, if I give it a long line
it is happy. Initially I tried with the
stringstream based I/O, then I tried using the builtin functions to provide
strings for I/O. Both give exactly the same errors. Then I tried the
overloaded versions of LexerInput and LexerOutput, and it worked first time,
but with exactly the same errors. Finally I cleaned up the .l file. Still
the same errors. Went back to version 8.

I think the problem is that the parser does not remember its state. When
the lexer tells it that there is no more input, it tries to wrap everything
else up at once. We really need a thread-driven input here, something
like what the cin driven approach gives. 

The work I've done on LexerInput etc is still useful. Will need to
code as blocking calls to call from a thread.

Better do this now before bringing in the sli code, just to be sure
that my diagnosis on the current issues is correct.

=============================================================================
1 April 2004
Set up test10, first pass just shifted it to a subdirectory and separated off
c++ code into test10.cpp. I'll need to put the threading stuff here.

Dieter is here and now we'll shift over to doing some compartmental models
as a start to doing the matrix solutions.

Implemented compartments and tabchannels, working on interpols. Problem here
with clean handling of interpols in a tabchannel. Suggestion to 
duplicate interpols every time one is modified. Have a flag to indicate
whether the current interpols are one's own or copies. Problem in that
copies will not know if their parent's interpol is changed.
Other option is to have a set of messages from master interpol to the
channels using its pointer.

=============================================================================
2 April
One step forward, two back. Many interlocking things need doing as I try
to implement channels and tables.

- Compartments are done.
- Channels are done but for the interpol handling. I'll try to set up
	interpols as fields.
- Interpols are done
- Tables done, need testing
- kparser handling of tables is partly done, needs testing.
- nernst 
- synchan

Table reading still doesn't work.
Trying to handle tab reading through lookup of interpol type and its
field.s Too tired.
=============================================================================
3 April
How to cleanly implement interpols and their association with multiple
targets.
- Use a parent/child message from table or channel to interpol
	- Messy to do multiple tables per channel. Multiply by 500 compts
		in 1000 cells. However this could be the opportunity to
		use the evaluated messages.
	- The direction of this message is backward. Really want to get
		info from interpol to channel, not other way. Could use
		reverse piggyback concept, I guess.
	- Parent/child message also maps well onto the idea of subfields
	- Would need to endow the interpol with a different kind of child
		target that can handle multiple parents.
- Use a special message from the interpol to all channels that use it
	- Similar options for evaluated messages
	- The simple appearance of parent-child hierarchy is lost.
	- Direction of info flow is more sensible.

=============================================================================
4 April
	In addition to the above list:
- Dangling pointers with no way of tracing origin or shared values
	(Current approach, obviously not a good idea.)
- String info about source of data
	- Incompatible with other forms of reference in the system.

So to streamline things I really need to set up a new kind of field that
acts like a reference for data that is internally stored as a pointer,
and provides hooks for the tie-up with the original via a message.
Assuming option 2 (from 3 Apr) this field would do the following:
	- act like the msgdest
	- hold the relevant pointer for internal access
	- Make the tab look like a child/subfield/nested object.
	- Determine if the field is to be treated as RO or RW.

Further, will need to standardize this kind of traversal of child fields.
	- Follow field to original instance of object
	- Do field lookup/assignment there.

Slowly, things are coming together. Loaded compartment model without error,
appears that all the bits are in there. Implemented a status function that
helps to do a quick check.

Want to test loading of tables.
Mostly done. Compiles. Too tired to test.

=============================================================================
5 April
Need to figure out how to make a field that indexes [i], in the interpol. Once
this is done much becomes possible. Options:

- Allocated finfos that contain index info. Could create when scanning through
	FieldLookup, replacing name string equivalence with a function that
	recognizes indices.
	- Problem with disposing of used finfos.

- Replace finfos with fids, that include the finfo ptr and any necessary
	indexing. Need to deal with a lot of commands but it is almost
	always simple. The fids are simple fields and would be automatically
	deallocated after use. See above option.

- Extended set of commands using finfos. This is horrendous, there are
	lots of such commands.

Would also like to have a clean way to follow nested fields. Here the fid
	could hold additional info for traversing the nesting.

Much headache with loading the interpol and then a baffling bug when testing
it with test/test_table.g. 
Finally turned out to be a scheduling problem related to order of calling
clockticks. Cleaned up, tested.

Successfully loaded nonscaf6, still some issues with the table as it
repeatedly gets to FillTable.
For a moment it seemed like the scheduling fixes had speeded things up.
Recompiled with O3 and tested. No such luck. Old times hold almost exactly.

=============================================================================
9 April.
Difficult to find time to work. Fixed the FillTable bug, still need
to verify that the entire table is loaded correctly.

Fixed some more bugs, now FillTable works and it looks like so does the
nonscaf6 model.

Created a test for a compartmental model based on the rallpacks. Called
it axon.dumpfile.g. It is generated by test/rallpack/make_axondump.g

Basic model loads. Now to get the dumpfile to specify all the other stuff,
plots and timesteps etc.

Dumpfile seems OK but output is still just a flat line.

=============================================================================
10 April
Working on compartment computations. A little messy

Much fixed, but it still isn't calculating properly. Timestep ?
=============================================================================
11 April
Compartmental computations including propagation of action potentials
along a cable, appear to work.

For Dieter's project:
* Get full models loaded from dumpfiles. Mostly a case of interpol assignment.
- Get an hsolve equivalent to work, probably using gnu scientific libs.
- Figure out how to merge Dieter's new markov channel stuff.

For Squid demo in moose:
- Get SLI working
- Make graphs and other graphical things for Moose
- Make tabchannels pretend to be hh_channels.

For Moose KKit standalone .g reading stuff without graphics.
- Get fast solver working for kinetics
- Get stoch and other methods working for kinetics
- Get SLI working.

For serious signaling models:
- Get SMP to work
- Get node decomposition to work


A little puttering around with the kparser: pwe, le, need ce and pushe.
=============================================================================
12 April
A little more messing around, pwe and le are working, ce is getting there.
Still some issues with show.  Would like to show *.
=============================================================================
18 April
Work on Dieter's project as we should have an hsolver equiv working soon.
- Make a proper dump of his entire cell model
	* Put the tabchannel definitions for the prototypes of the channels
	* Fix the old genesis code to deal with the simdump correctly.
	- Fix the old genesis code also to handle the returns for creation
		of molecules, which were problematic earlier.
	* Put in the rest of the model without the dump option.
+ Load in prototypes and rest of model into moose
	- Prototypes load
		This works in part, but several classes are not yet defined:
		* Ca_concen
		* nernst
		+ synchan
		- Mg_block
	- rest of model load
		* Need to create GP and assorted other neutrals.
		* Problem loading - seems to be issue with dump itself -
			Yes, isn't dumping stuff with array indices.
			Fixed, minor issue with path in dumpscript.
		* Problem loading because of missing classes. Otherwise
			no errors.
* Put in an ad-hoc channel assigner after initial load is done.
* Test with exp euler
- Implement an hsolve type thing just for compts.
- Grab Dieter's code for the channel, implement it.

Status: Working on nernst. Need to 
	* Check about local variable status of Cin and Cout. 
	* Check if the simdump stuff needs redoing for these variables
	* Complete the messge conversion

Before it can work I will also need to implement the Ca_concen

=============================================================================
19 April.
Ca concen done, loads.
Nernst done, loads.
Synchan done in a partial manner. Loads. Now entire thing loads, both the
	main.dump.g and the proto.dump.g. The proto.dump.g has an Mg_block
	which is not yet defined though.

Ran model, works. Output is similar to that in runcip_noh.g,
which is the GENESIS equivalent, but a long way from a precise
overlap. Runs in 51 sec in the moose version compiled with -g, as compared
to 30 sec in the scsim18 compilation of the genesis version.
Tried with -O3 compiler settings for moose, this time it runs in 31 sec.
About the same as the scsim18 version. Should look at optimizing.
More importantly, should get the outputs to match exactly. Then on to 
an hsolver in moose.

- Fixed lack of scheduling of ca_concens and nernsts. No apparent effect.
- There is possibly an issue with previous_state sequencing. Implementing
	an init action to handle this.
	This seems to be on the right track, giving matching results with
	the GENESIS version for a while, then going nan.
- There was also a problem with the Ca_concen object. multiple problems,
	in fact. Fixed. Now output waveforms pretty much coincide.

=============================================================================
20 April
Thinking about hsolve and other solvers.
Speedups come from:
	- Better numerical method
	- Bypassing messages.
The current code is supposed to be far faster than the old genesis for
messaging. For some reason it is not. Need to profile to work out why.

OK, the Send is calling the begin() and especially the end() methods
way too often. Can bypass:

- Add templates for field types onto msgsrclists. 
- Use msgsrclist::Send(). This would eliminate several indirections.
- If I could store the target function and target elm ptr in the msgsrclist,
	I could eliminate a couple of lookups via the msgdestlist.
	If the target function didn't change it would help too, no lookup,
	needs less storage. Ugly though.
- Could definitely template the msgdestlist and call its Recv directly
	rather than look up the function and also the parent. One or
	two less indirections there. Cleaner too.

Back to hsolve. We want to avoid munging of data structures, allow arbitrary 
channel solvers.
	- Use channels in order so that the same interpol is used in all.
	- Use smaller interpols, actually do interpolation
	- Put the compartment ptrs in a local array. Some waste, but not
		too bad. Alternate is to just store ptr to regular compt.
		This splits up memory locations, otherwise no problem.
	- Channels have to provide a special function, perhaps all
		objects should provide a function, for evaluating state
		and its derivative at a given pt. This is a pretty big
		function for HH channels, so func call overhead is small.
		Use messaging. Other channels: synchan is pretty small.
	- Ca concen and the like: Issue is how they communicate with the
		channels. If the channel update function is able to
		get this info it is cleanest.

OK, so on to work on the messaging. Doing some timing.

This is compiled with -g. Note timings in comparison to those on 21 March.
				Before msging change	After change.
run kholodenko.g for 100000 sec. 	31 sec.
Run acc4_1e-21.g for 1000 sec. 		49 sec.		38 sec.

OK, a 20% improvement. Not bad, but not great either. Long way still to go.

Try with optimization O3:
				Moose		scsim18 in text mode	new
kholodenko.g for 100000 sec	12.83		13.4			10.23
acc4_1e-21.g for 2000 sec	40.27		22.22			29.25

So far I have cleaned up the main messages in molecule, all in reac, most
in enzyme, and the procout in the clocktick.

Pretty good improvement. Still not there yet in comparison to direct pointer
lookups, but getting competitive - only took 30% longer rather than nearly 2x.

Now need to look at mpp and also to back-fix all the other messages.

=============================================================================
22 Apr 2004.

- Test msgdestlist templating, see if it helps.
Fixes needed for mpp:
	- Put in static const stuff to automatically initialize it in .cpp
	- put in stuff for templating the msgsrclists and destlists.

Some timings
				Moose orig	scsim18 in text mode	new
kholodenko.g for 100000 sec	12.83		13.4			9.55
acc4_1e-21.g for 2000 sec	40.27		22.22			27.15
gpcell.g for 0.02 sec dt=1e-5	34.3		30			30

This is surprisingly slow and discouraging. What is going wrong?
I butchered the table lookup stuff to skip all error checking and interpolation.No change.

Working on the profiling. Cleaned up various other messages in compartments
and other things. Will need to recompile with O3 to redo comparison above.

These changes imnproved the kinetic calculations a little, compared to above.
But barely bring compartment stuff to parity with scsim18.

Idea- Can the channel calculations be directly triggered from the compartment,
rather than requiring a process? Consider. Will eliminate a bunch of msgs.
This is probably possible, but I think that the speed issue is not due to
messages any more, but to some internal calculation that is slow.

Tried to eliminate the check for 'instant' in the channel routine. No
effect.

=============================================================================
23 April 2004
Test 1: eliminate calls to table lookup.
Test 2: Restore calls to table lookup.
Test 3: Restore calls to table interpolate. Interpolate is not too bad.
Test 4: Test3 + Direct call for channels when Vm is passed. Some improvement.
Test 5: Above plus Eliminate INIT phase for compartments. This has no effect.


Model		Moose	scsim18	Test1	Test2	Test3	Test4	Test5	Test 6
gpcell.g	new
0.02 sec,	30	30	28	30.9	32.1	26.85	27.15	11.8
dt=1e-5
		Test7	Test8	Test9	Test10	Test11	Test12	Test13	Test14
		24.0	14.8	14.7	24.7	25.3	20.3	25.2	14.8

		Test15	Test16	Test17	Test18	Test19	Test20	Test21	Test22
		24.4	24.3	24.2	21.3	22.4	2.3	24.2	3.0

		Test23	Test24	Test25	Test26	Test27	Test28	Test29	Test30
		11.8	25.4	25.1



Looks like something else accounts for slowness.
Test 6: Test5 + eliminate all of channel::proc calculations.
	Aha. This is it. What is happening in there?!
Test 7: Eliminate the Z calculations. Hm. Should not matter, but it does. 
Test 8: Replace pow with a func lookup on the exponent predefined at reinit.
	Well, this is impressive, but the answers are all wrong.
Test 9: Fix the Z calculations. 
	This is the same in time, and the answers are still wrong.... perhaps
	reinit is never called.
Test 10: Fix the reinit. Whoops, now the time is slow again and the answers
	are still wrong. Time to do some debugging.
	
Yet more stuff to fix up. It looks like none of the synchans were called
earlier, now that I have set them up to use the same dt with the voltage
message things will take longer still. Will get the results to behave before
I go back to timing the system.

Results getting back to sanity. Precise form of waveform not quite there yet.
OK, fixed it all. I had to redo the init phase of the compartments. Now
to recompile, rerun as test11. The timing is OK, no great signs of improvement.

Test 12: Eliminate table calls again, just return 0.001 from interpol_lookup.
Hm, this suggests it is a bigger factor than I thought earlier. But there is
still a lot of slack.

Test 13: Restore the tables, set up Nernst so that it is called directly 
	from CaConcen rather than separately from proc. A miniscule difference
	from test 11.

Test 14. See how much time is spent in the other tabchannel calculations,
	the integration and power steps. Commented out these steps.
	These are around 10 sec. Pretty significant.

Test 15. Restored to state of test13. Tightened up the code a little in the
	tabchannel calculations, eliminated temporary variables. Slight 
	improvement.

Test 16. Replaced channel::variables with static variables. Minimal effect,
	not thread-safe.

Test 17. Went back to local variables. Doesn't seem to hurt.

Test 18. Eliminate Ca concens and nernsts from schedule. They contribute 3 sec.

Test 19. Restore Ca concens. Eliminate compartment::init phase from schedule.
	This contributes 2 sec.

Test 20. Restore init phase. Eliminate compartment::proc from schedule, also
	gets rid of channels. This accounts for 21 sec!

Test 21. Just to ensure we are still working. Put all bits back and check
	values of output. OK, all still fine.

Test 22. Eliminate calls to channels. Down to 3 sec, eliminating 21 sec.
	So the channels are almost all of it. Note though that we still
	have masses of messaging.

Test 23. Restore calls to channels, but eliminate the process calculation
	part of the channels. Same as test 6, it takes only 11.8 seconds.
	This is everything - messaging for the whole system, calculations
	for everything but the channels.

Test 24. Restore channel process. Try to inline the voltage func in the channel.
	Doesn't help, in fact slows it a bit.

Test 25. Put it back. Still about the same.

The next clear thing to do is to organize the entire thing in memory so
	it doesn't get bogged down with cache misses. Should be able to
	munge the interpols to do this.

Another possible direction is the use of a consolidated channel object,
	that takes a single message and manages all channels, or at
	least tabchannels, for a compartment. It should look like a set
	of regular channels, but do some clever memory alignment and 
	access sequencing to go faster. I think we could work down to
	about 15 sec with a good implementation.

=============================================================================
25 April 2004.

Here are notes for further tests for Moose:


Date: Thu, 22 Apr 2004 13:14:03 -0400
From: Dieter Jaeger <djaeger@emory.edu>
To: bhalla@mailsvr.ncbs.res.in
Subject: sample simulation

Upi,

I have created a directory /home/dieter/tomoose/vclamp on manoharam, which
contains a sample simulation stellsyn1.g (w/ hsolve in chanmode 1) and
stellsyn1_noh.g (the same w/o hsolve). The results files from these simulations
are in the results subdirectory.

This simulation uses timetable, synchan, diffamp, vlcamp and disk_out objects.
A
cerebellar stellate cell is read in with readcell. A synapse is hooked up to a
distal dendrite, and the voltage clamp to the soma. The simulation shows local
escape at the site of the synapse in the present of the somatic clamp even in
this relatively compact cell (paper in preparation).

This simulation uses no voltage-gated channels.

Pardon the messy script writing. It is hacked together a bit from various
sources, and I replaced channelC3 with synchan. The simulation takes 3 seconds
on my laptop with the hines solver, and about 6 without.

-Dieter



Date: Sun, 25 Apr 2004 13:52:04 -0400
From: Dieter Jaeger <djaeger@emory.edu>
To: Upinder Singh Bhalla <bhalla@mailsvr.ncbs.res.in>
Subject: Moose test kit

Hi Upi,

I have put a 2nd Moose test kit on manoharam in /home/dieter/tomoose/synact.
These are GP neuron simulations with lots of synaptic stimulation. Ca_concen
and Nernst elements are included in each compartment. The base simulation
script to run with the Hines solver is run_brate120103_par.g.  It reads a
parameter set from brate120103.par and writes a result file to the data
subdirectory. A 2nd version of this script is named run_brate_nohines_par.g,
repeating the same simulation without a Hines solver. (The same that is, if you
reset the .par file to point to the same next open parameter set).

I tested both versions and found that the Hines solved versino is accurate at
dt
= 1e-5, whereas the exponential Euler one needs 1e-6. for an acceptable
behavior. In addition it is about 5 times slower than the Hines solver at the
same dt, so the overall slowdown is about a factor of 50. Yuck! The Hines
version runs 3 sec of GP time in 12 minutes on my Laptop. (1 GigH Pentium).

To include an example with the Mg_block element, I added NMDA synapses to the
simulation in a slight revision of the scripts called with
run_brate_NMDA_par.g. I only have a Hines solved version for this one.

I also didn't yet try Hines in chanmode 1, which is using the Hines compartment
solver but not the chip array for channels. I will let you know its speed
later.

Let me know if you want to discuss these simulations in more detail.

-Dieter

=============================================================================
26 Apr 2004
Some more thoughts on solvers in general.

The key in many of these is the ability to locate object fields in 
locations designed for faster access and calculations, especially with cache
in mind. This is rather easy to accommodate, just need to update
the field lookup functions to go to the new locations. And that is where things
get interesting.

	- need to replace the wrapper with a new one that handles the 
		correct locations. But wrapper pointers are stored all
		over, how to replace them? Search and replace ?
	- Would like to do some of this automatically. The solving object
		should be able to provide the needed fieldlookups.
	- Recall that special-purpose finfos were going to be used for
		array lookups.
	- Really want to minimize special coding in solvers. The ideal
		arrangement would organize the entire comput object into
		an array, still accessible to the rest of the
		system without any changes other than pickup lookup.
	- What operations do we need to handle a general integrator
		like runge kutta?

=============================================================================
28 April 2004

Based on list from 11 April:
For Dieter's project:
* Get full models loaded from dumpfiles. Mostly a case of interpol assignment.
- Get an hsolve equivalent to work, probably using gnu scientific libs.
- Figure out how to merge Dieter's new markov channel stuff.
- Design fast channel object that either merges all channels or puts
	the array in a different order for faster lookup.

For Squid demo in moose:
- Get SLI working
- Make graphs and other graphical things for Moose
- Make tabchannels pretend to be hh_channels.

For Moose KKit standalone .g reading stuff without graphics.
+ Get fast solver working for kinetics
- Get stoch and other methods working for kinetics
- Get SLI working.

For serious signaling models:
- Get SMP to work
- Get node decomposition to work

For general improvements
- Fix mpp to use fast messaging
- Figure out how to do object substitution, esp when handling solvers.
	- Use ids
	- Actually objects are never accessed directly, they are always
		via messages. Problem becomes how to substitute messages.
- Can field replacement stand in for object substitution.
	- Msgdestlist: on object. Replace the msgdestfunction and the
		pointer to the 'parent'.
	- Msgsrclist: on object: Nothing to change.
	- Func_fields: on class: Replace the function
	- Simple fields: on class: Will need to replace the field itself,
		as it is cast to a specific object type. Probably need
		func_field instead.
- Could elements be completely generic containers, and hold only a
	pointer to the data class? The message lists could just be fields,
	and stored in the regular fieldlookup array. Better use the genmsg
	lists, which are already defined.
	Problem is the management of all the msgs and the functions. Also
	the static field initialization for classinfo and fieldlist info.
	However, this static field initialization and func management
	does not necessarily have to be done with an element subclass -
	could be any specialized class, or a subclass of cinfo.
	Cost: A pointer to the cinfo, a pointer to the data.
	Also: Each msgdestlist now will have to store 3 ptrs rather than 2:
		data (new), parent, field
	Savings: (Possible anyway) Now that msgsrcs are templated, we don't
		need to save msi (finfo) ptr in msgsrclist

- Elements could be cast to a derived class, which has identical 
	msgdests and so on, but provides different member functions ,
	possibly replacing the fieldlookup and cinfo.
- Msgdests store wrapper and data separately.

=============================================================================
29 Apr.
Fiddling around with ideas above. I think that this is all very hypothetical
till I have a few specific cases that need the object substitution. How about:
	- persistent objects, putting parts of a model to sleep on disk
	- Setting up channels with a chsolver that does the alignment by
		replacing their original lookups with an ordered table for
		all channels and single point indexing. The original channels
		should continue to behave normally.
	- Setting up the main hsolve
	- Setting up a ksolver for kinetics
	- Setting up the gsolver.

=============================================================================
30 Apr
Finally moving on the solvers. Making a simple ksolver, first pass is
to make a kderiv solver that optimizes derivative calculations and can
be used in a Runge-Kutta or similar scheme.

In doing so it is also clearer what will be needed for the solver interface.
I think it can work with two kinds of messages:
	- From solver to each molecule, carrying n (conc) info. This
	message would not execute unless...
	- A plot or a field access is done on the local field, which then
	sends out a query using retrograde messaging, to get the info from
	the kderiv.

=============================================================================
1 May
On the them of what is needed to accomplish solvers:
	- Will also need templated messaging. Consider large array of cells,
		or compartments in a diffusive model.
		The solver is templated for them. The messages that set up
		the interface between solver and real cells should be
		configured just once, with a prototype, but be apparent
		on all duplicates. Would be nice if the duplicates do not
		even exist except for their solver manifestations.
	
Attempting to build kderiv moose object and then I'll start with a simple
euler method.

OK, object built and loaded, now to proceed with using it.

Slowly working on getting the object to read in models and fill up the
execution arrays. Does pretty well so far. Some tricky referencing still
to come: association of all the incoming rates with each molecule.
Maybe trick is a map relating each flux term with a reac/enz, and then
scan each molecule for interactions with reacs/enzs.

=============================================================================
2 May
Also need to partition molecule array by those molecules which are integrated
vs buffered and sumtotals.

A bit stuck on going to the next stage, where I gather the rate terms together
to calculate differentials. I will need to do the following:
- Associate an address for a composite flux, with each reaction
	(note here: could do the negatives of them for pure degradation ones.
	probably would not add any time, and would simplify indexing.
	See, possibly could eliminate second pass altogether with this.
- Go through on second pass summing fluxes with derivs.

- Flip sign of kb terms so all flux terms have the same direction. 
	Simplifies cases where only kb is present.
	OR
	Put in small number of zeros for cases where reactions are unidirection

OK, looks like it is able to build the deriv calculation tree.
Now to see if it can calculate derivatives without dying.

Assorted bugs later: runs both kholodenko.g and kholodenko_explicit_enz.g
and other small models without dumping, but dies on all the big models
tried so far. Perhaps I should now try the smaller models with actual
calculations. Incidentally the speedup for the kholodenko-type models is
reasonable 3x, as far as one can tell without actual result calculation, 
no compiler optimisation, and with a rather small model.

Beginning to do tests using the simple euler method.
enz.g is OK numerically. 
mm_enz.g is not OK numerically. enz is fine, but substrate goes subzero.
	OK, fixed it. Now output matches.
kholodenko.g is OK too.
The coredump with the acc4 model continues though.

Well hey, rk4 works first time. Slow though.

testsumtot gives wrong answer but doesn't dump core.

=============================================================================
3 May 2004
tworeac.g (just created): correct answer. Rules out obvious issues with
reactions and 2nd order reactions. Looks like I need to chop up the big model
and find when it doesn't dump.
a4_nopkc.g  a4_nopkc_MAPK.g  a4_nopkc_MAPK_PLA2.g
a4_nopkc_MAPK_PLA2_EGFR.g a4_nopkc_MAPK_PLA2_EGFR_sos.g
a4_onlyras_no_Sos.g
a4_onlyras_no_Sos_GTPase.g
a4_onlyras_no_Sos_GTPase_GAP1.g
a4_onlyras_no_Sos_GTPase_GAP12.g
All dump

a4_onlyras_no_Sos_GTPase_GAP1_GEF1.g: Finally doesn't dump. Critical step
seems to have been a reaction controlling an enzyme level. Let's make a
model with this shape.

Went through a series of tests here. I am unable to replicate problem with
an apparently isomorphic model in enzreac.g. Even put it on group, no
problem. Even shuffled the creation order around in the original problem
model. It still dumps core.

OK, finally pinpointed problem: It doesn't like unidirectional reactions.
This is true both for enzreac_unidir.g and tworeac_unidir.g.

Now I can sort it out.
OK, sorted. I was simply not properly counting the number of used rates in
pass1, and was going over the end.

Now it loads all the models I have tested, but it gives nans for 
the big models. Possibly a dt thing.
Tests:
kholodenko.g: OK
enzreac_unidir.g: OK
acc4_1e-16.g: Still nans.
Buffering substrates to enzs seems faulty.
	Found one bug: an attempt to calculate derivs for buffered molecules.
	Still faulty.
	Fixed similar bug in the loop to update molecules.
acc4_1e-16.g: OK
nonscaf_syn6.g: nans, but OK with smaller dt.
mega.g: OK with smaller dt.
ip3.g: nans even with smaller dt.

As a trivial benchmark: when compiled O3, moose is about 2x as fast using
rk4 than genesis. rk4 has about 4x as many evaluations per timestep.
Hopefully with the adaptive timesteps we should do better still.


Need to design general solver. Parts:
	*Derivs:                                   Works
	+RK4 and other engines:                    Partly but will need redoing.
	+Time-wise updates incl sumtot and table:  Need table still
	+Fixes for big models:                     Probably above item needed.
	Reverse updating of plots etc:            Need
	Solver sharing for big models:            Need
	SMP:                                      Need

=============================================================================
4 May 2004
Architecture of solver so far:

kderiv :
	does all the nasty calculation sequencing and the actual derivative
	calculations (which are trivial once the sequencing is worked out).
	Also needs to handle special cases for non-derivative calculations:
		- Sumtotals: handle internally as they are common and simple.
		- Externally imposed values (e.g., tables). Needs to go out
			and request input. Some issues with passing times,
			as the dt varies.
		- Interface with stuff done at different dt.
	Also special case where derivs are calculated elsewhere
		- Arbitrary functional forms. Not urgent. Two approaches:
			- Build a table (or 2-d table)
			- Write a functional parser. 

rksolver:
	Uses deriv and n arrays from kderiv. Has routines for
		- Advancing timestep: e.g., rk4 and simple_euler
		- rk5 timestep advance with error estimate.
		- Driver for stepper: uniform intervals (usually long ones)
			as well as complete step freedom.


Need:
	* Clear way of tying together solver and derivs
	* Clean way to pass n and deriv vectors from derivs to solver, once,
		at setup. A return message from reinit would make sense.

Started implementing rksolve. Only needs n and derivs, does not assume
anything else.

rksolve compiles. Now chopping up kderiv to take out rksolve portions.

=============================================================================
5 May 2004
Frustrating day trying to compile rksolver with kderiv. Stupid things like
problems with passing string args in SetField, not yet resolved.

Slowly inching through bugs. Now I have the system set up to do a call
'rkrun time' from the command line but it dumps core.

Probably because the scheduler does not like being rescheduled: the 
DeleteKids() function is flakey.

Still having problems with DeleteKids. Best to start with a simpler case.
=============================================================================
6 May
Recursive headaches.
- The msgsrclist::Send() for the case without arguments still seems to be using
	the ugly field->Send internal construct. Slow. Need to eliminate
	all field->Send, just compile it out.
- The order for deletion is not what I thought, and the problem with deletekids
	continues. There is a spill over of deletes to innocent bystanders.
- An enormous number of ugly message Add/Drop/Forget related stupid bugs,
	astonishing that things got this far before they cropped up.
- Erasing an entry in a vector messes up any iterator that is using that
	vector. Had to redo the parent traversal of kids using a separate
	copy of the kids.
Quite a spring-cleaning.

OK, basic kholodenko.g still works.
rkrun still dumps core. Sigh.

OK, fixed that. Now rkrun does not dump core but doesn't seem to be
scheduled properly.

OK, fixed scheduling and fixed another bug related to references for vectors
in messages. Pointers work better. Now the rksolve does work.

Onward ho: 
	- Solver field lookups, e.g., for plots.
		- Multiple stages:
			- intercept calls to Get and Set,
				(All calls including messaging calls would
				have to first check if an interceptor exists)
				(Replace field definition. Requires an 
				entire new object class to replace the original)
				- Set up as a generic msg on each object
				- Attach these to a special msgsrc, which
					does a common lookup
			- to translate between elms and kderiv
			- to set up a faster msg if there is an addmsg rather
				than a once-off lookup.
	- Higher order methods
	* Array field lookups (vecfield) (still need garbage collection).
		Works by creating unique finfos for the vecfields. Each
		has an internal index for the desired entry in the vector.

OK, I have array field lookups working.  Further steps:
* send messages from them to the plot to make sure all works well both with
	the model and with the vecfields. 
- figure out how to do automatic message forwarding of pre-existing messages
- finally how to do this for any field in the sim, at any stage.
	A field substitution at the lookup stage might do the trick. This
	substituted field would have to refer to the solver as well as
	the original field. Treat it like a message, in which case we
	use the regular genmsg stuff. In fact we can merge it with the
	above. Still need to figure out what to do if the field is updated
	internally - ok, a message relay kind of arrangement should do.
	Finally dug up the trick for relays: It substitutes a new field
	for the old msgdest field. This new field contains the old one,
	and does its stuff first, then it does its own stuff. Quite cool,
	amazing that I came up with something like that and completely forgot
	how I did it.
	- Create a single msgdest on the solver, takes 2 args: any incoming
	values, and the pointer of the requesting elm so it can look up
	the value. It will still need a list of all msgsrcs to obey msging
	rules, but even these in principle could be computed from the
	list in the map.
	- Create a msgsrc on each solved elm, put in the genmsgsrc, and
	flagged for all field lookups to check.

Beginning implementation half-done. For the original object there is a
solverelay class taking shape in relay.h. Next to create the counterpart
on the solver.

=============================================================================
7 May 2004.
We now have three cases of wanting to clone a field in some way.  All
are templated with type info of the field. So far all refer to single field.

- Relays. These are currently done using AddRelay virtual func in finfo.
	Simple and Func fields implement this, the others just return
	themselves. Usually only used for single argument fields.
	Need srclist argument and need to know if the field does internal
	lookup (a bool).
- Vectors. These clone themselves with a new index. Could in principle be
	used for more complex kinds of indirection.
	Need index argument.
- SolveRelays. These are yet to be merged in, but are a lot like relays.
	Usually only used for single argument fields.
	Need srclist argument.

All will need memory management, that is, to be released properly when
the message is deleted. Normal fields are static and are not to be
relased. There is now a finfo::EraseClone() virtual method which might
be generally applicable.

Basically we want to be able to generate an object combining two type features,
one of which is present in the finfo, and one is passed in as a base-class
cloner object. So the templated finfo can do stuff with type creation.
new clone1<T>(this, cloner);

Can't come to a clean solution right away. For now I'll expand the 
bool uselookup_arg to an enum: 
	0 : regular relay, do not use lookup.
	1 : Regular relay, use lookup
	2 : Solve relay.

OK, done.

Now to build the corresponding finfo on the solver.

This is turning out to be really horrible. Chugging away.

OK, I was trying to be too cute with the solver, avoiding using a
regular nmsgdest to save a little space. No point, the internal mol_lookup
stuff is too messy.

Finally got the basic stuff to compile and run. Disappointing:
- Still need to put in the converter to intercept calls to GetField.
	At this point the messages do nothing.
	- To do this the GetField calls need to go through the element,
	not just the cinfo, because all the solving is element specific.
	Then I need to seek out genmsgsrcs which have fields of the type
	SolveRelay. Could get slow.
- I need to handle many fields through this: conc, CoInit, n, nInit.
	Some of them the solver doesn't even care about.
- I need to handle Piggyback and ReversePiggyback type calls.
	The current framework might, but only if applied all over the place.
	Even here, the conc field is not directly updated by the solver.
	We want instead for the Send request from Piggyback to first
	call the solver for an update, then proceed as usual.

=============================================================================
8 May 2004
Refined design for zombie mode:

Solver side
- Specify source
	Options:
	- Second arg
	- Naughty use of element argument.
- Set solver field
	- Specify which field we want to set. Options
		- Always set all fields. Not good: nInit vs n.
		- Second arg is extended, includes field as well as elm info
		- Separate arg info call, then solver goes piggyback to request
			specific once-off field call, which sets value.
		- Separate arg info call, followed by regular call for field
	- Pass field value. What happens if field is non-double ?
		- Allow only doubles
		- Value passed as void *
		- Value passed as element*
		- Templated type zombies
	- How Recv func works
- Get solver field
	- Specification of field. Options
		- Second arg is extended, includes info saying it is a request
			for a field as well as identity of elm and field.
	- Passing field value, esp if field is funny type.
		- Permit only doubles
		- Value passed as void*
		- Value passed as element*
		- Templated type zombies
	- How Send func works.
		- See extended second arg approach. This tells the solver
			what and where to send. Solver calls appropriate
			Recv with appropriate value.
OK, solver side seems pretty clear. Here is the design:
- Single argument message with a solveinfo field. It contains:
	* Field info, e.g, name.
	* Requesting elm info: ptr.
	* Direction of request
	* Data value. For now start with a double, later we'll template.

Zombie side
- Intercept Gets
	- Intercept cinfo::GetField (the one which looks up fields by name),
		look if first entry in msgsrclist is a solvermsg
	- Check for zombie in execution path, in the Send(elm*, destlist*)
		command of all
		fields. This adds general overhead, but Send is not used
		by messaging now so it may be OK.
		Don't like this one. It adds another layer of complexity to
		fields, not good.
	- Replace all relevant fieldinfos of the element with one that 
		calls the solver for an update first.
- Intercept Sets
	- Intercept cinfo::GetField(const string&) which looks up field info
		from name.
	- Cannot intercept during Recv as this is time-critical.
	- Replace all relevant fieldinfos of the element with one that 
		calls the solver with an update after.

- Intercept ReversePiggyback triggered requests. This calls the Send
	function of the existing message. Which means that it uses the
	Field() info of the existing msgsrc. 
	- Replace the Field() of all outgoing messages with something asking
		the solver for an update before the Send() is initiated.
	- Replace all existing messages. Unrealistic ?
- Intercept regular msgouts
	- Are these ever called ? Perhaps it is a case of intercepting
	all incoming messages such as proc.
	- A global sweep through the associated messages. Consider what 
	we need to do for Proc messages. For efficiency the scheduling
	itself is altered. See scheduling below.
- Interecept regular msgins
	- Go up to src msgouts and intercept there. 
		- Would this be a general way of disabling the scheduling ?
		- Not clear what interception means here.
			- For procs it is disabling. See below.
			- For assignment messages it means forwarding contents
			to solver.
- Intercept entire cell message reqs for cell display
	- Design a composite dynamic message object to handle bundles of
	messages.
	- Do it by the book. Update all compartments as the display part
		is going to be expensive anyway.
	- Find a way for a global update signal forwarded to the solver so
		we don't have to go through all the intermediate compts.

- Delete entire tree of regular objects. Provide equivalent info internally.
  Take over all messages directly.
	- Too horrible. Solver needs to know too much about internals.

Summary: Zombie side is still difficult. It would be nice to be able to
replace the entire fieldlookup array with versions that know about the
solver. Cannot do this unless I replace the classinfo for all affected
fields, or unless I use the alternate element format.
For now it may be possible to do various intercepts in a piecemeal manner,
but it is not clean or efficent.


Scheduling side
- Intercept Proc msg outs
	- Proc should be disabled anyway.
	- The solver may want to farm out certain rare and tedious aspects
		of elm function. This would involve rather close design
		collaboration between solver and object, to make a separate
		process of the rare calls. Otherwise, like in sumtotproc,
		it could be a generic design feature of all elements to put
		special funcs in a separate proc stage.
	- Take over the role of Proc from the scheduler? In other words the
		solver should be a clocktick itself.
		- Too messy. What about non-solved elements, or multiple
			solves.
		- Actually not a problem. Just as we have
			multiple clockticks, we can handle multiple solvers
			plus leftover clockticks for the non-solved.
			In principle the solve should have fields for 
			path, dt, nextt anyway. target_func is not needed,
			but is part of the clocktick interface so will need
			this as a dummy.
			nclocks and max_clocks are internal things and not
			needed.
			The thread handling stuff is also appropriate here.
			proc, resched, reinit are all appropriate.
			procout is the business of the solver alone.
			- Need to keep track of 
			
			Could
			set up as dummy to 
		- As this is effectively what the solver does anyway, there
			should be something in the scheduling phase which
			knowns how to deal with solvers.

Summary: Will evolve toward incorporating solvers into scheduling in a
clean way. For now ignore.

			...........

Current design:

solver->each of the molecules etc. A single message.
Passes a solveinfo which has elm, field finfo*, bool direction, value.
msgsrclist is a genmsgsrc on the solver
msgsrcfield is a func_field. All the interesting stuff is done in 
 	void kderiv_finfo::set_solvefield(element* e, const solveinfo& si)

msgdestlist is a genmsgdest on the elms.
Its field is currently like a  ?
From viewpoint of solver:
In Recv it takes solveinfo info to the field specified in the job using
In Send it sends backward 

Basic problem is connecting triggered fields to the input grid.
Too tired to continue.

		
=============================================================================
10 May.

Skeleton worked out:

- Solver sends solveinfo msg to each solvee.
	- Solver also sets up forwarding on solvee for exisitng messages.

+ solveinfo is a special type that carries solvee element ptr as key, field ptr,
	is_get_request flag, and value.

- On solver, the msgsrclist is a generic nmsgsrc.
- The msgfield is a func_field for type solveinfo.
- All the clever stuff happens within the recvfunc, named set_solvefield.
	The get_solvefield func for the sendfunc is a dummy.

+ On solvee, the msgdestlist is in a special location so that it can be
	quickly checked for overrides. Perhaps a ptr to destlist.
* The msgfield is special, called solvee_field. It despatches the info in
	either direction.
+ The regular fields are taken over by solverelays.
	* When there is a SetField or GetField or Call once-off, then the
	calling function checks if the element is a solvee. If so, the
	calling function makes a temporary solverelay field and uses it.
	- When there is a permanent message, then the solverelay is inserted
	into the message field and does its stuff there.
Remaining gaps:
	* What about non-solved fields ? It is wasteful to intercept those.
		Presumably rare in occurrence, so no problem.
	- What about non-doubles ? At this point a template version is
		non-obvious, but I think that as the field info is coming
		along with the solveinfo, it could be dealt with.
	- What about ReversePiggyback ? This looks up the Field from the
		srclist, which has been replaced with the relay.
	* How to generally identify a solver ? Use first entry (index 0)
		in genmsgdest on solved object.


fading out. I am trying to set up the solver with the required message and
msgfields. Most of the basics seem done, now to do
	- Set up kderiv to handle message properly
	- Set up dest elms to handle messages
	- Handle path assignment func for kderiv to do the setup stuff.

=============================================================================
11 May
After days of effort finally have a version that compiles again. It
immediately dumps core.
Now it doesn't dump, just spits out an error message for each molecule.
Now it seems to set up the original solver messages. Now to go through 
each of the relevant msgdestlists and msgsrclists on the molecule putting
in relays. Later repeat the circus with other classes. But the nice thing
is that all the structure is now in place.

Well, the relays are in but are not working for gets.

Hooray, they work both for set and for gets. I was able to change nInit
and rerun with the new value. Now to go on to taking over existing messages.

Note that the current arrangement requires intercepts in multiple places.
- SetField, Getfield
- assign (2 places) and shf in the parser
- Retrofitting old messages
- In the messaging code for new messages

It is clearly desirable to be able to whisk out the old fields and put in the
new ones at the object/class level.

OK, message takeover working in part. A bit of a mess because I want to
return conc values, which means passing the n values back instead.

Conc values stuff seems OK. This is good.
Loads in acc4 model OK but gives nans on running it.
Num method may need work, or perhaps just a dt issue.

=============================================================================
12 May 2004.
Testing why the solver croaks for big models. Tried with 1 msec dt to replace
5 msec.

OK, it was just a dt issue. It needs 1 msec dt for stability. Time now to
move on to rk5.


Big picture: 

Core 		Numerics	I/O		Environment	Future

Documentation:	Solvers:	File formats:	Parsers:	Environment:
User		hsolve		readcell	+SLI		T Maze
Developer	*rksolve	asc_in		Python		Morris water
Manual		gsolve		asc_out		C		Mechanics
		3dsolve		disk-out			Kinematics
		*adsolve	XML				3d diff
		smolve
		gb3dsolve

Code:		Parallel:	Other pgms:	Graphics:	Realtime:
Element update	SMP		SBML/MWB	Basic widg	mech
MPP		MPI		Matlab		Plots		daq
		Farming		Jims XML	Cell
						Tree
						3d view		
						xview

								Other sim types
								Mechanics
								Kinematics
								Neural nets


Priorities:
Ksolve	15 May
SLI	June
Hsolve	July
Readcell	July
Cell objects	July
Basic graphics	Aug-Sep


Trying to code rk5, too tired.

=============================================================================
13 May 2004
Distracted day. Got a horribly inefficient and hacked version of rk5 to work,
mostly. It cruises to spectacularly long timesteps for enz.g and kholodenko.g,
remaining pretty accurate. But it croaks for test/acc4_1.6e-21.g (gives nans).
Considerable cleanup needed, but it holds much promise. Need to figure out
how to interface better with the scheduler, including it handling plots
itself for a more reasonable ordering of timesteps.

=============================================================================
14 May 2004
An interesting clue: In the kholodenko_explicit_enz.g model, the system
settles to steady state in about 600 sec. All the differentials are presumably
close to zero here. However, for some reason the dts
in the solver do not grow or even stabilize. Can I replicate this behaviour
in a smaller model?

OK, problem happens with buffering. e.g., buf_substrate_enz.g
fixed.

Now it runs the acc4 model reasonably accurate, but with a very slow dt and
it fluctuates a lot, so I think something is still wrong.

OK, replicated in minimal reaction in test/e_r_cycle.g and cousins.

                Enz
            ___________
           /           \
          /             V
        Sub <--------- Prd

Here the 1x rates (O 0.1/sec kfs) settle to the max 1 sec dt
The 10x rates (1/sec kfs) show the fluctuations in the range 0.1 to 1 sec dt.
The 100x rates (10/sec kfs) fluctuate in the rate 0.02 to 0.1 sec dt.
In all these cases the actual output is completely flat after the initial
settle time. So it is puzzling that dts don't get longer.


Something funny happens the second time round in rk5 when I run cyc100_equil.g
which is pre-equilibrated. This should give the clue.

I fiddled a bit with Simple Euler for a longer timestep. It doesn't look so
unreasonable now that the stiff equations will cause problems. As I discovered
years ago, the Exponential Euler method really does work unusually well for
this class of calculations.
Considerable cleanup later. Time now to do some benchmarks.

		Moose orig	scsim18 Moose EE	rk4	rk5
kholodenko.g 	12.83, 9.55	13.4	9.4		6.4	0.5
1e5 sec                                          (same dt as ee) (variable dt)

acc4_1e-21.g 	40.27, 27.15	22.22	25.9		failed	64
2000 sec

nonscaf_syn6				72		failed	140
500 sec

mega.g					128			160
20 sec

In summary: The rk5 method works spectacularly well in some cases, but
is mediocre in most because of stiffness. Its great merit is that it 
automatically finds its timestep. 

There is a remaining bug where alternate points saved by the solver are
repeated.

It would be nice to also work out a fully automatic timestep routine where
the solver takes over the scheduled clock.

For now we need to wrap this phase up and return much later with an
implicit method that can deal with the stiff equations.

=============================================================================
18 May 2004
Trying to figure out what I had done with the parser stuff. Can't. Will
go back to start of book and work up again.
Doing stuff in moose/tparser. The idea is to start using the moose
architecture from the beginning, as at some point we need threads to
handle i/o.

Trying to implement a simple addition/subtraction parser. The complex
threading stuff work but the parser does not.
Alto tried to do a really simple yacc/bison parser, but it takes values
but does not emit them.

=============================================================================
19 May 2004
Slowly getting close to it working. It seems to require at least one cycle
with a blank input to emit its output. Perhaps the carriage return is being
lost.

OK, almost fixed. Now it works for normal use but if it gets an error it
goes into an infinite loop of dumping error messages.

Some improvement there. The errors dont go on in a loop, but it does
take several cycles to get round to the point where the parsing is healthy
again.

Next:
- Test with additional syntax
- Test with reentrance
- SLI parser.
- Readcell.

=============================================================================
20 May 2004

Fixed previous issue with errors. Now even if there are errors the thing
terminates and is ready for new input on the next line.

Before going on to additional syntax, I'll back up this version of tparser
so that it can be used as a start for sli.

Additional syntax is not terribly exciting. Not keen on doing any of this,
but I guess the SLI is the next step.

Did an ugly cut-and paste job to fit in SLI stuff. Fading.

=============================================================================
21 May 2004

On mid stretch in SLI reincarnation, but it is essentially a case of 
chugging along with the compiler and bringing in stuff when needed.
It is incredibly messy and involves
rather a lot of accessory files. I would have thought that the use of
bison and flex would have eliminated much of this stuff. Compiles
tp.cpp and tp.yy.cpp, gets stuck now in tp.tab.cpp based on tp.ypp.
I need to be careful in importing the old genesis stuff because there
are many system dependencies here. I also want to eliminate some of the
uglier jumps that the parser does in a couple of places.

=============================================================================
24 May 2004

Trudging through masses of old ugly code rewrites. Currently reincorporating
stuff from eval.c, pages of compiler errors. Looks like I'll have to next
do stuff from shell/shell_script.c

=============================================================================
25 May 2004

Still trudging. Now eval.cpp compiles in. I have made so bold as to try
to link it, and only get about 4 pages of undefined references. PTNew
and PTFree appear to be major culprits.
=============================================================================
27 May 2004

Slowly cleaning up compilation. Down to less than a page of undefined
references at the link stage.

=============================================================================
28 May 2004
Slowly cleanup continues, no visible progress in terms of undefined
references. Most of them are now due to not having functions as
methods of the myFlexLexer.
=============================================================================
29 May
Still trying to clean up. 

=============================================================================
30 May
Finally got the whole mess to compile and link. Of course, it does not work.

- Comment handling seems OK
- Is able to identify the two commands (quit, echo) I have hard-coded in.
- Does NOT execute them. Don't know where to go to look.
=============================================================================
31 May
Got execution going. The problem had been that the parser expected a
carriage return \n in order to do anything. 
- Correctly evaluates stuff
- Seems to create integers and assign values correctly.
- Seems to print out evaluated state of everything.
- Does not call any functions.

One step further. Now it does call functions. 
- Does not execute loops or conditionals.
* Dumps core when it encounters an unknown function.
* Fails to echo floats, works with ints and strings.
* Adds strings OK.

=============================================================================
1 June.
Clearing up bugs.

* Does not execute loops or conditionals.
* Does not handle functions
* Dumps core when it encounters an unknown function. (now test for null command)
* Fails to echo floats, works with ints and strings. (initalized float_format)
* Adds strings OK.
* Fails to load script file

OK, got while and for to work on a single line if I separate the line with
semicolons. So the problem seems to be with multiline calls.

OK, got loops and conditionals and functions and nested functions to work.
This is a MAJOR step along. Still fails to load script file.
It is not clear to me where, if at all, it actually reads the included
script file. Need to track down and that would be the missing point.

OK, it happens in shell/shell_io.c:sgets which calls shell_io.c:GetLineFp().
In lex.yy.c it redefines YY_INPUT as GEN_moreinput(buf, n), which calls
sgets.  Seems to be triggered by doing PTNew(INCLUDE, filename, NULL, NULL)

Still confused about where the calls actually begin.

=============================================================================
2 June.
Looks like the system works like this:

- On startup, the system plugs in tty input as the first script. 
- As we include scripts, new ones get inserted into the script list.
- The current script is always the latest on the list
- As scripts get finished, they are removed from the list and it falls back
	to the last one.

If correct, this means that all the script file juggling happens away from
the parser itself. Our job is then just to feed strings to the parser and
let it deal with stuff.

OK, I think I have something that works. Much more extensive testing needed,
and it will probably reveal more bugs. Also I still need to put in a huge
number of support functions. But the basics work.

=============================================================================
4 June.
Elements as generic containers.
	class element {
		singlemsgdest parent;
		string name;
		const cinfo* mycinfo;
	};

	fieldlookup accessed only though cinfo.

From 28 April
- Could elements be completely generic containers, and hold only a
	pointer to the data class? The message lists could just be fields,
	and stored in the regular fieldlookup array. Better use the genmsg
	lists, which are already defined.
	Problem is the management of all the msgs and the functions. Also
	the static field initialization for classinfo and fieldlist info.
	However, this static field initialization and func management
	does not necessarily have to be done with an element subclass -
	could be any specialized class, or a subclass of cinfo.
	Cost: A pointer to the cinfo, a pointer to the data.
	Also: Each msgdestlist now will have to store 3 ptrs rather than 2:
		data (new), parent, field
	Savings: (Possible anyway) Now that msgsrcs are templated, we don't
		need to save msi (finfo) ptr in msgsrclist

=============================================================================

5 June
Functions that the generic container must handle
- Storage of comput class data
- Creation
- Deletion
- Copies
- Array copies
- Array lookup for elements
- Array lookup for fields
- Access to class info
- Access to message info
- GetCinfo
- Inheritance
- Find parent
- Find children
- Looking up fields
- Converting element data to and from a field type
- Adding msgs
- Dropping msgs
- Message relays
- Message lookups, accessing message fields. msg[i].type, msg[i].parent...
- Whether to abolish msgsrclist fieldinfo.
- Whether to template msgdestlists
- Calling msgfuncs
- Solver message forwarding
- Object virtualization and remapping
- Object serialization and dumping
- Extended fields

Also should decide on utility and level of operation, and inter-simulation
compatibility of fids, eids, and cids.
	- on 1 CPU
	- on SMP
	- on clusters
	- on separate machines, running as distinct but communicating sims.


OK, this is a nice list. When should I tackle it ? I will need a solid month
sometime to clean up all items and get the code back to its current
functionality.
From 12 May, here are some things to work on in schedule:

Ksolve	15 May
*SLI	June
Hsolve	July
Readcell	July
Cell objects	July
Basic graphics	Aug-Sep

So by this list I should now turn to Readcell. In the Moose version I could
- Use Lex ?
	Cleaner parsing
	Handle line breaks more sensibly
	Allow simpler encoding of channel definition
- Provide a channel definition section, preferably language-neutral. 
	Dave Beeman has something on these lines.

There are aslo several other objects, most notably synchan, that need
to be reimplemented more intelligently.

=============================================================================
22 June
First go at doing readcell parser.
	- Compile error about 
	"readcell.ypp contains 1 useless nonterminal and 1 useless rule"
	- Doesn't really do any evaluation, need to fix file io
	
=============================================================================
25 June
Slowly getting it to work.
It can now march through part of the mit.p test file.

=============================================================================
27 June
Values now accessible within the yacc portion. Next:
* Make vector for channels. Note that not everything is a channel.
- Parse entire mit.p
	Here there is a problem. It doesn't seem to get nicely to the
	end of the comptline statement; it always give an error for the
	next compt.
- Parse files which set up prototypes
- Tie back in to moose calls.

=============================================================================
17 July.
Back to work after hiatus. Working on implementing adaptive stochastic
method. Turns out to be singularly incompatible with Moose architecture,
though in principle I could do it using a set of additional messages, or
by heavy and perverted use of reverse message piggybacking. Instead I'll
set it up using a distinct solver: adstoch. Set up to duplicate GENESIS
stuff initially, later try refinement.

Steps:
+ Duplicate kderiv
+ Set up structure:
	- Array of molecules: n, A, B
	- Array of bufmols: n, nInit // for fluctuating about mean
	- Array of sumtots: n, startptr, endptr
	- Array of reacs: kf, startptr, endptr, kb, startptr, endptr
	- Array of MMs.
- Set up comput sequence
- Set up mapping to moose


Also, by way of light enterntainment, setting up graph object in ../gui.

=============================================================================
18 July
Implemented graph and dialog. Dialog doesn't know how to reposition, other than
that it looks promising. Need to implement a base widget class for the 
generic fields x y w h etc.

After much messing around, sorted out repositioning: the dialog has redefined
the position method to do something different. Gah.

Implementing adstoch, the adaptic stochastic solver. Compile OK but link fails.

Getting closer. Implement random no generator : in progress. 
=============================================================================
20 July.
Random number generator in.
Framework for adstoch in. Filling in details now. 
+ Need to put in reaction specification
- Need to put in enzyme stuff.
- Need to put in sumtots and buffers.

Working on reaction specification. Fading.
Idea is to convert the halfreacs into class heirarchy with zero, one, two, 
etc. substrates. Faster than the old version, will have to provide general
case with n as a vector. I think up to n=3 covers 99% of cases.


=============================================================================
21 July
Slowly getting reaction specs in, cleaning up compiling.

Nearly there. Numerical errors but I think it is close. Using
test/onereac. and tworeac.g

Looks like it is working for one and two reacs.

Working on enzyme. Fading. Tackle tomorrow.
=============================================================================
22 July
* Need to put in reaction specification
* Need to put in enzyme stuff.
* Put in mm enzyme stuff
* Need to put in sumtots and buffers.
- Fix volume scaling of generic EE method
- Fix tables for RK and adaptive stochastic sims.
- Fix multiple timestepping for AD.
- Fix conversion from SLAVE  to SUMTOTAL messages.
- Design tests for stochastic version of method.

Sumtots seem OK, buffers have bugs with enzymes.

More testing.
Turns out the old EE has problems in volumes other that 1.666e-21. See
enz1e-15.g. rksolve and adsolve handle it OK.
It would help for debugging if the adsolve had a deterministic mode.
Set up.

Test				EE		RK		AD(det)
buf_enz_enz.g			OK		OK		OK
bufreac.g			OK		OK		OK
buf_substrate_enz.g		OK		OK		OK
enz1e-15.g			Bad		OK		OK
enz.g				OK		OK		OK
enzreac.g			OK		OK		OK
enzreacgrp.g			OK		OK, tail	OK
enzreac_unidir.g		inacc		OK		OK
e_r_cycle100.g			3%		reference	5%
e_r_cycle10.g			OK		OK		OK
e_r_cycle.g			OK		OK		OK
mm_enz.g			OK		OK		OK
onereac.g			OK		OK		OK
tworeac.g			OK		OK		bug (fixed)
tworeac_unidir.gA		OK		OK		OK
testsumtot.g			OK		OK		bug (fixed)
voltest.g			OK		OK		10% (due to n-1)
voltest2.g			OK		OK		10% (due to n-1)
test_table.g			OK		-		OK (24 Jul)
test_tab_once.g			OK		-		OK (24 Jul)
kholodenko.g			OK		OK		OK
kholodenko_explicit_enz.g	OK		OK		10% ? Fixed.
								Needed initdt
kholodenko_sumtot.g		OK		OK		OK
acc4_1.6e-21.g			Poor		reference	?
acc4_1.6e-21.g(on jul 23)	Poor		reference	Poor, same as EE
acc4.g
ip3.g				Can't handle INTRAMOLS
nonscaf6_1.6e-21b.g		OK, num?	Errors		Same as EE
nonscaf_syn6.g
mega_1.6e-21.g
threadtab2.g
kholodenko_2node.g
gpcell.g


At this stage we have basic functionality of the adaptive stochastic
method working. Fuller testing is needed specially for stochastic runs.

This version is going out as a reference version to indicate the starting
point of the software as it goes into the contract with BioPhase. At this
stage the code is under the GPL. Future licences will be LGPL.

There are various other licenses applicable to FLTK and to the Merseinne
Twister code.


Later:
Some improvement in the kholodenko_explicit_enz.g run by putting in variable
dt runs for the adaptive adrun solver. Still fails for acc4_1.6e-21.g
=============================================================================
23 Jul 2004
Some attempts to fix problem.
- Called process for sumtotals as part of reinit
- Checked for and handled cases where there are dangling enzymes.
Still fails for acc4_1.6e-12.g
	Now need to check the n(n-1) issue for higher order reactions.

Looks like the code is actually not good to try to do both kinds with the
same code. What I'll do is set up alternate halfreacs to deal with
EE vs stoch calculations. 

Done. Instead of alternate halfreacs, I use the existing halfreacs and 
have an EEProcess method. Works. Now to fix the n(n-1) issue with the adstoch
method.

Done, need to test.

Now looking at sumtot input. This raises interesting Qs for general solver
handling. Options:
	- Build replacement message from source to solver.
	- Allow existing sumtots to be handled, read off object
	- Send proc message to source, use reverse piggyback to get value.
	- Build replacement message from source to solver, solver uses 
		reverse piggyback to call proc for source.
	- Intercept Sumtot msg to molecule using generic solver message to
		zombified molecule.
	- Intercept Sumtot msg to molecule using special solver message to
		zombified molecule.

OK, most of the above are moot because variable dt solvers will need to send
proc messages with special times. Remaining candidates are:
	- Send proc message to source, use reverse piggyback to get value.
		- Will need to retain info about original scheduling in
		  case solver is removed, since proc msgs are single.
		- More in line with usual message from solver to zombies.
		- Problem in calling reverse piggyback: proc normally does not.
	- Build replacement message from source to solver, solver uses 
		reverse piggyback to call proc for source.
		- The reverse piggyback call will need to be extended to do
		this.
	- Send proc msg to source, send message from source to solver.
		The point of this is that the solver is supposed to be _fast_,
		and should handle occasional non-solved situations as fast
		as possible. This will necessitate a special solver msgdest
		field, possibly even getsolvefield. The destmsg stuff should
		be labelled-line, that is, have direct ptrs to the target data.

=============================================================================

24 Jul
	- Use a genmsgdest that has all the info, or use some stuff in the
	solver? I think the genmsgdest should deal with all of it.
		- Keeps the solver from getting bogged down with details
		of all msgsrcs.
	- From the point of view  of multiproc calculations, should ideally
		send out the request early and later scan msgdests
		for it. But this is probably a premature optimisation.

Hooray, the table input now works for adstoch.
Still need to figure out how to handle variable dt with the rksolve.
This is part of the problem with taking over the scheduler. Some but
not all of the external objects will need to provide data samples at
variable dts, as in RK. Some won't be able to do it at all. Interesting.

=============================================================================
25 July.

Some ideas:
	- Use the new fast precomputed message lookups for other messages
	to and from the solver

Here is the overal BioPhase schedule. I don't know what t0 is, probably by
July end.
			Time (months)
Initial training: 	t0 + 1
Adaptic stoch solver:	t0 + 1.5
Translocation objects:	t0 + 2
GUI API specification:	t0 + 2
Genetic expression:	t0 + 3
Fast solver:		t0 + 4
Exact stoch solver:	t0 + 5
Wrap up:		t0 + 6
Bug fixing:		t0 + 9

I want to implement two kinds of translocation objects. 
- First, one that behaves like the existing one in kkit. This handles
transport processes that insert a delay in expression and arrival of
some molecule. Transport in kkit is implemented by a reaction in series
with a table, passing in the B (-derivative) term of the supplying molecule.
The table acts like a shift register.  At the far end the value in the table
emerges and is passed to the MM_PRD (equivalent to +ve derivative) message
of the target molecule.
- Second, something more like the cell biology of the system where we have
formation and turnover of vesicles, which move around. This is needed in 
any case to replicate the model of Resat et al. Here are some features we
need to implement:
	- Formation of new vesicles, each containing a predefined reac system
	  Typically this reaction system will be a subset of the system in
	  another compartment, say the golgi.
	- Initialization of values of contents of new vesicle. Some rule
	  related to current values in main compartment.
	- Surface/volume considerations for membrane and soluble molecules
	  at the time of creation of vesicle.
	- Movement of vesicle: Certain time lapse before it is accessible
	  to other compartments. During this time reacns proceed independently
	  within vesicle, or in equil with some fixed (e.g., cytosolic)
	  surround. Perhaps attach a timer/movement object onto the vesicle.
	- Fusion of vesicles, adding contents back to appropriate parts
	  of content of target compartment, say endosome.
	- Control of fusion/formation of vesicles through other reactions.

Some interesting features about writing solvers for this situation are:
	- Many vesicles with same reactions, just different concs.
		- Could have multiple solvers working nearly independently.
		- This is a situation where the ability to share reac schemes
		  between solvers would be handy. See cell networks and hsolve.
	- Creation and removing vesicles.
		- Do we define all the reactions for all the vesicles at start
		  and have a way of flagging some as not yet existing ?
		  Problem with having unexpected growth in number of vesicles.
		- Or, do we form and schedule new ones as needed, likewise
		  removing old ones ? This should be OK in Moose.
	- Initialization and destruction rules involving other compartments.
		- Trigger for formation. Need a conversion step from a 
		  pool of n molecules to n individuals. Applies not only to
		  vesicles, but also to scaffold-like complexes or for that
		  matter to SNARE complexes. Something like a reaction where
		  n molecules come in, and with a certain probability,
		  m complexes come out, each obeying certain rules. So this
		  'reaction-like' object is the key here.
		  	- Have a link to prototype reaction scheme
		  	- Starting stochiometry is identical to that of source
		  	molecules
		  	- Define equilibration reactions to 'fill' vesicle
		- Trigger for destruction. Similar conversion step, except
		  it acts the other way. Each complex bears trigger(s).
		  	- Trigger is again like a reaction. Need to have
			  both all-or-none rules as well as probability rules
			  depending on various concs.
			- Define ties to pools in fusion compartment that
			  take up all the complex molecules. 
			- Need checks to ensure that all molecular species
			  are accounted for
			- Freeing and descheduling of solvers/reactions.
=============================================================================
27 July 2004.
Minor glitch in loading models from a script. Turns out that the 
system tries to read the script, then do scheduling. However, if the script
itself tries to run the simulation, then we get a core dump. The
reason why it wants to do scheduling after the script is because of those
messy sumtotals. Need a special search function on the appropriate
clocktick to obtain the list of affected molecules, or need an extension
to the wildcarding. Then need to ensure that resched on the clockticks is
called. Should also have an addsched command for use later, where just
the new objects get suitably scheduled.

- Extended WildcardFind to handle fields.
- Set up scheduling to use extended wildcard path rather than the ugly scan
	through molecules.
- Tested on two models. 
- Fixed issue with molecules that did not always return correct mode to
	indicate sumtotals.

Now need to reorder the loading of external files vs scheduling in main.cpp.

=============================================================================
28 July 2004
Much fun doing the external file loading stuff. Now it seems to work,
except that any run command is non-blocking. Need to set up so that 
run commands are blocking from within a file, or to put in semaphores.
Or have a blocking run call as a default, and a nonblocking or even farming
version.
All this was so that I could test the transport.
Also had to fix the plot so it doesn't do multiple points even if the
source of the message is actively propagating them out.
Anyway, tested and surprisingly, the transport itself seems to have worked
first time. A contrast to all the stuff I had to do to get at its function.
See test/transport.m.

=============================================================================
9 Aug 2004
Begun work on the kinetics/budding object. This needs a functioning
Copy command, applicable to all elements.

In element.cpp reworking the old DuplicateMessagesOnTree code. This
takes tree A and tree B, and creates messages within B that are equivalent
to messages within A.
Also wrote DuplicateMessagesOutsideTree. This function
takes tree A and its duplicate tree B on a map. A connects to outside tree T,
and this function conects B equivalently to this outside tree T.

=============================================================================
10 Aug 2004
An API for SWIG and any other interface:
- create, delete, copy, move
- addmsg, deletemsg
- set, get
- Foreach: wildcarding
- Call (execute MOOSE method from script)
- Execute (Execute script function from MOOSE)
- Some threading stuff.
- Help

Now to get the Copy to work. To check: create the kholodenko model,
duplicate it including graphs, resched, run.
First try on test_copy.m: spectacular 200+ Mb core dump.
OK, sorted out: it was trying to do the recursive copy of /kinetics to 
/kinetics/k2 but as it added k2 before it was done, it became infinite. I
wanted to check this very issue. Anyway, after a bit of debugging the
tree copying stuff works onto another location, but the things that are
copied are not molecules etc, as they do not have an internal copy operation.
Need to put this into .mpp

OK, major change coming up so I need to put everything into a separate
subdir in case I want to back out later. I need to put in a prototype element
for the Create command. I earlier used a separate Copy command, but this
is cleaner as it is the convention for many languages.

=============================================================================
29 Aug 2004

Returning to code development after a long break. Regarding Copy command vs
prototype on creation. Irrelevant. The more fundamental feature is to make
a good general assignment command for any object to one of its derived or
sub-classes. Assignment following creation is no problem after this.
Anyway, now that we have prototype on creation we'll follow it through and
take the opportunity to eliminate the Copy method.

The cases where assignment is ambiguous is when the object may have allocated
storage, pointers or other things. In C/C++ such cases also need special 
care. But in moose the assumption of shared memory is dangerous, e.g.,
across nodes. So we'll make the following rules:
- All objects give the illusion of being completely independent.
- When an object can share memory (e.g, channel, solver) it must maintain
	a flag to indicate if the table has been duplicated. If so, any
	attempt to change the table leads to its reallocation.
- If you really want to have a shared table, it should be implemented as a
	separate object which messages to the sharers. Then any association
	is explicit.


Traversing message links in a manner similar to traversing child heirarchies.
Specify the context for the listing...

* Intelm has a MOLECULE_H define.
- cinfo.cpp::GetField should return an automatic field for self.
- cinfo.cpp::GetField should return automatic fields for class info and 
	field info
- Need to provide an assignment operator for all elms.
* Complete the prototype on creation stuff, eliminate Copy. 
	Done till gui. Still several dirs to do.
- Do some documentation for each moose class
- Do scheduling documentation.

=============================================================================
30 Aug 2004
Completed the prototype on creation stuff, implemented Copy using it.
Implemented the Move command
Tested it all out using test_copy.m which duplicates the kholodenko model.
Works.
Next: Use all this in the implementation of budding.
In the budding object, need to decide how to handle the prototype, the
external messages and initialization.


=============================================================================
31 Aug 2004

Prototype: provide an element ptr. I would like to use messages, but that
would require a generic msg to reach a neutral.

Issue with making multiple vesicles. At pesent there is no way to 
quickly equilibrate so we don't have to.  Instead looking at a volume
scaling (possibly already a good idea) for removing molecules from
proto to vesicle.

=============================================================================
1 Sep 2004
Much design work on budding, fusing and proximity. Saved in documentation.
Started implementation on budding.

Finished implementation of budding, compiled successfully.

=============================================================================
2 Sep 2004
Back to budding. Key step missed: scheduling. Close look at process. Easiest
is to do complete resched, or at least resched of the existing clockticks.
Wasteful as it scans entire model. Better option:
- Have sched definition separated between path search and filter
+ Have separate add_to_sched method to run a wildcard list through filter,
	and add in matches.
- Monitor progress of add-ins and have a way to notify main scheduler when
	a big resched, such as rethreading, should be done.

+Implemented entire filtering stuff, not yet compiled or tested.
+Implemented appending to clocktick.
+Implemented appending to all jobs.
+Implemented budding object calling the append function.
	- Need to do using a message
-Need to figure out a test routine.

=============================================================================
3 Sep 2004

Now that per-element scheduling is efficient, I can implement automated 
scheduling upon creation. Is this desirable ?
Per element Scheduling discussion:
- Eliminates a step in object handling. GENESIS has RESET issues which are
	confusing.
- Do we ever want to create an object without scheduling it ?
	(If it is going to be solved. But the solving will presumably be done
	before the scheduling call)
	(How does the solving work with scheduling ? See below.)
- Would it be more efficient to wait till a whole lot of objects are added ?
	(Could do the automatic rescheduling just before starting a run
	in cases where the simulation was not running)
- Similar problem: for multithreading, rescheduling is tricky and may
	need some extra analysis.
- More complex scenarious may permit multiple schedulers. How to reschedule
	automatically then ?
- Solvers remove objects from sched lists. Selectively ? Yes, e.g., vesicles.
- If we build an object on top of a running simulation, we don't really want
	stuff to happen to it till all bits are ready. Consider adding
	a molecule, and then a forward reaction, and then a backward
	reaction. In the interim, the molecule would build up stuff and
	disrupt the running simulation. This issue goes beyond instant
	scheduling: even without the scheduling, the incoming messages may
	cause problems if they are triggered by already running objects.
	(Could have the addmsg for the scheduler to trigger a reinit
	operation on the object)
- Do we want to block object formation during simulations ? No, but we
	do want to make it barrier protected so that the object formation
	as well as its messaging are done between timesteps.
	Easy to guarantee for copies and deletes like in the budding/fusing.
	For tty and graphical addition to a simulation, we would like to
	be able to do the object construction including messaging while
	things are running, and then commit it in a safe manner.
	Means we need to have the new stuff made on a non-scheduled parent,
	and provide hooks for messages to/from existing objects. At
	commit time all these are moved on-line.

Summary for Per element Scheduling:
- Yes, automated scheduling.
- Takes place at the 'start' command or between timesteps if it is an
	internal operation such as budding, to handle max objects in
	sched operation.
- Special situations for running simulations, solvers, and multithreading.

Solvers and scheduling
- Solvers as clockticks with varying dt. Clockproc needs to be smarter.
	- For starters, steps each solver one step, estimates their next time. 
		Need a way for all solvers to restore old values/apply new
		values only when directed to.
	- If any other clocks need updating before earliest next time, do so
	using old values from solvers. Should only apply to readonly values.
	- Find youngest solver (advances the smallest). Apply its values.
	- Heuristic: Update other solvers depending on how closely they
		are coupled. If loose, they can be ignored.
	Repeat last 3 till done.
	This has the advantage that any request to schedule something is
	handled by the solver itself.

- Solvers as clockticks, with specified maximal dt.
	Again, the solver needs to keep from updating its visible part
	till approved.
	Here the scheduling is pretty ordinary. At maximal dt the solver
	can choose whether to reassess its next (internal) time, or to
	carry on.

- Solvers as clockprocs controlling everything else.
	Too much work for the solver, unless it is derived from a suitable
	class that also knows how to schedule other things like graphics.
	Even then it is ugly.
Summary for Solvers and Scheduling:

Multiple schedulers. 
- Multiple simulations within the same instance of MOOSE.
- Do not enable multiple schedulers. If you want to do something like that,
	run multiple instances of moose and get them to talk to each other
	by internode messaging.
Summary:
- Second option is reasonable and simple. Let the OS worry about it.


........................................................................

Implementation: In the process of compiling the simple budding stuff with
the on-line scheduling handled using filters. Later need to test filters
on their own and then to replace all scheduling with filters.
*Compiled.
-Test filters
-Replace scheduling

Some progress on each of those. The system currently compiles but fails
to work (no execution of objects, it seems) when run.

=============================================================================
4 Sep 2004
Finally looks like filters work. Just at the beginning of sorting out
scheduling with them. I'll have the Create method automatically run each
object through the filters on the sched. Minor extra overhead compared to
doing a list of the objects, but simpler. Avoids the issue of deciding
how to queue objects for scheduling and when to schedule them. However,
- will later need to deal with issue of doing this at runtime.
- Will also want to provide utility functions to disable/enable objects
or object trees after creation.
- Will need a simple way of modifying schedule and clocks, including their
	associated elms. Resched should clear current schedule and redo entire
	lot while steering clear of disabled objects.
- Will need intelligent way to handle disabling/re-enabling with solvers.
- Are there objects which can run both in sched and non-sched modes ?

=============================================================================
5 Sep 2004.
Slowly cleaning up the mess of the scheduling stuff. Implemented a
different form of reset/resched, that uses the filters. Seems to work
fine. In particular, the reset and resched commands can be issued as often
as needed and it still seems to work OK. 
Reinit: Zeroes out simulation time. Done using piggyback calls through
        the process messages.
Resched: Redoes the entire scheduling message structure, but without
        doing a reinit. The simulation will start off from where it stopped,
        possibly with a change of scheduled objects.
Reset: Resched followed by reinit.

To optimize Create() calls in massive simulations, we could have a 
message from the appropriate cinfo to the relevant clockticks. This could
in part even replace the filter stuff, though we could still will retain
filtering for wildcards, and will still need filtering for field values.

Now to test the budding objects. How about a simple cell-division model
where we have a set of reactions where the molecule number increases till 
budding occurs. Would like at the time of budding to create an additional
plot. Also interesting to see how we can reinit the time of plots etc
to the current simulation time rather than the time of their existence.
Instead of dt, the process message should be passing a simstate ptr with
dt, current time, tty, thread and similar info.

Working on it, using test/division.g as the test script. Rather early in
this found some problems with the message copying.
- There is one entire scan through the messages which seems to fail. Don't
	understand yet. Are we making lots of generic msgs ?
	No, it appears to have to do with the parent-child messages. Not
	quite clear.
* There is currently no provision for copying generic messages. As all plots
	are of this kind, this is a problem.  Fixed.

So the current version of division.g works. It simply copies a model including
its plots. Would have been much simpler not to have dealt with the generic
messages, but would have been an issue later.

Current round: barfs at assigning the paths for proto etc to the budding.

=============================================================================
6 Sep 2004.
OK, budding works, using division.g as test file. Anticipated issues with
plots did not arise because the plot duplication is perfect, including
history of the plot. 
- Will need some way either to run an initialization script, or to
	handle yet another level of specialized duplication. Suppose the
	budding object itself was on the prototype being duplicated. Then
	the proto should be the current cell, and the eventual container
	should either be different or there should be some naming changes
	set up.
	* Proto could be a relative path.
	- Buddings could communicate with a master counter for child index.


Working on the recursive budding. Several fixes and a small but powerful
addition to the DeepCopy functionality, where after the copy is complete
a post-copy virtual function HandlePostCopy() is called for all new objects.
This helps for the budding because it needs to do stuff with relative paths.
Even more so for future solvers, which will have to rebuild their path info.
Sounds good, but it all dumps core right now.
- Dies if any budding object is in the replicated set, regardless of whether
	it is called or not. Let's now check copying, followed by deleting
	of the original
	: Copying works.
- Dies if a copy of the budding object is retained, but with null 
	paths for proto etc.
- Does not die if the same copy is retained, but does not initiate any 
	budding steps.
- Does not die if the same copy is retained, even if it initiates budding
	events of its own.
So looks like some of the problems are due to problems with paths. Let's fix.
Fixed - initialization issue. Now handles empty budding objects with aplomb.

Still dies when asked to do recursive_division.g
- Is it the relative path? No, croaks whenever a budded budding tries to bud,
	even if it uses absolute paths. (I have to come up with a better name).
- Is it the duplication of external messages? No. Went through it, and the
	only messages duplicated were the correct ones.

OK, figured it out. Ugly indeed. The addition of a new proc message to the 
new budding object alters (including realloc) the msgdestlist of the simclock
just as it returns from processing the old budding object. Due to reallocation
the msgdestlist iterator is no longer valid.

Options:
	- Save the elist with the new objects, handle it at a safe time
	- Split the scheduling of the budding object

OK, did first. Tested. Works. Grew it up to some 1300 cells in 200 sec.
- Need to fix issue with parentinfo when attempting to duplicate messages.
- Minor change to add_elist message so instead of overwriting target_list,
	it appends to it.


Working on implementation of fusing object. Issue here with scheduling
again. Suppose we delete a bunch of objects in the middle of the calculations.
OK, provided the target object (the fusing object) is on a different
clock from everyone else. How do we avoid issues again with the iterator
for the process msgsrc, given that the target fusing object vanishes ?
Also, how do we prevent the fusing object from starting off too soon ?
A tether message that is not duplicated is one option. Perhaps on the
reinit message. 

=============================================================================
7 Sep 2004
Another rather simple option for the fusing object keeping silent is to
have a field that defaults to the active state, but in the prototype is kept
in the inactive state.

Implemented fusing. This again involved some consultation with the scheduling,
again because deleting objects midstream might mess up ongoing iterations
through the element list.

Got fusing to work, even up to dumping plots the instant before they
are deleted. As I implement more complex functions, I feel that the
expressive power of MOOSE is indeed turning out to be very good. The
test file is an extension of the recursive budding file, now there is 
budding as well as fusing taking place. See test/recurse_div_fusing.g

Fixed the two points above: parent info complaint and add_elist appending.

Next: Several things to try for:
- Gene expression object. Would need to read Savageau.
- Parser stuff: Need to learn SWIG. Need to specify key parms. Need cwe/shell.
- Graphics stuff: FLTK based. Need some of parser interface stuff. Need plot.
- Document adstoch solver for Meena. Document solvers in general.

=============================================================================
8 Sep 2004.

Somewhat unexpectedly was able to locate a Savageau paper and implement
the gene_s object to handle his simple and elegant representation of genetic
expression. Originally there were problems due to network issues at Cell.
Still to test. I think an n_step object would complete the initial portfolio
of basic gene-expression objects.

=============================================================================
9 Sep 2004
Working on n_step. Would like to look up individual points along it.
There was a method for doing this for tables. Seems to use the CloneVec
command for the field. Uses basecode/vecfield.h, but this is not part of
the main header. Also used in kderiv_wrapper.cpp.


=============================================================================
10 Sep 2004
Implemented n_step. As usual, the implementation resulted in considerable
refinement of concept.

Need a way to fit constants into message args. An adaptor ?
In the meantime, need to have the n_step deal with reac msgs for
its product.

Looks like n_step is working. Not terribly exciting. Tested using
test_n_step.m
Would like an analytical test. Would like to upgrade to implicit/Crank
Nicolson solution. Would like to use Gillespie-type method.
=============================================================================
13 Sep 2004.

Back to adaptive stochastic method. Some fixes in progress to get it to work. 
- Scheduling changes had confused method considerably.
- Had to put in various fixes for 64-bit mode, quite unrelated to method.
- Method seems more stable and accurate than the one in GENESIS. In particular,
	mass conservation issues are no longer as evident. Not quite sure why.

=============================================================================
14 Sep 2004.
Some issues cropping up with adstoch method. In particular, 
tworeac_unidir.g gives glitches, and in acc4.g these scale into NaNs.
Ran tworeac_unidir.g with smaller dt. Glitches persist.
Ran tworeac_unidir.g with double order reac reduced to single. No glitches.

OK, figured out bug with tworeac_unidir.g: confusion with submin and prdmin
in halfreac::UpdateStoch.
This fixed the tworeac_unidir bug.

Found another potential bug: when we have higher-order reactions, the dn 
must be small enough that we never have a -ve n. However, the submin
calculations don't take higher-order molecule changes into account.
Attempted ugly fix by setting submin to 1 in such cases. Doesn't fix
problem with acc4.g

Did other checks for n going below zero, no effect.
Checked. It is using the submin and prdmin quite a lot. Those are likely
issues.

=============================================================================
15 Sep 2004
Closer analysis of acc4.g output. At least two things are happening, possibly
unrelated. First, the PKC blows up from about 0.1 to about 1. This happens
smoothly, that is, over the course of about a second or so. Second, MAPK
and everything else goes nan over a single timestep.

Did a separate verification that the loading of the model is OK: ran the
adsolver in EE mode and compared with a vanilla run in EE mode without the
solver.

Buffered PKC to 0.1 and 1 respectively. Get nan in both cases at t = 446 sec.
Suggests that there is an issue with PKC step feeding into MAPK cascade.

OK, found and fixed one major error: I was assigning submin to n without 
testing that it was actually larger than n. This may have resulted in a
huge value of submin. This fix corrected the nans. The blowup of PKC continues,
although the buildup is not quite as fast.
This looks a little like the issue we had with the MAPK blowup in the AS
method on GENESIS. 
Happens with adstoch even when dt is reduced by 10 fold.
Confirmed that the CONSERVE messages have nothing to do with it. Identical
output with or without these messages.

Plotted some more fields. AA is the culprit: builds up indefinitely.
Trying to track down, nothing obvious. Will make a reduced version and see
if the same effect occurs. Simple reduced version: check_AA.g: does not give
effect.
Made a reduced version from the original acc4 model: check_pla2.g: does give
effect. PLA2-Ca* is the first molecule to start buildup.
Seems to happen just as its count exceeds 100. Could be important.

~100       30000   0.0013    > 100    5.4     ~100        lots
PLA2-Ca* + APC <=========> complex  --------> PLA2-Ca*  + AA
                21.6

dt = 0.005, so 
	p1 = 3e6 * 0.005 * 0.0013 = 19.5
	p2 = 100 * 0.005 * 21.6 = 10.8
	p3 = 100 * 0.005 * 5.4 = 2.7

80    90          0.001   ~100
Ca + PLA2 <===========> PLA2-Ca*
            0.1

pf ~ 0.04
pb ~ 0.05

So it should be doing determ calculations at this point for the enzyme.
There are stoch inputs in the form of the Ca binding step. Forward is
stoch because n < 100. Back is determ, because the prob limit is 0.01.
So this could be a numerical thing. If Ca always gets treated as below
stoch limit...

Ran it at 10 X vol. Still misbehaves in same way.
In an odd coincidence, the time at which this starts acting up is almost
exactly 100 sec.

Found and fixed another bug: the buffered mode was using n, not ninit.

OK, I think I have found a problem: when the dn is very large, then 
the comparison with submin or prdmin always results in dn being truncated.

The related problem is that there are a whole lot of redundant 
halfreacs. If they were eliminated then the calculations would go faster
too.

OK, finally sorted out. The above diagnosis was correct. Initializing
submin and prdmin to a large value sorted out the problem. Still need
to optimize the adsolver in the following respects:

- Eliminate all halfreacs with zero terms
- Create additional specialised halfreacs e.g., for a duplicated substrate
- Have dedicated halfreacs for cases where one term is buffered ?

=============================================================================
20 Sep 2004.

Fixed some clutter with the transport, still to test. The fixes enable it
to talk directly to molecules. Will need later to define an API so that
all these kinetic objects can also talk to solvers.

Now to wrap up this phase with a bit of graphics capability. This will
require some functioning inheritance facilities in MOOSE.

=============================================================================
21 Sep 2004
Implemented base_widg to serve as the base for fields like geometry,
visibility, colour, font, and so on, for all other widgets.
Looks like the existing inheritance stuff works OK, at least so far. 
Converted all graphical objects to be subclassed off the base_widg. 
Much cleaner. 
Next: Get the graphics flrun stuff scheduled, not like normal objects but
on a special job/thread. Then make an interface for the squid demo and
a simple kkit load and run graphical thing.

* Scheduling
+ Creation from script
	* Fix the assignment of string values to the dialog
	* Fix scalability of form window
- Allow setting of names of objects.
+ Graph widget: Compiled, but still need much hooking up to do.
	+ Convert to equivalent of text-based plot.
	- Fix issues with compiling.
- File widget
- Implement kkit load/run
- Implement squid or parts thereof.

=============================================================================
23 Sep 2004
Finally, in a very ugly way, have plots appearing.
- Need resize: should do automatic refresh
* Axes
- Label of plot
* Placement of plot labels
- Autoscale option by typing A

This is a truly pathetic implementation. After enormous effort I got it
to refresh the screen after the run was over. Unable to do it during run.

=============================================================================
24 Sep 2004
After much messing around, nearly there with the fileselect.

Finally: Able to load and run a model from the gui. Graphing it is a little
more tricky, cannot do till the internal graphs are set to give rise to
gui graphs rather than the internal text variety.

=============================================================================
25 Sep 2004
Some ideas:
+ Put a FLTK timeout_callback in the flrun object. It is a standard call.
	Provide a field for refresh interval so it doesn't bog the system down.
	-> This helps the display when it works. Widgets pop up upon 
		setting their 'visible', without needing other events.
	-> The flush is not needed in the timeout_callback.
	-> Many runs do not start properly because the flrun does not get
	started, in fact its proc does not even get called. This is an
	issue with threading, not the gui.
- I wanted to have a button that can issue a 'start' command, take the
	runtime from a dialog, and do the rest itself.
	Various interface points to put on kparser to get this to work:
		- have the runtime as a field in the kparser, assign by dialog
		- Have the 'Run' command as a message
			- Merge the normal run, rkrun, adrun etc.
			- Prevent duplicate running.
		- Have the 'Reinit' command as a message
		- Have a field to select solver method. This has hooks to
			update dts etc in the scheduler.
		* Use the clocktick for plots for the update of currtime
			* Provide a proc for dialogs, to tell them to update
			from a message using ReversePiggyback.
- Make the graph more useful. Put multiple plots in it. Do as pseudo-objects.
	- The pseudo-objects can function like text plots if their parents are
	not proper graphs. This keeps the system from getting messy in 
	batch mode.
	- Plots should have a print option where the filename is specified.
- Do some updates to messaging for cases where we want to fill in a blank.
	Useful in many cases, but may not be practical for speed reasons as
	a general solution. Options:
	x Allow a trigger message to be created with a prespecified value,
		for assignment to fields. This would be stored in a special
		version of genmsgdest.
	* Allow buttons to have a value associated with them for assignment.
		- Auto field-type conversion depending on msg type ?
		- See option below
	* Allow buttons to have a string attached that
		can be passed to the kparser as a complex command.

End point for this stage will be an adequate GUI for loading and running models.


current issues: 
	* Implementing button stuff. Issue with assignment of command string.
	* Need to check basic scheduling as I have fixed a sched message.

Remaining item: To do the graph stuff. Once that is there I can do almost
all the things needed for, e.g., a squid type demo.

=============================================================================
27 Sep 2004
Need to set up the standard plot in relation to the ghastly graph widget.
Set up so that it simply dumps its contents to the graph when run is done.

Done. Works. Moose is now looking almost civilized. Still to do:
* Display plot labels.
* Figure out how to call the flush on each plot once each run ends.
* Reinit on graph needs to clear all plots and not clear the axes.
* Put in a reinit for the silly dialog.
x On reinit, don't just blank the graph.
x On load do a run right away ?
* Have a 'stop' button
* Have a button to delete the model and try again.

=============================================================================
28 Sep 2004
Filled in some of the remaining gaps. Tested loading and deleting and stopping.
Now need to sort out the issue with the threads, and we will be done for
this phase.

Threading sequence: (j2 applies to the gui)

- If it calls job 1 at the start and job 2 right at the end, then it works.

- If it calls both jobs at once, then tty works but not gui

- If it calls j2 after creating the form but before finishing the gui,
	it sometimes works.

- If it calls j2 after creating the graph but before/during the File handler
	it has an Xlib error.

- If it calls j2 at once but the proc while doing the form, then it may work.
- If it calls j2 at once but the fltk proc right at the end, then it works.

- It does allow a widget to be created after flrun is going, but it is chancy.

A simplistic approach would be to put in a barrier between launching off
each of the threads from the scheduler. The barrier could be released once
the thread is safely in its event loop.

I think the fundamental problem is that fltk gets confused when object
creation is out of sync with its event loop. This could be handled by
blocking the event loop every time an object is being made.
Options:
	- templated fl_new function incorporating barrier
	- Barrier around creation funcs, using base-widg functions.
	- Queueing of all create requests on the fltk job. Would need a func.

OK, I'll put in a mutex around the flrun event loop.

Use the job class to do this. It will be more general.

- Provide an option to treat the proc as an infinite loop
- Provide a message for an external call to lock mutex.
- Provide a message for an external call to unlock mutex.
- Open up the flrun to use a loop. Will need to put the initial add-timeout
	elsewhere, possibly in flrun creation.

Big issue is: suppose the GUI thread itself initiates a call to make a new
object. This would cause a deadlock, although it should just go through
without any mutexes at all. One option is to put all callbacks onto a different
thread or a queue.

For now: just put in the mutex block into jobs. Will need to be very
careful in its use.

Well, this helps a lot but does uncover some other strange bugs. Notably
the job 1 for tty input is now sometimes getting stuck. Extended the coverage
of the locks and it is a bit better. Helps still more to have less diagnostic
messages as we load up.

OK, let's try this out as reference version.

Checking out headers:
Basecode is mostly the GPL form. Some are even older:
msgdest, msgdestlist, msgsrc, msgsrclist, msgsrclisttempl.h, relay.h

=============================================================================
27 Oct 2004
Some ideas for cleaning up threading issues with gui and other things:
- Have an 'exclusive' call from the parser. Pauses all threads except the
	parser. Use to protect creation and manipulation of GUI and other
	sensitive objects. Possibly to protect against other parsers.
- Have a cond_wait type call that waits on completion of some other thread,
	typically a simulation thread. Alternatively, could also have a
	blocking-simulation run call. This would be very handy for doing
	multi-step sims. Can't call the proc of the clockjob directly, though
	this is tempting. There would be problems as it may already be running
	on another thread, and we really should keep the threads separate.
	Instead want to put the parser thread to sleep till the message
	arrives from the ending of the clockjob.

=============================================================================
31 Oct 2004
Perhaps should work out a general inter-thread messaging protocol. Perhaps
even going through a slimmed down version of the postmaster to guarantee
safety. But for now, 2 requirements:
- kparser blocking run
- GUI

Blocking run logic:
Create message from clockproc to parser job
Set off simulation
Wait for message - job sleeps
message arrives: wake up
delete message
Resume parser execution.

So the conditional wait stuff is all in the job itself - nothing else needs
to deal with the threading.

=============================================================================
2 Nov
Trying to get blocking runs to work.
Compiles, seems to set up most of it, but doesn't work.
=============================================================================
3 Nov.
Problem seems to be that the message indicating the end of the job leads to
a change in its own listing. Details are:
clockjob::overout_ms.Send() tells the job
to wake up, and when it wakes up it deletes the message. Because the Send()
command tries to iterate through a list of targets, this messes up the
iterator.

Eliminated the automatic deletion of the message from overout. 
Looks like it now works. Still not completely clean.

=============================================================================
4 Nov.
Cleaned up implementation of adstoch. Now adrun works solo, without the need
for adinit, and it also works in blocking mode.

Fixed save_plots so it can now save to a specified file.

=============================================================================
6 Nov
Tested moose out in production simulation
- Possible issue with adstoch timestep. It seems to be going a lot slower than
	expected.
- Issue with assigning values during adstoch run. Adstoch seems only to
	know about n of molecules. Needs to handle a lot more stuff:
	molecules: ninit, conc, concinit, mode.
	reactions: kf, kb
	enzymes: k1, k2, k3, mode.
- Issue with assigning concinit, silly name error in molecule.h. Fixed.

Output matches. However, speed is pathetic. Will need to get solvers in gear.

=============================================================================
1 Dec 2004
on 17 Nov had merged the UNIX moose with the Windows development version.
This lives in the directory moosemerge, which I will shortly move over here.
That location lacks the full threading, parsing, and GUI stuff, but includes
the latest compartment modeling stuff.

=============================================================================
2 Dec 2004
Starting to use the merged version as the main development version. It has
been moved to the main moose directory, and the old tree is now in
~/genesis/moose_nov2004
Updated the rksolver initialization and running stuff, verified it works,
did benchmarks.

=============================================================================
3 Dec 2004
Beginning work on converters. Idea is to have a base converter and derive
a number of others off it. Maybe. 
Molecule-centric specifications:
	diffeq
	matlab

Reaction-centric specifications:
	reac dia

List of molecules, then reaction-centric
	Smoldyn
	SBML ?
	.g
	doqcs
	sigpath ?


General sequence:
1. Make list of molecules, subdivided into regular, buffered, sumtotalled.
	The list will also need enzyme-substrate complexes, done already in
	Moose.
	Each has just the ptr to the moose object.
2. Put in a map because we will be doing lots of lookups from the reactions.
3. Invoke class-specific method for spitting out entire table.
	Diffeq and Matlab versions will go after reacs and enzymes at this
	stage. 
4. Scan through regular reactions. Class-specific printout per-reaction here.
	Diffeq and Matlab don't do anything at all at this stage.

5. Scan through enzymes. First pass does regular enzymes. Second pass does
	MM enzymes. In each case the class-specific printout occurs.

6. Tidy up with sumtotals. Again, class-specific printouts.

Could the same object be used for reading into moose ?
Desired formats:
	SBML
	doqcs
	.g
	MATLAB would be nice but tricky.
=============================================================================
7 Dec 2004
Working on converter. Falling into place. The conv_base is an abstract
class that provides hooks for printing things. It defaults to a reaction-
centric form. Idea is to start out by implementing a .g output format, then
go on perhaps to matlab which is molecule-centric. The .g output will need
to be strongly supplemented with layout and runtime info, but perhaps this
will be a good step towards the equivalent for SBML.

=============================================================================
10 Dec 2004

More working on converter. Building .g output for starters. 

=============================================================================
11 Dec 2004
Suggested modules from Shinya:
Running things through to steady state.
Mixed stochastic/deterministic calculations (exact for some parts,
determ for others)
Frequency response analysis, transient response analysis

Converter base compiled. Need now to implement kinio_wrapper class. This
will have to deal with assorted headers for different format conversions.
Still not clear if the same kinio should deal both with reading and writing.

=============================================================================
12 Dec 2004
Struggling with getting things to run - nothing in the kinio, just the Call
syntax is messed up somewhere. Oddly, Call works with a single argument,
for example as 'call /kp readline quit'. What is there about 2 args ?

Much messing around later, still stuck.
Going on anyway to conversions.
This, of course, nearly works right off the bat for the kkit conversion.
Lots of syntax errors, and I really neead to get in a header section to put
in the simobjdump boilerplate. Also something for the groups.

=============================================================================
14 Dec 2004
Header working
need to introduce groups otherwise it won't load.
Groups in, still some way to go.
=============================================================================
16 Dec 2004
Got tworeac.g to work. On to enzyme models
Got enz.g to work
Got kholodenko.g to work. Yeehah!

* Clean up file dumping in the conv_base.
* Print out plot calls.
- Figure out how to preserve colour, layout info.
* Do sumtotals
- Do tables
- Verify with test suite.
- On to SBML format, Smoldyn format, MATLAB format, SQL format etc.

=============================================================================
18 Dec 2004
Got file dumping sortof working
Got plot calls to work
Got sumtotals to work.

Working on conv_matlab. Not much progress yet.
=============================================================================
19 Dec 2004
conv_matlab starting to show output, much to do.

Later: Looks like matlab conversion is mostly working. Seems to handle
all the regular cases, including mm enzymes and sumtots.

=============================================================================
21 Dec 2004
conv_matlab in good shape. Begun work on conv_sbml
Also beginning to look at exact stochastic methods.
The existing kderiv is almost but not completely adequate for the job, but
perhaps could be derived from to get it to work.

=============================================================================
24 Dec 2004
Another look at kderiv. It actually is not so good because it is 
molecule-centric rather than reaction-centric. This means that the 
Gillespie-type methods cannot identify which reaction to pick for
transitions. We want something similar to kderiv, but which gives
a vector of reactions rather than of molecules.

For the Elf method we want to go one step further and apply the reaction
rate calculations to a large number of subvolumes, each with the same
complement of molecules. Easy to do if we plan for it now.

For the Gibson-Bruck method we need to provide an ordered graph. We also
need to refer back to the Gillespie rate generation routine periodically
in case there is a change in model conditions. The ordered graph would 
best be done in a different framework than the Gillespie one, but could be
OK if suboptimal via pointers.

The SBML conversion is getting there, but stuck because we need a test
program for the output.

G1 algorithm (Direct method):
To init: Scan all reactions, calculate total propensity a0 (ignoring dt),
	create dependency graph

Each cycle: {
	-Select a random no r2[0..1], scan through reactions again till
		r2.a0 >= sum(propensities)
	- Calculate tau = (1/a0) ln (1/r1)
	- Increment molecular counts, advance time
	- Scan through dependency graph of affected reactions.
		Update ai. Update a0.
	}

G2 algorithm (First reaction method):
To init: Set initial conditions.
Each cycle: {
	- Calculate propensity and putative reaction time for each reacn
	- Select shortest reaction time
	- Increment molecular counts, advance time
	}
Note that the algorithm is much simpler and does not involve dependency graphs.

GB algorithm (Next reaction method):
To init: Scan all reactions, calculate ai and taui, create dependency graph,
	make priority queue
Each cycle: {
	- Select smallest taui
	- Increment molecular counts, advance time
	- Update ai, taui from dependency graph based on changes. This
		is a little tricky, see GB paper.
	- Update queue. Based on our experience with this, we also need
		to watch out for external inputs to update queue.
	}

In general, the GB method is fastest for intermediate sized reaction systems.
The G1 algorithm with subpartitioning a la Elf is best for really large
reac-diff type situations because handling the GB priority queue becomes messy
in such cases.

Current status: still working on allstoch.h and allstoch.cpp. The building
part is now in progress. Many of the functions have been defined in the .h,
but need to be implemented in the .cpp.

=============================================================================
28 Dec 2004
Implementation taking shape
Working on dependency list for g1 method, likely useful in other cases as well.
Here we need to identify all affected half-reactions following firing of
any given half-reaction. Go through the substrates and prds and enzs of the
affected half-reaction, then any reaction that may affect those, then any
half-reaction arising from from these molecules. Was trying to do it in
the half-built structure of the solution objects, but too messy. Will need
to set up at build time.
=============================================================================
29 Dec 2004
Analyzing the dependency list a little more closely. It is not a simple matter
to map from the MOOSE formulation of reactions to the one used in the 
Gillespie solver. Each reaction type would have different effects depending
on the role of the affected molecule as substrate, product, enzyme etc.
Suggested approach:
- Make dep list of halfreacs having allstoch_mol as an input. Keep in a map
	indexed by the allstoch_mol ptr.
- During formation of deplist, scan through all halfreacs looking for 
	affected allstoch_mols. Use to look up the index and build deplist.
- Find unique entries in deplist.

Getting there. Got it to run and give output, which was garbage. Negative
values.

Some fixes. No negative values but wrong output.

Seem to have fixed output. Need to do 
- checking of distribution,
* a whole lot of stuff for enzymes and general cleanup. 
	This is currently nearly there at line 620
- Would like to also do some optimization - several more cases for halfreacs,
	and perhaps streamline the product list. 
* Then benchmarks.

=============================================================================
30 Dec 2004
Looks like the kholodenko model works, both explicit and mm enz. Sumtots remain.

Sumtots done. Now to grind through the benchmarks and test cases.

		scsim19 			Moose
		EE	adstoch	G1	GB	EE	adstoch	G1	RK5
kholodenko.g 	12	18	6	8	18	10	0.6	0.9
1e5 sec                                          

acc4_1e-21.g 	11	21	190	75	25	27	85	75
1000 sec

nonscaf_syn6	13	22	160	41	28	28	36	65
100 sec

mega.g	
20 sec

Fixing bugs thanks to the acc4 run which had some zero rate reacns.

=============================================================================
31 Dec 2004
Finished up most of the benchmarking above. The G1 method in MOOSE is pretty
good. With the Elf refinements could probably beat the GB method in most cases.

=============================================================================
1 Jan 2004
Finished up most of the tests. Sumtotals remain an issue, though they seem
to pass the tests well there are problems with updating especially with
external inputs.
* Any reaction upstream of a sumtotal must propagate UpdateDependents through
	the sumtotal to all reactions immediately downstream of the sumtot.
* Any direct input to a sumtot must alter the sumtot and then do an
	UpdateDependents to all reactions immediately downstream of the sumtot.

Things seem to be reasonably OK, but there is still a big discrepancy when
solving the nonscaf6_1.6e-18b.g model. There is an initial dip of Ca
which then slowly trickles back up to the correct level. The problem does
not occur if the Ca_input pool is buffered. Implemented a few useful
additional test models
test_tab_reac.g
test_tab_reac_hiorder.g
test_tab_multireac.g
and those seem to work well. It is only the big model that has this problem.
Made another test model which illustrates the problem:
test_tab_fastreac.g
Here the reactions leading out of the sumtotal are faster. This does it.
Looks like it is simply a case of the sumtot not retaining its externally
set values. To test: a faster update rate should change the response.
Confirmed.
Fixed. It is a ghastly fix. I added the sumtot itself to the deplist of its
own product. This means that if any downstream molecule alters a sumtotalled
molecule, it just gets reassigned. Wasteful but sumtots are rare.

Just about done with the Gillespie solver. I have put in the general case
for regular reactions but the MM enzymes are still a little fragile. Need
to put in ways to handle buffered enzyme/substrates/products and higher
order MM enzymes.

=============================================================================
2 Jan 2004
The test_tab_fastreac.g model adds another useful test: What happens when
all propensities go to zero. The current G1 solver (allstoch) just stalls.
Actually should simply advance to the next dt.

Fixed.

Also put in updated mm enzyme stuff for buffered and higher-order cases.
Have only done basic tests on these.

=============================================================================
9 Jan 2004
Implementing in kp.cpp a way to read command line args. This is nearly
there, needs compiling and testing.
=============================================================================
16 Jan 2004
Basics of command line stuff are working. Would like to simplify. Perhaps
a func that specifies how many args are expected and the name of the command.

Following operations have been adapted to using the GetArgs routine that
enables evaluation of passed in args:

All the 'run' routines (for passing in runtimes, for example)
The assignment routine.
The 'call' function.

Should now be able to do production simulations with Moose. If I had a 
Rosenbrock solver it would be great - massive speed-ups on the most 
common problems.

=============================================================================
17 Jan 2004
Attempted production sims, of course failed.
- Error with huge model notes.
- Worked on kinio - one of the MATLAB bugs for the dangling models.

=============================================================================
18 Jan 2004

Fixed problem with huge model notes. It was due to use of old c-style
strings for I/O, ran into overflows with long notes for the model. Converted
to C++ strings and problem was solved, though the syntax of C++ is ghastly
as always. Sundry fixes to the allrun, adrun and other basic commands.

* Fix adrun etc, or simply run, so that it we can do stop/start simulations.
* Put in randnum seeder.

- Continuing problem with cAMP unreasonable buildup. Did a load of tests
with a simple model. It is not due to later assignment of mode for buffered
molecule, nor simply interaction of bufferring in obvious ways with
enzymes either as prds or subs.
Looks like I need to do it by elimination
In the original transloc model, problem remains even if cAMP is buffered
from the start.

=============================================================================
19 Jan 2004
Much messing around later: It looks like the lookup for buffered molecules
goes to some strange memory location. It is not entirely random, because
values are quite within range of molecule counts. I have not been able to
reproduce the cumulative changes in lookup values that we see from the full
model, but do get differences in individual runs, which oddly go as factors
of 2 for the model PKA.g with just PKA activation from cAMP (no ACs).

Found that part of the problem was because the AC enzymes are MM, which had
not done EliminateBuffers on their output. Still get strange values for n.
Further problem: Changes to ninit need to propagate to the affected reacts.
Easy to trigger, harder to store. Buffer obviously stores a list of dependent
reacs. One option is that all reacs store both
the original k and the adjusted k. Cleaner but may slow things down by adding
to the size of the reac structure. Alternate is that the buffer also store
original rates for each of the reacs. Ugly. 
However, it isn't much
use to store the original k in the reac, what if there were two buffered
inputs ? We should store in the buffer the original k for the reac if the
buff scale factor were 1. Then we can scale up and down by the new ninit
without worrying about cases where the ninit goes to zero. Again, problem
is it assumes that any other buffered mols are not being scaled.

Solution: Each buffer has list of:
	Affected reacs
	Other buffers affecting reacs
	Original rates for reacs

During update, new k = old k * prd of ninit for all other input buffers.

OK, implemented, compiled, test fails.
=============================================================================
20 Jan 2004
Fixed up running issues, but still the assignments fail to trickle down to
the solver.
Implemented using a horrible ugly hack in the element::GetFieldInfo
function. Much cleaning up to do on elements and solvers.

For now, though, it still does not work.

=============================================================================
21 Jan.
Fixed the more fundamental problem, of failing to update fields in solvers.
But the G1solve still fails to propagate the changes to the rates.

Fixed more stuff. Some cleanup. Now all the solvers seem to handle such
inputs OK. The basic (non-solver) integ method now has some issues, though.

Now that I have more experience with solvers it is clearer that the 
changes to the class structure may help.

=============================================================================
22 Jan
Returning to issue of conversion errors. One of the ugly errors is when
a reaction spans compartments. Kinetikit allows this because it works in
terms of n. Need to to some creative scaling when handling this in concs.

Cases:
- Substrates are vol1, prds are vol2.
- Enzyme is one vol, substrates and prds are other vols
- Enzyme and substrate are one vol, prd other vol.
- Substrates are different vols from each other.
	Let us simply exclude this case. In kkit we will soon be using
	compartments as the definitive specification of volumes, rather
	than individual molecules. We can prohibit this case. In fact,
	we may wish to prohibit reactions across compartments without a
	specific translocation, but there are a lot of legacy models that
	do it. Note however that enzymes may effectively do this.

Basic approach: 
- If substrates/prds are all in same vol, simply apply volscale
- If vols differ

dC/dt = dN/dt * volscale

dN/dt is obtained from conc rates by taking all substrates, scaling up all the
rates by volscale.

Then we scale back by individual volscale to get dC/dt. This should work
both for substrates and products.

An issue here: How will all this work for SBML?  Need to ask Mike H.

Implemented another test: onereac_vol_order.g

Fixed conv_matlab for the reactions. Enzymes still to come.

=============================================================================
23 Jan 2005
Fixed regular enzymes, but still to check with a messy multi-volume situation
enz_multivol_order.g.

MM enzymes next and hopefully last.

rate = kcat * e * s / (km + s)
Key thing is that km should be in units of s. Currently it is in units of n.
k3 is easy, in units of sec^-1

OK, done, vols should work. Some of these fixes will carry over to SBML, I
suppose.

=============================================================================
24 Jan 2005
Make a generic pathway object. Gets inputs from other pathways, with a 
sign, a delay, and a weight (encapsulates sign). Tends to decay to baseline.
For user interaction, treat messages like an array and provide a size()
function. The weight/delay array is then parallel to this one. Much like
synapses. Need way for src to look up dest index.

=============================================================================
29 Jan 2005
finfos should be returned as self-destructing classes, not as ptrs where there
is ambiguity about how to destroy them.

Msgs themselves need to be visible to users, as evaluated vec_fields. The
apparent fields of the msg are src, dest, srcfield(s), destfield(s), srcindex,
destindex. Will need to add fields for synapse type msgs.
Every vec_field should have a size. 
Every vec_field should provide extra lookup functions, indexing by src/dest,
filtering by fields.
(These things should be worked into the GetField syntax too)

=============================================================================
1 Feb 2005
Brought Moose back from Harsha's machine, where it had been fixed up for the
MATLAB conversions. I have now fixed it up so it compiles with libsbml too
so that I can test the sbml converter locally. Also trying to compile the
sbmlsolver (a C language command line SBML solver program) for doing tests
right here.

OK, got the kinconv command to do the right thing with the specified 
conversion type and destination file. Now I need to test the sbml output.

Got the smbl_solver to work. Aliased to ssolve.

Started testing the conversions with sbml_solver. 
- kholodenko.g converted well and works
- onereac converted well and works.
- enz.g conversion step fails, dumps core.

=============================================================================
2 Feb 2005.
Much messing around trying to get enzymes to work. Turns out that there is
an ugly assumption in libsbml, that all the species references are unique
and are deallocated (I think) in the reaction destructor. So we need to
reallocate the species references each time.
Also got the sumtotals to work, on a first pass. Next:
* Save current version as it is at least partly functional. Saved as
	mus_feb02_2005.tgz
* sumtotals and buffers should be used as modifiers, not as reactants or 
	products.
- Volume conversions need a lot of work.

=============================================================================
3 Feb 2005
For volume conversions: I should establish a set of compartments first,
and assign each molecule to one.

Issue is to do this in a way backward compatible with kkit.
- In existing models one can have different volumes within the same group
- There is nothing special about reactions between different vols.

Options:
	- Each unique volume is a different compartment, made automatically
		Would work for existing models, which have very few compts.
	- Each molecule, in addition to a group, has a specified compartment
		- Would cause changes in kkit .g format. Manageable.
		- Need orientation or related info for transmemb molecules ?
	- Each group belongs to a compartment.
		Would cause changes in kkit .g format. Manageable. But old
		models would not fit in this format.
		- Issue in that many signaling modules (groups) span compts.
	- Each group can be a new compartment, otherwise it is within compt of
		parent group.
		- Manageable changes in .g format, but issue with old models.
		- Issue in that many signaling modules (groups) span compts.

Conclusion: Groups and compts are orthogonal. Do compts on a per molecule basis.
Some rules:
	- A given molecular species can only be present in one compartment. 
		If it crosses compartments, need explicit transfer or equil,
		and unique species in each compt.
	- Molecules can interact only with mols in contiguous compartments
		Interface level check for this.
		Compartments have a list of contig compartments.
			Or: A single enclosing compartment (outside)
				Could be problematic. Should be N.
			N neighbour compartments
			N enclosed compartments (inside)
				Could be partially enclosed, in cooperation.
		Tool to duplicate groups containing multiple compts, specify
		rules for contiguity, provide automatic reaction binding.
		Tool to subdivide compts, again with appropriate rules.
	- Compts provide a default diffusion rate, but molecules may specify own
		Another change to molecule .g format.
	- Compts link to a geometry specification
	- Depending on solver, may need to query mol conc with coordinates.
	- Need way to query pos of individual molecules in uscopic solvers.

Some implementation details:
	- Moose molecules need a diffusion const and a compt
	- Compt needs a geometry and a contig list
	- Geometry provides at least a vol/area and dimensions.

In due course I need to deprecate the volscale field from molecules, and
instead provide a compartment message and a diffusion const field.
Or, the volscale field can be readonly and obtained from the compartment.
Moose, when reading kkit files, will need to figure out if they have the old
vol field or if they use compartments. 

				    *--*

Done as follows: I have incorporated the compartments (molcompt) as objects
in MOOSE, and they are built in right at the .g reading stage, including 
the creation of new ones for each unique volume.

Some work remaining
- The actual volume scaling is yet to happen
- Possibly because of this, get no response at all when I run the testsumtot
	model.

Some work on the MATLAB front: 
* Some names have ' in them, need fixing.
* Some models have sumtots from enzymes. Need to handle in the MOOSE loading.
- The accursed INTRAMOL messages still need to be handled.

=============================================================================
4 Feb 2005
Massive changes in version to compile on dbc. Most importantly, changed
the func_field typedef from const T to just T. This avoids the ugly
const const situation that arises sometimes. Unfortunately there are
ripple effects through many many objects. Fortunately I sorted them all
out. Presumably it will compile better with other things now. Maybe I should
use the pedantic flag.

Now working on volume issues for sbml. Turns out that the compts are fine,
it ignores the default compt if it is not used. It expects a volume scale
of 1, which makes sense given the units. Will need to define volume units
somewhere.

Much unit definition later. Now getting to the point of defining units
for rates, and here we are stumped. It may be necessary to revert to the
kkit idea of counting individual molecules.

=============================================================================
6 Feb 2005
A closer look at units in SBML shows that they are actually directly compatible
with those of MOOSE and kkit. So I can plug in many things direct from
MOOSE, a relief. Will need care with setting volumes, but essentially the
same conversion factors I normally use should be good.

Much later:
Lots of issues with units, may be a problem with odeSolve in that it does
not recognize the flag HasOnlySubstanceUnits. May be a common issue with
solvers. Perhaps safer to go to conc units as a general policy, even though
it necessitates some ugly conversions.
=============================================================================
7 Feb
Starting to make headway. Some nasty test cases failing, in particular:
- reac_multivol_hiorder.g
- enz_multivol_hiorder.g  
- Kholodenko_bigvol

Am in process of testing whether Genesis/Moose is wrong, or the SBML output.

reac_multivol_hiorder.g: Reaction is

Sub2 (6e5, volx1) + 2 Sub (6e5, vol x 10) <===> 4 Prd (vol x 0.1)
kf = 3e-13, kb = 1.4e-17; Kf = 0.00108, Kb = 0.003024
Let R be amount of S2 reacted.

Sub2: volscale = 6e4
Sub: volscale = 6e5
Prd: Volscale = 6e3

At Steady state:
S2 = 6e5 - R
S = 6e5 - 2R
P = 4R
Also,

S2 * S * S * kf = P^4 * kb
So,
(6e5 - R) * (6e5 - 2R) * (6e5 - 2R) * 3e-13 = (4R)^4 * 1.4e-17
Let X = 6e5
(X - R) * (X - 2R)^2 * kf = (4R)^4 * kb
Well, I'm not going to solve this the hard way, but I'll plug in the answer
from GENESIS and see if it fits.
4R = 2.2884e5
So R = 57210
LHS = 38395
RHS = 38393
OK, this is right. Good, GENESIS is a reliable workhorse. Now to examine issues
with the SBML equations.

rate forward is 0.00036 * 3e-13
rate back is 0.00216 * 1.4e-17
These are straight from the sbml file.

NUM_IN_L = 6e17
Rates are kf * VolProduct / NUM_IN_L = kf * 216e12 / NUM_IN_L = kf * 36e-5
kb * VolProduct / NUM_IN_L = kb * 1296e12 / NUM_IN_L = kb * 216e-5

VolProduct for kf should be 10x more than what it is.
Found bug in VolProduct, long assumed to be tested and OK.

Now working: 
* reac_multivol_hiorder.g
* enz_multivol_hiorder.g  
- Kholodenko_bigvol: Nope.

The last has been gone over once, still confusing.

=============================================================================
8 Feb.
Still at it
* Kholodenko_bigvol:
* mmenz_multivol_hiorder.g  

seems fixed now.

Working on Smoldyn converter. Things to ask Karen:
- Does order of definitions matter ? Can we specify graphical things after
	the 'wall' definitions ?
- How could we represent buffers ?
- How could we represent sumtotals ?
- How could we represent mm enz ?
- If we put buffers in as scale factors on rates, can we change them on
	the fly ? Likewise sumtotals.
- For reactions, can we simply put each reactant line separately, or do
	all corresponding reactants have to be on the same line ?
- Is the 2nd order limitation real or can we go to higher orders ?

Current state: does a reasonable start to reac-based smoldyn models. 
Need to implement enzymes.
Need to get local copy of smoldyn for testing.

=============================================================================
9 Feb.
Start out by backing up existing copy of moose.
Then merge in the changes to func_fields for compilation cleanness.
Tedious, but done.
Now back to Smoldyn. Here are the answers from Karen:

- Does order of definitions matter ? Can we specify graphical things after
	the 'wall' definitions ?
	No and Yes.
- How could we represent buffers ?
	Either by scaling rate consts (preferred for large #s of molecules)
	or by fudging something like 
		A + B <-----> C
	into
		A + B -----> C + B
		A <------C
	where B is the buffered species
- How could we represent sumtotals ?
	Don't. Split up into individual reactions.
- How could we represent mm enz ?
	Don't. Split up into regular enzyme.
- If we put buffers in as scale factors on rates, can we change them on
	the fly ? Likewise sumtotals.
	Ask Steven. However, in the second form (where A + B ----> C + B)
	we can alter B on the fly.
- For reactions, can we simply put each reactant line separately, or do
	all corresponding reactants have to be on the same line ?
	Have to be on same line.
- Is the 2nd order limitation real or can we go to higher orders ?
	Is real.


Working on conv_smoldyn, things in a mess working on enzymes.
=============================================================================
10 Feb
Plans:
Smoldyn: Till Thu (today)
SQL: Till Mon
Then bag it. Need to get on to doing other work. 
After that need to focus on parsers.

Doing Smoldyn tests. It is quite sensitive to volume/diffusion effects and one
has to be careful with the interaction volumes to get accurate results. 
Fortunately Smoldyn itself issues warnings. Have tested onereac, tworeac and
enz. Once we get past the warnings the results are clean. Used dat3xplot
to convert Smoldyn output to xplot.

Attempted to do kholodenko_explicit_enz.g
Got stuck on the length of the line handling names.

=============================================================================
11 Feb 2005
Working on the SQL conversion for DOQCS. Rather easy compared to others,
but some conceptual and design issues:
- Do we put all information into the .g file ?
	A: Preferably yes. 
		- Single point of data entry, single reference when updating.
		- This would make it possible to convert to .sbml too
		- Can flexibly build UI.
- How do we import stuff into MOOSE ?
	- Make a doqcsinfo object which contains fields for name, notes, author,
		etc. This is converted into a p_element with string children
		of the appropriate name.
 
 Almost there. Some glitch with loading in the doqcsinfo fields.

=============================================================================
12 Feb 2005
Looks like it works now. The small glitch was difficult indeed - processing
of quotes embedded in strings, and how it propagates through. There are
also issues with these quotes in loading back into kkit.

=============================================================================
13 Feb 2005

Referring back to 24/25 Jan for issues that apply for many aspects of messaging:
	- The API
	- The user interface
	- Handing dynamically created finfos
	- Additional fields in messages
	- synapses and generic pathways.

> 24 Jan 2005
> Make a generic pathway object. Gets inputs from other pathways, with a 
> sign, a delay, and a weight (encapsulates sign). Tends to decay to baseline.
> For user interaction, treat messages like an array and provide a size()
> function. The weight/delay array is then parallel to this one. Much like
> synapses. Need way for src to look up dest index.
> 
> 29 Jan 2005
> finfos should be returned as self-destructing classes, not as ptrs where there
> is ambiguity about how to destroy them.
> 
> Msgs themselves need to be visible to users, as evaluated vec_fields. The
> apparent fields of the msg are src, dest, srcfield(s), destfield(s), srcindex,
> destindex. Will need to add fields for synapse type msgs.
> Every vec_field should have a size. 
> Every vec_field should provide extra lookup functions, indexing by src/dest,
> filtering by fields.
> (These things should be worked into the GetField syntax too)

API and user interface:
The message field either of src or dest should look like a class, giving
	.size
	.add(src/dest)
	.delete(number)
	.delete(src/dest)
	[].srcelm
	[].srcfield
	([].src could include both of these in a single id/path)
	[].destelm
	[].destfield
	[].dest
	other fields (.weight, .delay, ...)
	Some are readonly, most should permit reassignment.

Fixed fields and indexes can be dealt with.
Calls can be handled too.
Other fields will need some new stuff.

in cinfo::GetField:
it goes through the fieldlookup array doing a strcmp, after doing parsing
to separate out the square braces. May want instead to leave the matching
to the finfo in the fieldlookup, so that it can do interesting
things through virtual funcs.
=============================================================================
24 Feb 2005
Putting in fixes for the sumtotals in smoldyn conversions. Need a dummy
enzobject  to create and change its name around so that the 
AddSmolreac function will generate suitable complexes. Possibly use the
original and mess with its name.
Very confusing bug where the reference to a vector turns to a null pointer
during a call to HalfPrint.

OK, sorted out. It was actually getting hung up on a bad pointer in the
Elm2eid function because I had used an element called /dummy rather than
/kinetics/dummy.
=============================================================================
24 March 2005
Deplorable rate of progress here. Looking at fixes for MATLAB and SBML
conversions.
MATLAB: 2 main things:
- INTRAMOLS
- conversions of inputs from tables and other things not known to matlab.

The second can be addressed simply by putting out a note for the values,
possibly buffering the molecule if it is a slave message.

The intramols are essentially a scaling on k1 rate of an enzyme. Easy to
represent provided MOOSE itself knows how to.

                        *--*
Here is some matlab code provided by Rajnish to help with the coding.

function test();
global a;
a = [1, 2, 3, 4, 5];
k = f1(1);
k = f2(2);

function t = f1(i);
global a;
t = a(i);

function s = f2(i);
global a
 s= a(i);

                        *--*

Got ambitious on the table conversion front, implementing a full representation
of the table in the converter. This should give us the ability to do 
almost all the simulations, even if they have complex inputs.
Ready now to test with a simple table feeding into a reaction or two.

Test done, works but the output of the element controlled by the table
is not simple. Need to think about it.
Also implemented intramol messages, both in the matlab and sbml formats.
Tables are not done yet, and perhaps never, for SBML.

Extensive testing still to be done on all these converters.

=============================================================================
25 March 2005
More fixes to matlab converter. Looks reasonable now, does plots as well
as intramols.
Tested each independently in test_tabreac2ndorder.g, test_tabreac.g, and
	test_intramol.g.

Need to do proper interpolation rather than the direct lookup I use now.

Moose still doesn't handle channels properly. So the matlab conversion still
is problematic.

But acc33.g converts properly, graphs and all. I think Harsha can take it from
here. Remaining things:
	- Channels
	* Interpolation in tables
	- Check sbml conversion

=============================================================================
21 Apr 2005.
Issue with rkrun. Doesn't work for Tyson model. Probably has to do with
behavior of sumtotals or of MM enzymes, as the model is full of these.

I think I tracked it down. look at mmenz_multiprd.g. As it indicates, the
rk method does not like multiple products of a mmenz.
Looks like regular enz multiple products are also messed up.

Working on fixes in kderiv.h. This goes up to 2 prds.
Seems like it works. Takes a mere 35ish seconds to handle 100 hours of simtime,
on a little 1 Ghz laptop. Wish the PDGF model was as fast.

=============================================================================
23 Apr 2005.
Need to check that rkrun responds to changes in n and ninit during run.
=============================================================================
24 Apr 2005.
Confirmed above. See test/rk_set.mu and rk_set2.mu.
What these runs also reveal is that there is a problem with the flow control,
again probably related to the threading model I use. Very often the two runs
simply freeze after the first rkrun.

So now the job is to clean out threading. Major hassle but important for
portability and for fast batch-mode runs. Issue remains how this will work
with the old GENESIS parser, but that is for later.

Saved current version of MOOSE in 

mus_apr_24_2005.tgz

Stripped out threading. Now need to work out a new flow control.
In the threading model, the scheduler calls up different jobs that 
deal with things ranging from parser to simulator. Then the scheduler goes
into a busy-loop (perhaps a bad idea in itself) to wait till something
happens. Supposedly this busy loop will wait for a signal, but I don't
think that works too well either.

In the non-threading model, will need to non-preemptively give control
to different jobs. The tricky one is the simulator job, as it runs for a
big block of time. One way out would be to return periodically. Another
option is to use the complicated clock structure to itself make periodic
calls out to 'jobs' like tty.

The two can be combined by using a clocktick to send a message to 'halt' on
the clockproc.

For now we'll use the graphics clock tick to do this. Once halted, the system
will call each job individually.

Summary:
	- Scheduler: loops through all jobs till it gets a quit message.
	- Jobs: call checking function.
	- clockjob: Set off clockproc::Run
	- Clockproc: run till end of sim or till recieves a halt
	- Clockticks: As usual. The graphics tick calls halt on the clockproc.

Much work later, this looks like it is working splendidly and perhaps there
is a speedup. Still a problem with running stuff from a file.

Understood.  File issue arises because the entire parsing of the file and
the run commands therein happen on a single call out to the tty. The control
flow never gets back to the scheduler which is waiting to call the 
number crunching stuff.

Fixed. Preliminary tests suggest that the speed of MOOSE is nearly doubled.

Came across this interesting comment in slashdot. Need to figure out
what he means by these libraries.

>>Show me code how to assign callbacks.
>
>Sure. This is an example using the boost::function and boost::bind libraries which have both been available for a long time and are in the process of becoming part of the standard C++ library.
>
>    #include <iostream>
>    #include <boost/function.hpp>
>    #include <boost/bind.hpp>
>     
>    using namespace std;
>    using boost::function;
>    using boost::bind;
>     
>    void hello() { cout << "hello from function" << endl; }
>     
>    struct Object {
>        void hello() { cout << "hello from member function" << endl; }
>    };
>     
>    int
>    main()
>    {
>    // callback with a normal function
>        function<void()> f(hello);
>        f();
>     
>    // callback with a member function
>        Object o;
>        f = bind(&Object::hello, &o);
>        f();
>    } 
>
>If you don't want to use libraries just assign function objects or static class functions.
>
>If you want to do several callbacks at once check out one of the many available signal/slot libraries.
>
>
>

=============================================================================
25 Apr 2005.
Looked at budding and fusing objects. They are too specialized and 
sophisticated to do the simple mass-halving we need for the Novak-Tyson model.
Instead I will create a conditional object. This takes an input msg, applies
a condition against internal field A, and if condition is met triggers output
message(s). Provide a float and a string argument for a variety of outputs.

Looking at why we get double values in rk solver.
- Do not occur in other solvers
- Do not occur when we have other modes of rk solver

Sorted it out. There was an issue with scheduling for the rksolver, dts
were incorrectly assigned in the rkrun function.

=============================================================================
26 Apr 2005.
Implemented condition object. 
Fixed issue with showfield.
Found problem with rkrun. It always goes back to zero. Fixed.

Stuck on condition object. It is not getting the nout message. Will do
a test using a simpler model.

Set up the test.
- Works with regular run.
- rksolve does not send regular nout messages.
- rksolve does not listen to extended messages in to the field n.

=============================================================================
1 May 2005

Fixed another issue with rkrun not responding to the condition message.
Now the system can be made to work, even though it is not particularly
elegant.

General messaging idea: Could separate the concepts of function call and
trigger. 

Function call sends an argument from A to B
Trigger initiates this function call. In regular messages the trigger comes
from A. In piggybacks the trigger comes from B. Often we want to trigger
the message from C, which could be an event impinging on A or something
else altogether. Conservative case is to keep the triggers on either A or B.

So the function call part of the message is much as it is now: a system
for managing the connections between two elements and for passing an
argument, which may be from a field within A or from a calculated value
in A.
The trigger part of message is fuzzy

Actually we have 3 parts:
- A system for managing connections between elements
	- This is currently locked to one message type, which is a good thing
	from the viewpoint of type safety and speed in calling something
	stereotyped. Could even tighten it to a specific target func for
	a tiny bit more speed. But it weakens generality.
- A system for using these connections for calling remote functions with
	arguments generated locally
	- Currently does a typecast of the destination field into the 
	correct type to take the args, within a nmsgsrc1<class T>::Send call.
	- Used to pass the msglist itself in to a Send call. This boils down
	to the field definition itself which does the iteration and all.
	Arguably not a good place for it.
- A way to trigger the function calls.
	- The trigger part is relevant only if the argument part is 
	taken care of by the structure of the message.
	- The trigger is either an incoming func call, or a system event.
	- The trigger should be shaped like a simple function call
		- Zero arg if the argument is handled by message
		- With arg if this is what is going to the target.

We also need the ability to tap into messages. Currently handled by
the ad-hoc approach of doing relays. These are for receiving info. They
keep track of the original field, and continue to use it to receive info,
but additionally hold a local srclist so they can send (relay) the call
and arguments elsewhere too. Soverelays do the same both for sending
and receiving info.
In each of these cases we replace the local 'field' object with the
relay. So the use of the field pointer in the message structure has become
sort of embedded.

All these notes really need to be worked through in a week of clear time
when I completely redo message/field architecture of MOOSE.


=============================================================================
15 May 2005.
Some further notes on above topic. Seems to have expanded to many topics.

1. The connection part. This is symmetric between A and B:

class msgconn {
	virtual void exec_target(op myop); // Iterates and executes target.
	virtual msgconn* target(unsigned long index);
	virtual unsigned long ntargets();
	virtual element* pa();	// Should be able to compute from self addr
	virtual int msgconn_no();	// Should know from template.
	virtual bool add(msgconn* target);
	virtual bool drop(msgconn* target);
}

Single	A o---------------------o B

	   |--               --|
	   |--               --|
Multi	A o|-------------------|o B
	   |--               --|
	   |--               --|
	
	   |--               
	   |--               
Mixed	A o|--------------------o B
	   |--               
	   |--               

Computed A o-Fn . . . . . . . Fn-o B	(and other mixed cases)
	Here we can collapse calls where possible, esp across nodes.

	      |--o 
	      |--o
Relay	A o---|--o
	      |--o
	      |--o
	See below for relay. It is interposed between any two of the above.
	Computed->relay would be tricky though.

		Tests: 
		+ Creation/destruction of each kind. Memory leaks.
		+ All perms and combos
		- Traversal
		Docs:
		- Implementation doc: this plus details plus implem logic
		- Developer function API
		- Joe user doc.
	
Assigning connection fields (the connectivity part of msgs). Also
see field discussion below. The connection would be a rather complex
composite class, but its subparts should be accessible as strings etc.
Possibilities:
	- could this replace addmsg?
		Addmsg is a good condensed call. Also if connections are set
		dynmically then how would we set connection first and msgsrc
		later?
	- Note that connections are totally symmetric. Could assign
		at either end. Goto vs comefrom. Need careful typecheck
		on each assign.
	- Could have empty connections ?
		- Are connections free-floating or always associated with at
		least one msgsrc/msgdest? Do they proliferate dynamically?
		What does the msgsrc point to? Indirection issues?
	- How do we decide when multiple msgsrcs share a connection?
		- msgsets ? Loses flexibility.
	- Table of paths? ids vs strings vs elm ptr objs? See below.
	- Wildcard assign: To spread out into an array?
	- Function assign: Functions can be clever wildcards?

		Tests:
		- Lookup of connection fields parent, otherparent, indexed,
			nconnections.
		- Implement traversals
		- The assignment part still looks fuzzy. Test as developed.

2. The function call part. Some options
Option		Typechecking	Location of field	Relays		Symmetry
Current 	At setup	Ptr at src and dest	Replace field	Lost
Typecast conn	At setup	Func ptr at src		?		Lost
Msg sets	At setup	Func ptr at src		?		Yes
		Do not permit
		more msgs
Pass fid to elm	Part runtime	Fid at src, lookup elm	Elm lookup fid	Yes
Rigid src ptr	At setup	Func ptr at src		Separate part	Yes
							of conn list

Some of the intermediate ones are a bit fuzzy, but the last option has some
nice possibilities despite its apparent restrictiveness:
	- Eliminates field ptr at dest.		(memory)
	- Eliminates one level of indirection.	(speed)
	- Lumps together similar func calls.	(speed)
	- Handles relays by using a distinct func call. (generality)
		- Now the idea is to use a special connection to handle
		relays. Let's see how it works.
	- Uses similar field classes as already
	- Very clean about multiple use of same connection (piggybacking)
	- Tie up to field assignment. Call just uses the dest elm directly.
But:
	- May need separate parts of connection list (memory issue)
	- Needs retroactive reconfiguration of msg when a target is relayed.
	- Some of the target info is now at src (func/field ptr).
	- Does commit the src to contain some field info. 

		Tests:
		- Make a message
		- Call message from method
		- Call message offline
		- Create and delete a zillion messages. Memory leaks.
		- Implement current functionality
		- Benchmark current functionality
		- Once-off piggybacks
		- Unique piggybacks

	class element {
		... stuff ...
		vector<msgconn*> conns; // hm. Need to figure out how to get
			// sequences of different types.
	};
	Need to build one to see how to handle special cases like relays.

2a. Synapses. Need additional information for each target. Amount of info
	grows with # of msgs. Target may want access to info.
	- On target, keep vector of a struct {wt, delay, parent, msgconn}.
	- Src just points to appropriate msgconn.

2b. Fields and msgs: What happes to msgsrclist, msgdestlist?
	- msgsrc field: Ties and identifies a field (the destfield) with a
		msgconn.
		Or: Ties a msgconn to the calling function. The destfield
		is filled in when we do the addmsg. The msgsrc also needs
		to know the legal arg types, ie, should be a field<T1, T2>
		kind of thing.
	- msgdest field: Ties and identifies a function with a msgconn. 
	Implication: If you know the msgsrc or the msgdest, you only need to
		know the two elements at the ends.
	Issues: 
		How to handle new classes.
		How to handle say tables, which can get and send msgs anywhere.

3. Triggers.
	Two aspects:
	- Getting value of a field by triggering it (zero arg). Trigger
		causes any msg emanating from field to go out.
		- All value fields can handle this.
		- All zero arg fields can handle this.
		- Most other fields/msgsrcs cannot handle this.
			Need a way to warn?
	- Linking any function call to any other. Critical for traversal.
		Has to be bidirectional?
		- For custom triggers: Add a relay. Looks like a msg.
		- For internal triggers: 
			- Need a GetMsg type call on elm, 
			virtual, so that it can look up trigger logic.
			- Need to specify inmsg->outmsg ties in class defn
				- Can be many -> one and one -> many

	- For general traversal there are 3 cases: 
		- Along a message
		- Predefined, within an object (linking functional calls)
		- Relays.

		Tests:
		- Trigger value field
		- Trigger zero arg
		- Trigger invalid field. Check for sensible error handling
		- Add a relay
		- Create and delete many, memory leaks etc.
		- Provide field in message structure for lookup of triggers too
		- Lookup real trigger
		- Lookup virtual (hard-coded) triggers
		- Traverse from in to out
		- Traverse from out to in.
		- Build entire traversal tree, both ways.
		- Traverse up and down as needed for threading.

4. Relays.
	In all these cases, if we use a special msgfunc on distinct connection,
		it can contain additional local info. Cases:
	- Intercepting a call, possibly eliminating the original
		- Special func takes call, decides if to call original
	- Forwarding the call as a trigger
		- Special func contains target, passes on event to it. Even 
			extra args. This would allow issuing a multiarg
			msgsrc call through a trigger. Need full field access
			to args.
	- Forwarding both the call and the value(s)
		- Special func contains target, passes on event to it. Also
			passes on the arguments received.
	Here it begins to look like just a func may be insufficient, need 
		additional relay object info. Need to optimize.

	A distinct solution: put in an intermediate msgconn. It has additional
	info for sending to separate/original targets. No change in calling
	method should be needed.

	Intermediate msgconn issues.
	- Need to intercept original call, made through a Recv type operation
	on destination elm: f->Recv(outconn.Target(0)->Pa(), v1, v2);
		Three basic options
		- Could replace f on src.
		- Could do something different in the Recv function.
			Recv is typically a statically defined function. No
			convenient polymorphism here, otherwise could simply
			have a dummy Pa with a different equivalent.
		- Replace both f and target. Depending on type of relay
			(blocking/pre/post) can encapsulate or disable 
			original f. 

	Conclusion: 
		- Use msgconn as relay
		- Use msgconn as the argument for the recv func in the iterator
			on the msgsrc::Send()
		- These msgconns can include all sorts of additional info,
			and func can decide what to do with it.

		Tests:
		- Intercept
		- Forward
		- Forward with extra args. Make bunch of messages with fixed
			info
		- Forward with call and value
		- Create and destroy, check for memory leaks
		- Traversal. See above.
		- Benchmark
		- Get current stuff to work.

5. Solvers
	Currently done as a generic relay type msg.
	- Decide: Does object have special solver msg, or is it always
		done as a relay type msg ? Note that different solvers may
		have different needs.
	- Takeover of everything that an element does. Should pre-emptively
		block the scheduling: eliminate/disable process msgs outright.
		This is costly done at the obj level, easier but non-local
		at scheduler.
	- Global intercept of all msgs? Difficult with rigid func framework,
		as the msgs are decentralized. Instead need to explicitly
		parse msgs and intercept each selectively, as done now.
	- Replace elm with different one with different field array?	
		Tests:
		- Create and delete, memory leak test
		- Check if current stuff works
		- Check fixed offset (fast) solver field relay.
		- Check assignment of object values forwarded to solver
		- Check access of object values via solver
		- Check harvesting of existing messages
		- Check block of process
		- Get current stuff to work.

6. Relationship to field assignment, elm values, fields, and string conversions
	Field assignment options are between fields, entire elms, and strings.
	There are atomic fields: scalars, arrays, paths for objs and fields,
		ids for each of those and for classes too.
	Messages are not quite atomic: they are built (using a bunch of
		evaluated fields) from the above basic units.
	- All elms define a string conversion. Usually it is automatic,
		generated from the atomic fields in the elm defn.
		- It is bidirectional, going through a strval field.
	- All elms define a base field, which is the whole elm. Call it val.
		- However, if we do this do we need to define an elm equiv
		for fields? The val field _is_ the elm equiv. See next.
	- All fields define an elm equivalent. Ideally this would just be
		part of the field type definition. Do we permit non-converting
		fields ? Two reasons:
		- Unify string I/O through elms?
		- Make it possible to assign fields and elms to each other
	- All string I/O for fields goes through elms? Alt is all string I/O
		for elms goes through fields. 
		- Unique elm classes, many fields. Easier to go through elms.
		- To do a setfield: Create temp elm. Strset. Field assign.
		Delete temp elm.
		- To do a getfield: Create temp elm. Field assign. Strget.
		Delete temp elm.
		- To call a method: Create temp elms for each arg. Strset.
		Call method. Delete temp elms.
			- Obvious for value and method (msgdest) fields
			- Triggers msgout for msgsrc fields
	- Fields and subclasses:
		Field list looks first at children, then at current elm, then
		at parent class for a match.
	- Readonly and other flags:
		Different field subclasses. Need clear set of methods. Need
			warning of some kind if set fails. Perhaps a flag
			ahead of time for writable/exec/other things.
	- Reading system fields:
		- Base elm provides set of fields. Most are readonly.
		- Parent and name can be written, within limitations.
	- Assigning msgsrc fields:
		I guess this means call it with an arg. See string I/O above.
	- Assigning msgdest fields (methods):
		A matter of calling the method with args. See string I/O above.

			Tests:
			- Formation of all atomic field classes
			- Assignment to other field
			- Assignment to elm (presumably via field)
			- Set and Get fields, func-fields
			- Set and Get string values
			- Set and Get array fields
			- Set and Get complex fields like interpol and msg
			- Make readonly field
			- Make non-executable field ?
			- Assigning msgsrc and msgdest fields.
			- Set and Get fields from parent class
			- Set and Get special fields like classinfo and parent

7. Across nodes
	Deal with postmaster infrastructure later. I have some notes on it
	above, and I think that is pretty compatible with the current ideas.
	See 10 Apr 2003.
	- Need program constructs to indicate which parts of sim are ||.
	- Need intelligent load-balancing. Could be from postmasters,
	identifying which node is the slowest and trying to lighten it.
	More complex issue is identifying when communications cost more
	than sim time. Optimizing for total speed vs # of nodes.
	- elm ptr objects. They could refer either directly to the elm,
	or to a forwarding elm that knows where the real one lives. But this
	needs extra info otherwise there will be a surfeit of elm ptr objs.

8. Threading
	Primarily a nasty scheduling issue. Build a dependency graph. This
	is cleaner and automatable with the traversal/trigger stuff.
	Subdivide so that the subdivisions are independent up to clock bdries.
	Want to put in estimates of compute time per object.
	Need some concrete experience on all this and several rounds of 
	fine-tuning. Ideally should handle solvers as well, and decompose
	automatically based on dependencies and estimated times. Would like
	an intelligent resched algorithm that monitors performance. Perhaps
	build into the barrier something to keep track of whatever thread
	is taking longest, and see how to lighten it.

9. Do we use eids, fids, cids?
	eids: Could just use elm ptrs. Will need additional info for off-node
		eids. Union?
	fids: Field ptrs. If off node can always refer back to name or other id.
	cids: Ptrs, if off node refer back to class name.

10. Developer tools
	Remake mpp. Cleaner, higher-level syntax.

=============================================================================
17 May 2005.
Above list is pretty exhaustive. Need to add in plans for test suites and
documentation targets to pin it down. Doing so in situ.
Documentation is throughout 3-fold:
	Implementation logic
	Developer function API
	Joe user info.

=============================================================================
18 May 2005.
Saved previous version. Now on multiple tasks involving converters and
giving MOOSE some extra features:
0. Generate Stoich matrix from MOOSE. Generate rate vector.
1. Take code from CSPACE so that MOOSE can test stochiometry. Do some checks.
2. Take code from CSPACE so that MOOSE can generate conservation matrix.
3. Use conservation matrix calculations with the rate vector to generate
	minimal differential equation system. Also merge buffers into
	rate consts.
4. Join 2 to 3 to get initial conditions plus minimal diffeq system
5. Generate rate vector S.
6. Join 4 and 5 to generate many things:
	a. Optimized but opaque MATLAB code
	b. SSF dump for CSPACE calculations
	c. optimized rksolve system of eqns.
	d. Plugin for Rosenbrock solver
	e. Plugin for LSODA ?
7. Quite independent of all this: SQL converter.

Started out with kinio/stoichmat.h for setting up stoich matrix.
=============================================================================
22 May.
Just a small beginning. Defining stoichmat.h and stoichmat.cpp

=============================================================================
24 May.
Shifted back to generating the SQL stuff for Doqcs dump. Much of the work on
this is related to the kkit11 interface, which is beginning to mark a rather
major change. Some changes percolate down to the kparser and to the
molecule definition, and of course will have impacts on the various
converters. Ones affected include the SQL converter of course, but will
also impact the Smoldyn converter because now molecules know about the
necessary parameters for that.

Finally done a lot of work esp in kkit interface. Combined. Saved it all.
=============================================================================
26 May.
Some cleanup of doqcs converter
Currently working on geometry output.
=============================================================================
27 May.

Need to:
- Use messages to specify compartments for molecules. Could be default
compartment like in groups. Note that groups are somewhat orthogonal to
compartments. Could have a multi-compt pathway, hence a group, but have
many groups sharing the same compartment.
	- Make a suitable target in mol for the message from the compartment.
	- Update the way in which volumes are obtained.
	- Decide if all mols should be retrofitted so that they always use
		the compartment rather than a local vol.

- Make container messages more complete in molcompt. 'Contains' and 'contig'
	should have targets.
- Figure out relationship between compartment and geometry. Ideally the
	Want to specify complex shapes as a single geometry
	but want to specify memb etc as different compartments
	but want to use the same geom info to specify both the cytosol outer
	limits, the membrane itself, and the inner limits of extracell.
	- Subcompartments as mathematical subdivisions of a physiological compt
		made purely for numerical purposes.
		- Need to replicate molecules or have a PDE, depending on how
		this is handled.
		- Do molecules gain xyz coords that are needed to lookup
		local conc ?
	- Compartments as cellular compts: places separated from each other,
		but communicating
	- Geometries as shape definitions, can be shared among compts.



=============================================================================
28 May.
For now, to handle molcompts
+ Molecule in kkit uses name to look up compt. 
+ Molecule in moose uses a msg to look up compt, but vol is still locally saved
	for calculations
+ compts are built before any molecules. they are set up in a vector with
	incremental ids so that the SQL can refer to them. Save id and
	name of compt in a map.
+ When saving a moose molecule, trace msg to find compt, look up id from
	name, and then write SQL identifier.

Looks like it works. On now to the stoich matrix stuff from 18 May.

=============================================================================
29 May 2005

Issue on making stoich matrix. If I ignore buffered molecules I can get
stoich violations. Most simply
 A <---> B
where A is buffered
has a B term out of nothing on the RHS.
On the other hand I want to merge buffered molecules into rate consts for 
all analyses.

Stoich mat then has to use all mols. Bufs are OK but not clear yet how to
handle sumtots. Perhaps treat like bufs.

Rate vector would normally have included the terms for the buffered
molecules. These can be safely merged in as the rate vector is not used in
stoich analysis.

Stoich analysis to be done with full matrix, including buff terms.
Reduced eqns for SSF and perhaps MATLAB calculations should be done
by doing the conservation analysis on the full matrix.

Once we have the indept and dept terms, we can simply drop rows for the
buffered molecules. Or maybe not. The merging of rows means that we may have
a term that combines both.

Now the basic stoich matrix filling stuff compiles. How to invoke it? Various 
contexts:
- Test of stoichiometry of a MOOSE reaction scheme.
- Identification of conservation groups. 
- Generation of clean matrices for MATLAB, SSF, diffeq type solvers
- Generation of clean matrices for internal RK5 and other solvers.

Immediate need is for 2 things: stoich test func and SSF generator.
To implement stoich test func we'll set up a class that handles various
kinds of matrix analyses
	- stoich test
	- # indept, # dept
	- Quick internal SSF analysis ?

To implement SSF generator, use pretty much the usual code for model dumps.

Loaded in the consv_matrix.cpp stuff from CSPACE and made some minor changes
so it can work with any size system.

=============================================================================
30 May 2005
Daytime work: Got doqcs converter one step further along. Will be done within
a day or so at this rate.

Compiled conv_ssf. Long way yet to go on it. Slowly putting togeteher bits

=============================================================================
31 May 2005
Trying to debug conv_ssf.cpp. Something ugly going on with allocation while
trying to build the stoichmat.

Traced down to line 90 in stoichmat.cpp: something to do with the
creation of the molecule and assigning buffers.
=============================================================================
1 June 2005.

Various fixes. Now expanding the coefficient generation and other stuff on 
conv_ssf.cpp stoichmat.cpp etc.

=============================================================================
2-6 June 2005
Intermittent work on fine-tuning the doqcs converter. It is now nearly
functional. Model encoding to come.

=============================================================================
10 June 2005
Doqcs converter fine-tuning:
- Check for silly names: quotes, spaces etc. Don't try any fixes yet, just
	warn user so they can fix .g file by hand.
- Check for reactions between compartments/different vols. Dump differently
	there - use raw kf and kbs in terms of #.
=============================================================================
12 June 2005
Seem to be done above.
Slow progress on conv_ssf. Major bug with argument order, do not understand
why compiler did not catch it. Current status: Checking out functioning
of buffer folding into rates. So far not good.

=============================================================================
14 June 2005.
Working now on a very simple system:
A <===> 2B
The buffered version buffers A.

Now seems to be fixed. Onward ho. Next steps:
* put in remaining portions of SSF specifction file.
- Put in stoich calculations
- Put in code for eliminating indept reacs.

OK, seem to have finally gotten SSF output from moose. Now to do further
steps.

=============================================================================
20 June 2005.
Looking now at enzymes. Need to figure out whether we can banish the 
enzyme complex from the stoich analysis, or if we will need to put the 
explicit set of reactions in the calculation. Are we going to build
equations out of this, or just test stoichiometry? If the former, then
we need to keep the cplx terms.
=============================================================================
21 June.
Got it to compile. Still to test.
=============================================================================
23 June.
Checking it out with enzymes. Seems OK for basic stuff but fails if there
is buffering. 

Went back to reactions to see if they look OK with buffering. They do.

OK, enzymes are not correctly reporting that enz is also a prd.

OK, fixed. Looks like enzymes work OK now both with and without buffering.

Now to invoke the dependency stuff.
Created consv_mat and generated the old consv stuff.
Need to work through consv mat stuff to figure out how to use the
generated matrices for:
- Reduced eqn systems
- consv eqns.

=============================================================================
25 June.
Having gone through the logic, seems like I can safely scramble the N matrix
to get the independent set of equations, and subsequently add in the 
conservation relations (the dependent set) using initial conditions.

Also checked that the predicted consv relations are good 
(not at all intuitive).

So the outcome of this is that the system should print the following eqns
out:

dS/dt = 0 = Nr.v
Gamma.S - Gamma.S0 = 0

Getting close. Need to clean out the generation of the coeffs for the
consv terms, but the matrices seem to be OK.

Next step will be to handle buffering.
=============================================================================
26 June
Works as a first pass. Tested on the model abcd.g, generated an ssf file,
ran ssf on it and got results that agree with those from running the 
simulation.

Need to generate test suite.
Confirmed that buffering does not yet work.
Also had a concern about ordering: What happens if we need to reorder a 
dependent molecule. Should appear in a good test suite.
1. Simple reac	reac.g	OK
2. Simple enz	enz.g	OK
3. Enz + reac	er.g	OK
4. 2 reactions	abcd.g	OK
5. 3 reactions	abcde.g	OK

Took many iterations to get to this point. Now it looks like ordering is
sorted out. Now to look at buffering, then on to exciting systems.

6. Reac with buffering 		breac.g		OK
7. 2 reac with buffering 	b_abcd.g	OK
8. Enz with buffered enz	buf_enz_enz.g	OK
9. Enz reac with buffered enz	b_er.g		OK
10. Enz with buffering substrate b_sub_enz.g	SSF failed
	(infinity solution)

11. Bistab: Neg feedback	inh_bis_fb.g	Ran ssf half hour, never
						returned. 90 min on FX53: OK.

12. Because things looked bad here, went for big model to see if that was it.
    Big simple reac model	ax.g		OK

13. Another check: Highly interconnected model based on abcd.g:
				ay.g		Looks similar but not quite.


8. Bistab 1: pos feedback
10. Bistab 3: Simple AMPAR.
11. Oscillatory model
=============================================================================
28 June 2005
How to do an automatic test for bistability, osc, amplif etc.
- Osc: do an fft on outputs. 
- Bistability: 	
	1. Identify concs that do not affect SS. Could use consv laws:
	anything in a consv law is out.
	1.5 Verify by running to SS with minor deviation from init cond.
	2. Change init amount of these to a value around that of the highest
	in system.
	3. Run to SS. Is SS diferent?
	4. Validate: Try new init amount. Should get same SS.
	5. Double validate: See if iterative bisection works. Obtain thresh.
	6. Stoch stability. Run at different vols, look for transition times.
- Infinities:
	1. Just run and monitor. Look for linear and supralinear buildups.
- Amplif, FF filters, delays:
	1. Identify possible inputs. Buffered molecules ?
	2. Vary % wise. Run to SS. Monitor outputs. What is gain?
	2.5 Identify inputs and outputs
	3. Use time-series to look for transient responses with high gain.
	3.5 Identify inputs and outputs
	4. Use time-series to look for delays.
	4.5 Identify inputs and outputs, time-course
- Noise:
	Run at different volumes. Measure sdev of SS. Look at relevant inputs
	and outputs from above. Assess resistance to noise.


In parallel, working on a clean implementation of messaging to plug into the
existing MOOSE structure. See way back to 15 May.
Fair progress. Now a bit stuck with getting the msgconn to behave for dropping
targets.

=============================================================================
29 June 2005.
Some minor work on kinio/conv_doqcs.
Some interesting work on the minimus code. Basic conns done, at the crux of 
handling msg calls across conns.
=============================================================================
30 June 2005.
Working on msgs in minimus code. Interesting issues coming up in attempt to
get something fast and general. Attempted benchmarks in 
fptr_vs_vfunc.cpp
Immediate question is: does it matter if I use
field->Recv(args)
or is it significantly faster to use the func ptr directly
func(args)

=============================================================================
1 July 2005
Let us go ahead and do some implementations and benchmarks. Too many design
decisions here.
- Use of direct func ptrs
- What kind of iterators to use
- Role of msgsrc fields.

test1 was yesterdays/day-before's tests of msgconns. 
test2 is today's tests of msg passing. Works when I set it up by hand, using
	function ptrs I already know. Still need to work out msgsrc stuff.
	Be warned of dangers of bidirectionality in the msgconns.
- Check if storing vs. templating ptr for parent elm makes a difference,
	speed wise: In a very tight loop the time difference is less than 10%.
	Ptr to parent is consistently a tiny bit faster. This is compiled using
	O3.
- Check if using pre-allocated function object is faster than constructor.
	Surprising: constructor is slightly faster. Best to make the op
	fresh each time.
- Using explicit iterators. A little stuck here.

Out of curiosity: What is the hit if we use the virtual func interface
	rather than the current direct approach:

=============================================================================
2 July 2005.
Some more tests:
- Explicit iterators: Not too bad, only about 50% slower. Given that the
function is doing so little,
Results so far, for a single dest per elm and 1 million loops each going through
100 msgs on different elms:
	First time: using ptr to parent = 3.18726
	Second time: using templated lookup = 3.51891
	Third time: using static op = 3.32967
	Fourth time: using explicit iter = 5.55477

To compare: 100 dests per elm and 1 million loops each going through 1 msg
	on the same elm:
1src: First time: using ptr to parent = 3.06259
1src: Second time: using templated lookup = 3.46216
1src: Third time: using static op = 3.14867
1src: Fourth time: using explicit iter = 4.57042

So, a modest difference. After a little further streamlining on the explicit
iter:
First time: using ptr to parent = 3.37233
Second time: using templated lookup = 3.49633
Third time: using static op = 3.31892
Fourth time: using explicit iter = 4.72588
1src: First time: using ptr to parent = 3.06365
1src: Second time: using templated lookup = 3.46149
1src: Third time: using static op = 3.14578
1src: Fourth time: using explicit iter = 4.33437

Now to go to the next stage, 
=============================================================================
3 July 2005.
Plan now is to implement some fields and redo the above tests using the fields
to build the message calls.
Slow work on this in progress.
=============================================================================
5 July 2005.
Field-type lookup examined to inform design decision on whether to use
Recv or RecvFunc for messaging. Used test2 as that is already set up to do
such comparisons. Results are pretty clear:

First time: using ptr to parent = 3.15806
Second time: using templated lookup = 3.51582
Third time: using static op = 3.34169
Fourth time: using explicit iter = 4.74422
Fifth time: using field-type func ptr = 3.16381
Sixth time: using Recv func ptr = 4.2868
Seventh time: using static to local call= 3.4794
1src: First time: using ptr to parent = 2.98543
1src: Second time: using templated lookup = 3.47445
1src: Third time: using static op = 3.14032
1src: Fourth time: using explicit iter = 4.33238
1src: Fifth time: using field-type func pter = 3.1515
1src: Sixth time: using Recv func ptr = 4.18472
1src: Seventh time: using static to local call= 3.48128


Almost a 50% slowdown from Fifth to Sixth time. So we really do want to avoid
the extra func indirection. I suspect this slowdown is because the compiler
cannot inline the function call through the ptr, so we end up with lots of
stack activity.

Also added to the above list the results from the seventh test: what happens
if instead of doing the calculations within the static func, we hand them
down to the local func? Turns out it costs about 10% speed. The first time
version is still the best by far.

Slowly inching towards doing a comparable test but using fields and msgsrc/
msgdest info to set up connection.

=============================================================================
6 July.
Test 7 checked if it was expensive to just use the static function as a
wrapper and put the real work in a local function call. Yes, about 10%.
Would probably be worth it for a more demanding function though.

=============================================================================
7 July.
On the main MOOSE branch, lots of work related to CSPACE and the DOQCS 
conversion. The ssf converter code required some cleanup of delete operations,
which is OK as far as it goes, but in some cases needed ugly hacks of the
delete function call in the kparser, when applied to /kinetics.

Also various fixes have happened over the past few days to the DOQCS converter.
Major one was for calculation of Km for enzyme with substrates in different
compartments from enzyme (should use enzyme vol for scaling). Another one
that cropped up was for sumtotals involving other sumtotalled molecules.
Working on it: compiles but does not fix the sumtotal problem yet.

=============================================================================
8 July.
Finally ran a test with the msgsrc. It is remarkably good. Some surprises:

First time: using ptr to parent = 3.14189
Second time: using templated lookup = 3.54293
Third time: using conn msgsrc = 3.40486
Fourth time: using tgt msgsrc = 3.46511
1src: First time: using ptr to parent = 2.99773
1src: Second time: using templated lookup = 3.48675
1src: Third time: using conn msgsrc = 3.29095
1src: Fourth time: using tgt msgsrc = 3.31411

The third and fourth cases are for the msgsrc to store either the connection
as a ptr, or to the msglist in the connection as a reference.
Suprisingly the connection as ptr case is marginally faster. As it is also
easier to deal with, we'll use the third case.
Key point: Time loss by going through msgsrc is under 10%. Manageable.

Some more variants to check:
Using a clever templated version of the msgsrc to look up the msgconn/tgt
I have a couple of variants on this.
One very politely uses the system lookup func.
The other uses a brute-force offset and some typecasting funcs.

Next step is to go to fields.
Then assignment by value and by strings
=============================================================================
9 July.

Doing tests on templated version to look up msgconn etc.
First time: using ptr to parent = 6.52628
Second time: using templated lookup = 7.20301
Third time: using conn msgsrc = 7.08807
Fourth time: using tgt msgsrc = 7.09933
Fifth time: using offset to conn msgsrc = 6.6189
Sixth time: using offset to tgt msgsrc = 6.67185
Seventh time: using func to lookup conn msgsrc = 6.57357
1src: First time: using ptr to parent = 6.17572
1src: Second time: using templated lookup = 7.16693
1src: Third time: using conn msgsrc = 6.7269
1src: Fourth time: using tgt msgsrc = 6.74209
1src: Fifth time: using offset to conn msgsrc = 6.52464
1src: Sixth time: using offset to tgt msgsrc = 6.52721
1src: Seventh time: using func to lookup conn msgsrc = 6.49134


Results:
- templated version is faster, as well as having less
	storage. Problem is to compute the offset is no fun - needs two passes.
- No advantage (as seen earlier too) for going to the tgt rather than conn.
- Can use function as template for looking up connection msgsrc - it is
	actually a tiny bit faster than a precomputed (and painful, and
	dangerous) offset.

Should redo entire set on athlon64 (3400+). And here it is:
First time: using ptr to parent = 7.12856
Second time: using templated lookup = 7.59086
Third time: using conn msgsrc = 5.48789
Fourth time: using tgt msgsrc = 5.65957
Fifth time: using offset to conn msgsrc = 5.96028
Sixth time: using offset to tgt msgsrc = 5.92494
Seventh time: using func to lookup conn msgsrc = 5.85123
1src: First time: using ptr to parent = 5.39595
1src: Second time: using templated lookup = 5.22574
1src: Third time: using conn msgsrc = 5.6016
1src: Fourth time: using tgt msgsrc = 6.51216
1src: Fifth time: using offset to conn msgsrc = 5.83137
1src: Sixth time: using offset to tgt msgsrc = 5.56474
1src: Seventh time: using func to lookup conn msgsrc = 5.59597

Results:
- Broadly similar to reference set (on a 1GHz Pentium M, so the Athlon is not
	doing too well here.).
- Again, msgsrcs do very well, compared to explicit function calls.
- Again, the func to lookup conn msgsrc option is faster as well as
	cleaner than the precalculated offsets. It is about the same speed
	as having the msgconn in memory.


Next step:
Create a standalone field/msgconn to handle fmsgsrc1.
I can send from the fmsgsrc1.
I can't make a recv func that knows how to call the next fmsgsrc1, though.
	Recv func can call anything on the elm, but how to use the elm
	to find a dynamically created field and its Send() method ?

Suppose all fields/msgconns were dynamically created.
=============================================================================
10 July.

Suggestion: 
- Relation between field info and msgsrc/msgdest:
	Field info has recvfunc.
	msgsrc has Send() operation.
	Field is static
	msgsrc has to be assigned the appropriate recvfunc during msg creation.
	
- Connecting a msg into a field
	field has a value
	field info provides a rfunc that assigns the value.
	Multiple possible distinct rfuncs for different cases:
		Simple value assignment
		Value assignment + trigger(msgdest)
		value assignment + relay(msgdest, value)
		Value assignment block + trigger(msgdest)
		Value assignment block + relay(msgdest, value)
		first trigger, then value assignment
		first relay, then value assignment.

	Should have block as a separate flag. Trigger should be immediate.
	pre and post relay on either side of assignment. Hair splitting perhaps.


For now: Shifted over to test4 to play with fields.
Made a couple of skeletal fields within the testconn.h file.
One is a regular field. Looked at field assignments. Pretty fast.
The other is a msgrelay field, going through the pam msgconn. Significant speed
hit, but doesn't really matter:
Fields: Direct assignment = 0.009759
Fields: Assignment through ifield = 0.020628
1src: using conn msgsrc = 3.31022	// This is the pam version from test3
Fields: using relay5.66045		// This is the relay version.

Now that this is working, time to go back and think about implementation 
issues with fields.

- Access and lookup. Currently by scanning for names through array. Probably
	as fast as hash table for smallish numbers of fields.
	msgsrcs internally hold only the field Recv function. Would like to be
	able to search with this key too.
- Relays: Can insert special fields provided lookup is only by name. However
	msgsrcs may want to do it by field ptr.

Ideal: Text interface uses string lookups, but internally use per-class
	fid that is a simple integer indexing. Somehow want to deal with 
	the elms that have other fields.

Other fields are used for relays. Need 2 kinds of expansion space per elm:
- Replacement fields used in relays
- new msgsrcs, msgdests, and conns.

Reasons for elms to have data ptrs:
- Can replace elm under data for handling additional fields etc.
- Uniform interface to arrays etc.

Not to:
- Simplicity of msg ptr lookup lost
- Possible extra indirection
- Where do we put the msgs?


For relays and other forms of altering fields: Go back to every incoming
msg, tell it to change the recvfunc. Single msgsrcs have no problem. Multi
msgsrcs have to be able to handle multiple msg types anyway.

Were I to pass back a functor, (function object) then I could include
state information about which conns and other things to be activated with
the msg.

If we do this the info about the state of the field is not with it but with
its incoming msgs. Need another way to tell future msgs, calls, assignemnts
etc that the field has been relayed. Perhaps just lookup the vector of 
extensions.

The extension vector has an object that combines smsgsrc and smsgdest.
Could either make it with a bunch of ptrs to a base msging class, or have
a single object type that can handle arbitrary # and type of args, and has
assorted field info for helping lookup.

Every field must provide traversal ops. These have to return a msgconn of
targets in selected direction, plus appropriate field info. For the interally
defined ones have to make these on the fly, or have them statically defined.

Some things to calibrate:
- Time for multi-msg-src to work. Should be small when many msgs.
- See if it makes sense to make a 2msgsrc, having indept thing for each
- Can we dynamically change type of msgsrc? Would be even more worthwhile.
- Time if we replace all recvfuncs with functors. Shoudl work fast, as we
	already use them. Instead of having rfunc ptrs, have the functor
	ptr and fill its arg value v rather than creating a new one.
- May need to pass back functor with a ptr to a nested object, even a
	virtual class. Test time penalty.

- See if we can exhaustively enumerate all possible recvfunctors that need
	to be generated for each field. Three ish.

- Instead of different functor classes, retain current recvfunc stuff but
	have additional arg and an extra ptr in the functor, eg another dest.
- Check if making all the msgsrcs as derived from an abstract virtual class
	would affect speed. Should not.

=============================================================================
11 July
Implementing some analysis functions with the help of the GSL. Starting with
the tau calculations for 1 or 2 exponentials. Next will do FFT.

Implemented both tau and fft. Both appear to work well.
Next step is to handle all this using the analysis object which should
decide if the system oscillates, do tau measurement if not, and go through
all plots.

Implemented and compiled summary.cpp, tomorrow will check if it works.
=============================================================================
12 July
Well, it works sometimes but I currently have a pathological example in m5.g
which doesn't settle, and MOOSE is unhappy about the solution with rk5,
saying the adaptive timestep got too small.

=============================================================================
14 July.
The ee method on a fast machine takes 1 second to do the model with a 
0.01 sec dt. This should be accurate enough for all but the worst cases.
Simply use this rather than rkrun, and we are set. Should adapt cspace
to set this up and do a few more tests using the analysis program.

Notes from 28 June 2005:
How to do an automatic test for bistability, osc, amplif etc.
* Osc: do an fft on outputs. 
- Bistability: 	
	1. Identify concs that do not affect SS. Could use consv laws:
	anything in a consv law is out.
	1.5 Verify by running to SS with minor deviation from init cond.
	2. Change init amount of these to a value around that of the highest
	in system.
	3. Run to SS. Is SS diferent?
	4. Validate: Try new init amount. Should get same SS.
	5. Double validate: See if iterative bisection works. Obtain thresh.
	6. Stoch stability. Run at different vols, look for transition times.
- Infinities:
	1. Just run and monitor. Look for linear and supralinear buildups.
- Amplif, FF filters, delays:
	1. Identify possible inputs. Buffered molecules ?
	2. Vary % wise. Run to SS. Monitor outputs. What is gain?
	2.5 Identify inputs and outputs
	3. Use time-series to look for transient responses with high gain.
	3.5 Identify inputs and outputs
	4. Use time-series to look for delays.
	4.5 Identify inputs and outputs, time-course
- Noise:
	Run at different volumes. Measure sdev of SS. Look at relevant inputs
	and outputs from above. Assess resistance to noise.

=============================================================================
14 July 2005.
Shifting gears abruptly to minimus. 
1. Backed up old version in minimus_10jul05.tgz. Should really get back to 
	terms with rcs/cvs

Working on the functor ptr rather than a function ptr in msgsrcs.
Two costs: One is that the op is now one ptr bigger. 
	Other is that the recvfunc now has to handle an argument for the
	possible use of a distinct msgdest ptr.
In principle one could avoid both if we included an index into the template
	defn of the recvfunc. This would let us locate the new dest, if any.
	Issue: what happens if there are changes in the messaging.
	Advantage: Do not need to touch the current code.
	Issue: How do we pick the right recvfunc to send during msg setup?
	- OK, solution here: 
		- have the recvfunc take the msgconn ptr as an arg rather
			than the element.
		- Use a new recvfunc for relays. This field-templated
			recvfunc refers to the msgconn.
		- For a relay, the msgconn changes to a singlemsgconn on
			the relay vector. This singlemsgconn has all the
			needed info for doing the relay ops as well as
			retaining info about the original target, if needed.
Synapses: The problem here has been that there is additional
	info needed for each synapse. Frequently need to access and index.
	- Recvfunc needs more info. The above functor could do it.
		- Allocate a distinct functor for each synaptic connection,
		include wt etc fields. 
		- Issue of access to fields. Should be easy.
	- If recvfunc used ptr to conn as argument, rather than ptr to
		element, it would be able to go back and figure out index.
		Or no. It would need to _find_ its own ptr, a very slow
		process.
		- At 2 ptrs each, we could have an indept msgconn per src.
		- dest msgconn has a vector of msgconns. They each point to the
			target elm... Actually this would need virtual 
			msgconns, could be done with just the vptr table.
			So it would still be 2 ptrs per: one for the vptr,
			and one for the instance of the msgconn.
			... Actually even this would not work, vector of
			msgconns would still not be able to figure out parent
			without an additional ptr. Also need ptr for the src.
		- Don't want to confuse msgconns.
	- Start from field access viewpoint. On the dest, we want a vector
		of wt, delay, and perhaps a distinct msgconn on each.
		- Each distinct msgconn would have to store Pa(). No way to 
		get back to it.
		- If recvfunc uses msgconn ptr as arg, rather than element,
		it could easily figure out and operate on local delay etc.
		- This would let recvfunc bypass virtual func stuff for finding
		parent, while still retaining the option in other cases.



=============================================================================
15 July 2005
Working on implementing above ideas.
First: Test if passing msgconns works, and how fast.
Result: Yes, it works, but for some reason imposes a speed penalty of about 10%
Here are typical values:
1src: First time: using pam with elm ptr, standalone = 3.14716
1src: Second time: using pam with elm ptr, msgsrc.Send() = 3.41547
1src: Third time: using pam with msgconn ptr standalone = 3.34266
1src: Fourth time: using pam with msgconn ptr msgsrc.Send = 3.66116
1src: Fifth time: using pam with typecast msgconn ptr in msgsrc.Send() = 3.63331

I did the runs using const as well as regular msgconn ptrs, and there is no 
significant difference.
I also tried to use direct typecasting rather than refer through the virtual
func ptrs. Negligible difference between fourth and fifth times.

Just to check, repeated whole lot with -O2. Here it is:
1src: First time: using pam with elm ptr, standalone = 5.08199
1src: Second time: using pam with elm ptr, msgsrc.Send() = 5.20853
1src: Third time: using pam with msgconn ptr standalone = 5.25749
1src: Fourth time: using pam with msgconn ptr msgsrc.Send = 5.50996
1src: Fifth time: using pam with typecast msgconn ptr in msgsrc.Send() = 5.525

Pretty significant!

Well, it is disappointing about the msgconn ptrs. I should also test passing
another arg, just to simulate what may happen if I create a bigger op object.
Result: Another 8% slower than the option where we use msgconn ptr:

1src: Fifth time: using pam with typecast msgconn ptr in msgsrc.Send() = 3.66085
1src: Sixth time: Same as Second, using fatop = 3.9283

So there is a slight preference for the msgconn ptr in speed. Key remaining
issue is whether one or other is more functional. Based on the logic
above, it would seem that the msgconn ptr arrangement is also easier to 
set up with synapses and relays.

=============================================================================
16 July 2005
Consider possibility of only two kinds of fields: methods and values.
The values are already rather easy to handle on all counts: recv, send, and
trig.
For the methods, it would imply that we would connect out from a method
based on the things it does downstream. Let's look at proc in an 
equiv ckt compartment:
proc->axial (on next compt)
proc->raxial (on prev compt)
proc->vchan (on channel)

So if we just have a connection from a method (proc) into something else,
we have no way of knowing which of these is intended.

So we do need 3 kinds of fields:
methods, msgsrcs, and values.
methods take incoming msgs and do an operation on them. They typically
have implicit msgs into msgsrcs.
msgsrcs take incoming msgs as triggers, also permit incoming msgs which they
just send on with same args.
Values can take and send msgs and triggers.

The finfo data provides recvfuncs and trigfuncs for all of these. These two
functions initiate all the possibilities:
		Recvfunc				Trigfunc
methods/msgdests: Execution of a local function.	Only if 0 arg func
msgsrcs: 	Execution of a remote function		Only if 0 arg func
fields: 	Assignment of a value			Trigger of remote func
							with value as arg.

Treat all fields as handling msgs. In many cases this will involve extending
the object. This happens through a single class, the relay. It combines
roles of field, recv, send, and msgconn. It is pushed onto the relay vector on
each elm. In some situations the relay overrides the original field. In some
situations we have to backtrack to all msgs to override the recvfunc.

		As src of msg			As dest
methods:	Relay for recvfunc does fwd	Relay has msgconn, own func.
msgdest:	Relay for recvfunc does fwd	Internal msgconn.
msgsrc:		Internal msgconn, Send(T)	Relay has msgconn, new func
value:		Relay has msgconn for value	Relay has msgconn, sets val
						or: Relay/msgconn trigger
						for any downstream msgs.

So each finfo will have to provide Add1, Add2, Drop1, Drop2 functions. The
overall func is something like
Add(f1, e1, f2, e2) {
	m1 = f1->Add(e1);
	m2 = f2->Add(e2);
	m1->Add(m2);
	m2->Add(m1);
}

Now: field access.
- Assignment and calls: Take recvfunc and plug in values. Conversions...
	- Field has cinfo for equivalent class. 
	- Equiv class anyway has fields of equivalent type.
	- cinfo may provide str conversion either way for data part of class.
	- Simpler, less additional junk: User provides a strval field for
	doing the equivalence stuff. Just look for this field.
	- Better: cinfo may provide a strval converter either way.
		- Fields for obj data value and for its strval are
			generated automatically
		- Strval can be composited because cinfo knows about base
			classes and about the fields within the current class.
		- Use this internal strval converter rather than field. This
			avoids having to instantiate object to do conversion.

- Assignment is of 5 kinds:
	field = field	Recvfunc(e1, Val(e2))
	field = str	Recvfunc(e1, cinfo->ValFromStr(const string&)
	field = val 	Recvfunc(e1, val)
	str = field	string cinfo->StrFromVal(&Val(e1));
	val = field	val = Val(e1);
	- should be able to do first three with recvfunc for assignment
	- T Val(elm) would be a nice func, could pass directly into recvfunc.
- Getting values: The field provides a recvfunc for a passed in variable,
	and calls it:

- Finding msg src and dest. These include internal srcs and dests.
	unsigned int f->NSrc(element*)
	msgsrc* Src(unsigned int)
	unsigned int NDest(element*)
	msgdest* Dest(unsigned int)

- Indexing, arrays, structs
	Treat as a single field.
	- For all field operations, return a container class (not ptr)
	so that there is automatic destruction. This lets us also store
	internal indirection operations like array lookups and ptrs and
	subfields. Consider synapses, for example.
	- Field would have to provide parsing for special stuff.
	This means that lookup needs to use a field func like Match rather
	than a simple string compare.
	This also means that simplistic fids are not on.
	- Alternately provide a generic nesting of field lookup operations
	so that the synapse entries would look like cell/syn[503]/weight
	- This could also be done using the Match option.
	- Want to extend le to handle these.

- Other field info
	- listing by le
	- Showing by show
	- Type info as a subfield, coming out of elm equivalence.
	- Name as a subfield

                               *---*

Looks like the basics are now sketched out. Implementation issues:
- To build test framework first, or go right out for full implementation?
	- Test will iron out details
	- Test will need a lot of implementing, take a long time,
		and have to then redo
- Naming convention. Now or never. Look up in Google
	classes: Lower case.
	Methods: Upper case.
	Fields: lower case.
	connections: conn.
	msgsrc: as is.
	msgdest: as is.

Later: mpp syntax for future reference.

Setting off on a new implementation as a test. It is in 
moose/minimus2/
=============================================================================
17 July 2005
Slowly building up test framework. Compiled with cinfo, conn, element,
p_element, msgsrc.
=============================================================================
19 July 2005
Precious little work feasible. Nevertheless, in the process of implementing
an analyzer for stochastic runs to decide if they might be bistable.
All it does is to check for bimodal responses of some of the parms.

Finally got it working, sort of. Using a statistics-like test to look 
for reasonable bimodality. 

Tested it on the inh_fb bistability. Seems OK, but lots of false +ve
values. 

=============================================================================
20 July 2005.
Cleaned up binning for stoch bistability test. This is tricky, to get a
volume where there are spont transistions. The inhib-fb model does so only
at very low volumes/mol numbers.

Overall, our time-series based characterization algorithm could work like
this:
1. Run a deterministic time-series to settling.
	- Look at values and slopes: Break if infinities.
	- Look for fft. Break if oscillatory
	- Look for taus.
2. Run a stoch series for different volumes, starting at low volumes.
	- Look for bimodality
	- Look for distribs of noise
3. Run a series of deterministic calculations to settling, using
	different init conditions set by zeroing out all but one of the
	members of a consv group.
	- Look for distinct settling states

Runs 2 and 3 should indicate multistability and suggest if SSF is needed.

=============================================================================
21 July 2005
Several things to do to get above list going.
1 Need to lump all the analyses from 1 into a single object
2 Need to make a volume scaler - probably a function call
2 Need to make a propensity estimator. Possibly borrow what the adstoch does?
2 Need to make an object to handle volume series and do stoch runs, followed
	by the stoch bimodality analysis. This would work by finding 
	smallest n for non buffered molecules and scaling it up. Set an
	upper limit based on the propensity so that runtimes don't get too big.
3 Need to make an object for doing stoich analysis separate from the ssf. It
	should: 
	- check stoich
	- Emit minimal set
	- Emit consv groups and their coeffs
3. Need in general (also for SSF) to make something to check coeffs around loops
3. Need to make an object for doing multiple runs with different elements
	in consv group zeroed out

4. Finally, need a function or object to coordinate all of the above.


Starting on option 3.

=============================================================================
22 July.
Item 3 first part works: compiled in object for doing stoich analysis, except
	that it only does the consv groups so far. Enough for now.
Skip coeffs around loops, but will come back to it.
Now to use the new object to handle multiple runs with different elements
	zeroed out.
	- Look for mol coeffs with opposite sign of const coeff.
	- Set up model with values set appropriately
	- Run to SS
	- Examine values. If they are essentially the same, then we have
		single stability. Otherwise, request SSF to chip in.

Beginning the set up of the determ_ssf object, which will control all of this.
=============================================================================
23 July
Initial pass with determ_ssf got to work, now I have put in the skeleton of
a complete version but have yet to compile etc.
=============================================================================
24 July.
Success! determ_ssf now correctly finds 3 steady states for the reference
model, the inhib_fb model. Now need to try it on a few others.
- Also works on pos_fb model. Way faster with the rk5 method.
- Gives something of an answer on the ampar model, but the correspondence
is not so great. Possibly simply a settling time and/or numerics issue.

Should do the initial run, eliminate infinities and osc, and then look for
taus. Do the run for appropriate times based on tau. Use rk5, almost always
better.

Some tests to run either before or during the big runs:
- Take some classical cases of interesting behavior and run them through the
	Monte Carlo parameter variation stuff to see if we pick up the 
	behavior. Idea is to establish density of sampling we will need.

- Brusselator
- Oregonator
- Chaotic model
- Inhibitory fb bistable
- Excitatory fb bistable
- Kholodenko bistable
- AMPAR bistable
- Zero order hypersensitivty: Goldbeter and Koshland
- CaMKII hypersensitivity

To do this, I need to implement in MOOSE the same kind of stoch explorer as
we have in the cspace program.
Working on scrambler object to do just that.
Scrambler object implemented. Seems to work, see
~/genesis/moose/SSF_test/inhib_fb_scramble.g

Clearly need to work on freq analysis part.

=============================================================================
25 July
Trying to dump model. Kinconv for kkit format seems to lose buffering info.
OK, fixed and now it corresponds well to the state from the determ analysis.

More or less working. Set off a run using method 1 (Runge Kutta) on 
DBC. This has gotten seriously bogged down in the slow runge-kutta runs.
Will need to use EE. Slower in some cases, but time is bounded.
Looks like several of the current runs are bistable, will need to check.
Time: Did 170 or so in an hour.
Total	172
1	163
2	6
3	3

Reran using EE with dt= 0.02. This produced lots of garbage: Huge numbers of
supposedly bistable and higher order states. Most likely due to numerical error.
Time: Did 1000 in about 8 min. About 2 per sec, or 12 sec each on each node.
# of reported states:
Total	1016
1	108
2	238
3	221
4	199
5	141
6	80
7	29

Reran using EE with dt= 0.005. This produced slightly less garbage, took
33 min to produce 1000 runs. 
# of reported states:
1	455
2	247
3	215
4	101
5	24
6	9
Time: About 1 min 20 sec per run per node.

So at this point the basic state finder seems to work.

Looking at some of the calculated runs from DBC. There are errors in Km
terms for enzymes: Too small and the ratio is something random. 
a1: an infinity, but I need to report it properly
a2: Not bistable, but one state settles so slowly it would have not settled
by the time the test time ran out.
On other set, the only thing with 2 states was also a slow settler.

To do:
	- Report infinities properly
	- Report parm vector for db.
	- Fix enzyme ratio stuff.
=============================================================================
26 July
Done all three above. Now also to tie it to the CSPACE model generator,
and to automagically generate an SSF file for the interesting models.

=============================================================================
27 July
Done the above. Some more things to do for now:
- Volume scaler
- Reacn Signature reader
- Median-based bimodality calculator
* Test above out on systematically modified models of inh_fb_bis. See
	what the energy landscape and bimodality landscape looks like.
	See: kadam:homework/CSPACE/jul27_2005_landscape/

The simple bimodality calculation has two issues: First, it give zero
if it doesn't look bimodal. Second, it seems to need a local minimum between
values. Might not exist.
Work on median based  and other bimodality calculation

=============================================================================

30 July.

Converting minimus2 to more consistent naming style. Still in progress.
=============================================================================
31 July.
Converted. Compiled. Does parenting OK. Note that this still uses msgconns
directly. We need actually to do through msgsrc/msgdest finfos. Later will
work out if these finfos can refer to the msgconn without having any other
storage requirements... should be possible for things like parent-child msgs.

For now: Work on fields.
* Implement a string moose class.
* Use it to set and read object value.
* Use it to set and read object names.
	* Including referring fields to base class.
* Implement an int moose class.
* Implement a test class having string and int fields.
+ Assign parts and all of the test class.
* ? Interconvert between string and ints?
- Figure out indirection and arrays in fields.
	- Pass in reference for Field into match(), to be filled in if success.
		Field contains finfo ptr and indirection info.
	- Pass in reference for Indirection into match(), to be filled in.
		Indirection contains indir info.
	- Use a conn derived class for indirection.
- Start on msgs.

So some progress. The int class should be simple, but a good test. The
key things now are interconversions and indirection.
Working on func_field for ints. Too tired.

=============================================================================
2 Aug 2005
Got int class to work.

=============================================================================
7 Aug 2005
Implementing the test class with int i_, j_, and string s_.
Current ideas:
	- All fields (not just evaluated ones) should provide a set and get fn.
		Avoids using the field ptrs.
	- The class provides set and get functions for access to its value
		- Use an elm ptr as an arg?
		- Use operator=(Element* other) to do this?
		- Get?
	- The class provides set and get functions for access to its strvalue
		- Only if builtin class?
		- Use a static void strSet(Element* me, const string& val)?
		- Use a static string strGet(Element* me)?
		- Use a virtual functions and a string?
		- Should it provide a set/get function for data part only?
	- Every finfo then can handle both string and value set options.
		temp = f->cinfo_->CreateTemp();
		temp->strSet(value); f->set(other, valfinfo);
		delete temp
		

As the whole class is a field, may need to revisit: perhaps a template or
dual inheritance approach.

Template: A lot of things can be automated
Dual inheritance: simpler?
Separate object for data part: Cleaner separation, arrays. Extra indirection.
Problem throughout has been messages. Are they part of the data? They 
certainly are part of the data _logic_.
Scheduler, for example. This has to directly do stuff to the message data 
structures themselves.
For now, just brute force it.

=============================================================================
9 Aug.
Four approaches to string handling of fields:
- Some set of global stoi/itos type functions.
	- Simpler
	- No dependencies
	- Less general
- Current approach of defining elements. The elements will have to be created
	for every conversion because we cannot use templates.
	- More complex
	- Conversion needs elements
	- General
	- Possibly recursive. May be able to do everything.
- Let parser deal with conversions and type matching.
- Let Field<T> deal with string conversions.

Last looks simplest.
Working on it, seems to compile, but still to test. Will implement a
getField and setField function.
Done. Tested. 

Now looking at string set and get. Can do it through a 
virtual function off the base Finfo, but that would be somewhat dubious
as it is used only by the Finfo1 templates. What to do?
Made an intermediate baseclass, Finfo1Base. This does the trick.
strSet and strGet now work. Final test on TestField class, also works.

Refer back to 31 July. Current status of targets is:
* Implement a string moose class.
* Use it to set and read object value.
* Use it to set and read object names.
	* Including referring fields to base class.
* Implement an int moose class.
* Implement a test class having string and int fields.
+ Assign parts and all of the test class.
* ? Interconvert between string and ints?
- Figure out indirection and arrays in fields.
	- Pass in reference for Field into match(), to be filled in if success.
		Field contains finfo ptr and indirection info.
	- Pass in reference for Indirection into match(), to be filled in.
		Indirection contains indir info.
	- Use a conn derived class for indirection.
- Start on msgs.

We are not able to do the whole of the test class yet. Back to the issue of
the representation of the data class.

First: Thinking about indirection. Specific example: Synapse. Dest has
array of (wt, delay, trig). Conn has been set up (for efficiency) to point
right at these. Recvfunc looks like

synfunc(conn, time) {
	syn = static_cast<synconn *>(conn);
	trig = currtime - (time + syn->lookup->delay);
	syn->pa()->act_queue.push_back(trig, syn->lookup->weight);
	// Later the Process will look at queue and 
	// update the activation for an exp decay if any events have matured.
}


Looks like the conn is some steps removed from the finfo access. Just as well
to avoid confounding the concepts.
- Return a newly allocated Finfo* or the current static Finfo*, where
	necessary. 
	- Use a special deletion func that has to be invoked after use. 
	- The Finfo* has a virtual void* lookup(Element *) method, details
		are specific to the Finfo subclass. Needs later typecasting.
	- the Match function creates the new Finfo where needed.
- Return a Finfo object, not a ptr.
	- How do we handle different types of object? vfuncs?
- Return a wrapper as an object, this wrapper holds the original Finfo as a ptr
	and also a ptr to a lookup class that has virtual function
	virtual void* lookup(Element *)
	The original Finfo is never deleted, the lookup always is.
- The wrapper itself has the lookup data.

Once we have this returned thing, it provides the RecvFunc and a Conn creator?
=============================================================================
11 Aug.
Now on to doing indirection and arrays. As this is going to break a lot
of things, I will leave the existing code in minimus2 untouched, and
go on to minimus3. 
The things accomplished in minimus2 are:
- Conversion to coding standards
- Field set and get
- Element creation
- String set and get for fields
Not done:
	- Full object set and get.
	- Automatic stringification of full object.

In minimus3 the goals are:
- convert finfo access to use the Field class, to handle indirection and arrays
- incorporation of msgs.
- Message traversal and access
- Synapses
- Full element assignment and stringification


Starting on the finfo access. Looks like Field class is just a wrapper for
finfo, with a guarantee of clean deleting. Turns out that the time to make
the indirection stuff is in the match() call itself, and that the best
place to store it is in the finfo itself. So the job of the Field class is
only to ensure safe deleting and copying of finfos.
	- Should not delete native Finfos (the ones defined at startup)
	- Should delete non-native Finfos (ones having lookup info)
	- Should always make ptr copies of native Finfos.
	- Should always make full object copies of non-native Finfos.
		- Accomplish above with special delete and copy methods
		in the Finfo itself. Then all our field has to do is to
		invoke these when it is created or deleted.
		- Implemented revised version of match().
		- Need to run and test

=============================================================================
13 Aug.

To recap:
In minimus3 the goals are:
* convert finfo access to use the Field class, to handle indirection and arrays
	This needs to be compiled and tested. Done. Works. Now to test:
	Made TestField which has a vector. Trying to compile.


	* Can hack it to work if the SetConn includes a field for the 
	index. However, the general case is going to run into difficulties
	here. Suppose we do piggybacking. We may need to handle special fields
	using a shared conn. If both the original and the piggyback version
	need distinct special fields, we have a mess. The extra info should
	therefore be in the msgsrc.

	- Ideally conns should be generated by the fields, as they will
	know what inner data are needed. Issue:
		- How do we handle multiple kinds of conns. 
		- Perhaps we only ever generate one kind of conn: used in
			relays.
		- Perhaps the special finfo is itself a conn. Dual
			inheritance.
		* Perhaps we have a set of Conn generating vfuncs.
	Implemented the last of these.

- incorporation of msgs.
- Message traversal and access
- Synapses
- Full element assignment and stringification

=============================================================================

14 Aug.
Implemented a somewhat ad-hoc fix for doing indexed assignment, but it has
possibilities for future use with other kinds of indirection as well.

Going on to msg implementation
+ msgsrc
	Fields have specification (Templated offset) of applicable conn
		in some cases.
	Data has recvfunc ptr, in some cases conn ptr too.

- msgdests
	Fields specify conn and recvfunc lookup.

If we want to specify msgs separately from data, we would put recvfunc ptrs
and conns on the element.

Some progress on msgsrc and its field. needs considrable cleaning up.




Pros and cons of different element implementations can be worked out later,
but will require an assessment of speed, size, and elegance for
different implementations. In minimus4 I will redo with the ptr implementation
for elements to directly test speed impact, which is currently the biggest
concern.


=============================================================================
15 Aug
Implemented the following:
	MsgSrc: field for handling msg srcs. 
		Will need elaboration for NMsgSrcs to deal with multiple target
		recvFuncs.
	SrcFinfo: Finfo for handling MsgSrc
		Needs cleaning for the methods for lookup of Src and Dest.
	DestFinfo: Finfo for handling destinations, but there is no
	explicit MsgDest field. The DestInfo has enough info in
	the Conn and Recvfunc.
		Needs cleaning for the methods for lookup of Src and Dest.

Leaning toward using an extended form of Field to return both Finfo* and
Element* .

Looks like it ought to be easy to locate the Field for sources of
messages to the DestFinfo. Such Fields are 
well defined by the combination of Conn and recvFunc.

Looks also like similarly we should be able to find DestFields. With this
info we are in a position to traverse msgs, but first lets do the
implementation.

=============================================================================
16 Aug
Compiled stuff with the MsgSrc etc.
Now trying to put in the search for msgsrc and msgdest:

271         bool rFuncMatch(const void* func) const {
272             return ( func == (const void*)recvFunc() );
273         }
274         

=============================================================================
17 Aug.
Slowly implementing messaging in a TestMsg. Finally compiled.
Seems to run but too tired to do more checks.
=============================================================================
18 Aug.
Now to look into traversal.
Then to put message access stuff into field access.
Things to check
	Traversal
	* Regular, outgoing
	* Regular, incoming
	* internal, outgoing
	* internal, incoming
	+ Repeated msgs between same fields (consider reactions)
	Msg access: field type access to
	- nsrc
	- ndest
	- src[i]->element
	- src[i]->field
	- dest[i]->element
	- dest[i]->field
		These are aspects of all fields. Want a general way to do it.
	Multi Msgs:
	* Building rfunc lists
	+ deleting rfunc lists
	* Executing rfunc lists
	+ Sorting conns by rfunc
	All msgs:
	+ Adding
		As src
		* msgsrc
		- msgdest
		- field
		As dest
		- msgsrc
		* msgdest
		- field
	- Deleting
	- Cleanup. I think that the MsgSrcs should be derived and use vfuncs.


field:	These must exist ahead of time in the C++ object.
	field a;		// Regular value field. Make a set and get.
	readonly b;		// Readonly field. Make only a get.
	evaluated c;		// Evaluated field. Expects set and get provided

conn:	(usually not needed as it is defined implicitly for most msgs)

	uniconn conn1
	multiconn conn2


msgdest:
	msgdest m0		// Assumes a function m0( Conn * ) or
				// e->m0(). Automatically make code for latter
				// Makes conn automatically unless already there
	msgdest m1		// Assumes m1( Conn* T ) or
				// e->m1(T). Figures out typing.
				// Makes conn automatically unless already there
	msgdest m2		// Assumes function m2 ( Conn *, T1, T2 ) or
				// e->m2(T1, T2). figures out typing.
				// Makes conn etc.
	piggydest p0.m0		// p0 uses m0Conn.

	msgdest f0=>s0		// Internal message from f0 to src s0 
	piggydest p1.m1=>s1,s1b	// p1 uses m1Conn and calls s1, s1b.



..........................................................................
Down to business. Implementing the multimsg stuff. See 
/home/bhalla/genesis/minimus3/basecode/MsgSrc.cpp

Getting close but not compile yet.
=============================================================================
20 Aug
Working on fixing up multiconns. Messy but now on the compilation stage.

6:30 pm: Compiles, does not work.
Stuck in debugging. Perhaps pursue what happens in Op1  in MsgSrc.h
Possibly also the iterator at line 245:
	for_each( j, j += i->count(), op )
doesn't work they way I think.
Retried, and things change. Look at it later.
=============================================================================
21 Aug.
Basic stuff in multiconns looks OK now.
Deleting objects doesn't yet work: Conns die. Get core dump.
Issue appears to be disconnect between Conn drops and the MsgSrc.
Conn drops have to trigger a drop at the MsgSrc.
Can do by looking for all src fields using the conn.
But: What triggers a Conn drop? 
	- Deleting
		- Insert a 'doomed' tag onto all elements that are going to
		be deleted. Conns coming into these do not need to clean up
		when the conns are deleted.
	- Message drop call.
		We use an indexing approach to see what is in a message.
		- From the API, drop would be one of:
			- Drop a specific connected Field (Finfo + element)
			- Look up a message and drop it; with index
			- Drop all targets satisfying some condition
				- On a given tree
				- Of a given type.
			- Drop all targets
	From this list, it seems the simplest is to leave it to the Conn
	to find all attached MsgSrcs and clean up.
More fundamental issue: I have not generally implented message add, nor
	drop anywhere at all. Where do we do message add? Given that we want
	all fields to be able to handle messages, we could put 
	add and drop in the Finfo.
		- Fields will know what to do with themselves for add/drop.
		- But, fields may need to replace selves with relays in order
			to handle the add/drop
		- Could return a Field rather than a bool.
		- Could simply assume that the field is no longer valid.
		- Could require that access is through a wrapper function that
			does the right thing. But anyway, field becomes invalid.
	Moral: Don't store fields.
Another headache: Conns are needed to do messaging. Do I make Conns an
	invisible object for the API and stick to fields and elements?
	- Fewer things to deal with
		- Actually we still want to refer to the field for nSrc etc,
			because the conn does not know about intrinsic triggers.
	- But, lots of intermediate functions

API Options for fields to handle messaging:
		Field src(), long nSrc, Field dest(), long nDest, add, drop,
			Conn* in() (for dests), MsgSrc* out(),
			matchRemoteFunc(),
		OR:
		Conn* in(), Conn* out(), MsgSrc* out()
		Can't do this as MsgSrc is not a class tree.
		OR
		Conn* in(), MsgSrc* out()
		Can't do this as MsgSrc is not a class tree.
		OR
		Conn* in(), Conn* out(), add(), drop(), matchRemoteFunc()
		- add, called within a regular MsgSrc:
			dest Conn tells add() method if it can have anything
			added. If so, regular add onto dest Conn.
			If not, then add() method asks the parent dest field.
			Usually field will generate a relay and go from there.
			May forbid, for example, second Parent to an elm.
			See below.
		- add, called from a value field:
			Value field creates relay on parent elm.
			Relay has internal info do to MsgSrc stuff, including
			a local Conn.
			Usual stuff for dest.
		- add, called from an already full SingleMsgSrc:
			Check if the add is allowed. May not be, e.g, to self.
			Src field creates relay on parent elm. Relay refers
			to original msg.
			Usual stuff for dest.
		- add, called from a MsgDest.
			- Could either use the incoming args, or as trigger.
			- Create relay on parent elm.
			- Relay bounces incoming stuff onto original as
			needed. Could be pre, post, or not at all.
			- Relay also does MsgSrc stuff, including local Conn,
				to send it out again.
			- Usual stuff for dest.
		- dest, as regular conn:
			Works as usual
		- dest, as singlemsgconn, already full:
			Refer back to field.
			May forbid, for example, second Parent to an elm.
		- dest, as field dest for info purposes only:
			Info conn refuses added msg.
			Refer back to dest field. Dest field creates relay,
			which has a local InConn.
		- dest, onto a field already getting dest info:
			Usually bounced. Otherwise dest field will have to 
			know about relay, how? Field access will have to point
			to relay, not to original. Relay will handle.
		- dest, onto the  srcfinfo: Info conn refuses. Refers
			back to SrcFinfo, which creates a relay. Relay
			takes args that match the msgsrc::send(args), and
			calls its with those args.
			
Things to do with a relay using an existing msgdest as a src:
	- Call on before original msg
	- Call on after original msg
	- Block original, call on.
	How to specify?
Things to do with a relay using an existing msgsrc as a dest:
	- OR with the original input to the msgsrc
	- Block original, call on.
	How to specify?
Things to do with a solver
	- Add a relay. Its match() function will intercept calls to all of the
	taken over fields.
	- Msg is added from solver to 'solve' field of target. Solve field
	does not have a data counterpart, just ensures that the correct
	relay is set up.
	- Solver sets up additional specific relays to any field that is
	getting or sending messages. These specific relays point to appropriate
	dests/srcs in the solver. For example, plot msgs. 


Other jobs for this stage:
	- stress test the multimsgsrc with different targets
	- Do piggybacks
	- Do relays, automatic formation of messages between unusual targets.
	- Do Solve relays?
	- Implement Synapses
	- Speed tests.

Other stages:
	minimus4?:
		- Sort out Elements as having ptrs to data parts
		- Compile on Windows
		- Put on SourceForge
	rebuild:
		- Port over existing MOOSE
	parser:
		- Simple threading
		- Do parser
	threading:
	MPI:

=============================================================================

22 Aug 2005
Working on the conversion of the API. In DestFinfo need to come up with a
way to return a Conn that has the internalDest info. Essentially set up the
internal static Conns to point to each other.

=============================================================================
23 Aug.
Slowly working through it. I have put the recvFunc() function up as a virtual
for the Finfo, this makes many things easier. But I need to work out how to
handle trigFuncs.

5 pm: Compiles. Dumps core in the message traversal stuff, which I had filled
up with dummies and nulls. But it successfully executes the messages first.

Building up framework of conns etc between finfos that are triggered
internally. Try to use the existing structure for tracing messages.
Need to fix up the FinfoConn.
Remaining issue is to ensure elements are correctly filled in the field:
issue of thread safety.


=============================================================================
24 Aug.
Some message tracing works, but some still come out with a dummy. Basically
grinding through now.... Fixed.

Next step: crashes when some objects are deleted. We were here a good while
back.
Quite stuck. Not clear why it is dying. It is not simply the number of 
elements deleted, any deletions cause problems.

Try a call directly on # 98 and on # 0.
As we go through a huge number of stages in the stack, looks like #98 is
the culprit.
Tracked it down. It was the fact that the rfuncs_ vector is not updated
when the conns are dropped. When dropping a MultiConn, need to scan all
fields that use it, and go through them to clear out recvfuncs as needed.

Working on a cinfo::innerDrop type function which will go through all
fields on an elm which is linked up by the connection that is to be
removed. For each field the innerDrop cleans up the recvfunc only. The
conn itself is dropped after all this cleanup is done.

=============================================================================
25 Aug.
Deleting msgs nearly done. Nearly works. Remaining issue is that the 
parent->child conn is done in a 'dirty' manner, without fields being involved.
Fixed.

Starting on relays. May need to make a new kind of UniConn that knows about the
parent elm as a ptr.

Slowly implementing RelayFinfo. Uses but need to define a good Conn class.
Also don't forget to handle the relays going into Srcs and relays coming
from dests.
=============================================================================
26 Aug
Working on relays. Implementation proceeding using RelayFinfo and RelayConn.

As src
	* msgsrc	Original
	+ msgdest	Intercept incoming call to msgdest, forward data
				to msg. Here we decide about 4 options of
				ordering outgoing call wrt msgdest.
				Default is to execute msgdest and then onward
	+ field		Forward field data to msg, or forward trigger from
				field change to msg.
				Issue: If we have a field here we need to
				do a finfo type adaptation operation.
				Won't work if the Relays have a fixed
				field assumption.
				- Use a separate kind of relay for such
				cases. This is 0 args -> 1 arg.
				- Come up with a general solution for 
				N args-> fewer args(e.g., trigfuncs)
				- Come up with a solution which lets us
				put values in message fields.

As dest
	+ msgsrc	Use recvfunc provided by msgsrc. Incoming msg is
				used to provide trigger and args for send()
	* msgdest	Original
	+ field		Put msg data into field. If outgoing msgs exist from
				the field, this triggers a call to
				the outgoing field msgs which in turn could
				be field value or a trigger.
			Or, just trigger the outgoing call.


Issue arising: 
- adapting message arguments. Three main cases:
	- Fields. They take a trigger (0 arg) in and generate a T value out.
		Probably best done with a single templated special case.
	- per-message variable arguments. Synapses are one example, but
		consider the distance calculation used in the efield object.
		Here I think we should just have these fields located as
		synapse-like vector fields on the dest. Is there any case
		where the fields are on the srcs? Possibly delays for
		synapses, so that intervening postmasters could deduct time
		lags. But even those could simply be a special case of 
		messages with flexibility on the delivery schedule.
	- Downgrading an incoming message into a trigger.
		Could do fairly easily. Not clear if it is relevant.
	
- Intercepting messages at other points.
	- Msgdest, taking the calls it makes to outgoing msgs: 
		- Trivial, just add another msg target
	- msgsrc, taking its arguments somewhere else
		- Likewise.


Most things are done, skeletally. Need to formalize the process of creation
of the relay finfo and its conns.
	- Creating the relay
	- Putting the relay on the element
	- altering field sort function so that it first looks for relays
	- Altering conn deleting stuff to do the same.
	Then, tests:
	- Setting int via msg
	- getting int via msg
	- Setting int and triggering another msg.
	- Connecting alternate dest to input of msgsrc
	- Connecting int to input of msgsrc
	- Connecting alternate dest to int.

=============================================================================
28 Aug 2005.
Creating relay getting there. Current approach handles relays at src. 
Issue: What do we do when a relay needs to arrive at a dest?

Also should look at taking the finfo::add function and putting into the .cpp,
and almost all of them can be unified. Will need the conversion of the 
IsA test to look for Finfo1<T> level checking, rather than the specific type.

For doing plot type field accesses, we need to send a message from the plot
to the field to trigger a return message to the plot. This should be a
single add message call because we need to use a specific RelayFinfo for both
directions of the transfer. We need therefore to pass the RecvFunc of the
plot to the original field at the time of formation of the message. We cannot
pass the RecvFunc to the relay, which does not yet exist.

Deeper issue here: Currently the 'add' assumes that the target already can
handle the incoming msg, so it should return a valid inConn.
Not true for field or MsgSrc targets. In MsgSrc we currently have a horrible
hack to return the _internalSrc conn which is used to represent internal msgs.

So the target needs to explicitly do the following with the incoming msg
request.
- return a recvfunc after type checking
- return an inConn if it exists locally
- create a RelayFinfo if needed, and return recvfunc and inConn for the relay.

All this could be done if it returns a finfo that could be either itself
	or the relay. The returned finfo details may depend on the type
	of message requested, so it would return a regular RelayFinfo in
	one case, itself in another, and a TrigRelayFinfo in a third.

This will add another layer of mess to the message deletion and lookup
operations. Can we consolidate?

Will also need to coordinate with array finfos and other things that have
additional info in the finfo. The match() function is going to return a
field, we should use the field carefully for the later stages or the finfo
might get deleted. In particular, operator->() should be used with great care.


Compiling preliminary pass. Many things like field access and deleting still
to come.

Also need to redo the get/set/strGet/strSet functions to use messaging 
properly, so that events get triggered if fields change and relays and other
messages get triggered upon a Set/Call.

A SetField would work, as a standalone field created temporarily that 
uses the regular Relay stuff and also can talk to the set/get calls.

Seems horribly complicated compared to just sets and gets, but:
- compatible with other relays and msgs.
- node transparent.

Compiles. Appears to run, somewhat to my surprise. Made an apparent message
from one field to another, but much yet to do to test.

=============================================================================
29 Aug.

Working on the Finfo for accessing field values.
Looks like I need a special addmsg to deal with field request type messages.

=============================================================================
30 Aug.
Sorted out field request stuff. Not special addmsg, but special respond and
special field type. Will need to replicate this kind of field for graphs
and other field requesters.

More stuck: String conversions from fields.
Issue is that the AssignFinfos depend on the Finfo
Tried doing using extern and other ways to define the templated functions.
No luck. Options
- Return a suitably typed new Finfo* with an AssignFinfo< T > as a virtual func
- Juggle dependencies, put the AssignFinfo set and get classes into Finfo.h
  placed so that dependencies are OK. Could make a further sub class on <T>
  so that this can be done.

=============================================================================
31 Aug.
Finally compiled, after much work especially around const finfos.
When running gives 
Error: setField(i1, value) failed
Warning: .dropComplete( i1) failed. 
Warning: .dropComplete( i1) failed. 
Warning: .dropComplete( i1) failed. 
...

Finally, signs of movement. The assigns are working, both direct value
sets and string sets, but it fails to clean up after.
- The set command does not put an rfunc on the target. We do not need to
	clean up rfuncs in that case.
- If there are no more conns coming into a relay, should we delete the whole
	relay?


Issue with adding onto an existing relay. RelayFinfo1<T> needs to be able
to handle Get as well as Set operations. Should respondToAdd in a 
way which can deal with Gets.

Fixed the GetFinfo case. Just delete both Finfos.

Stuck on SetFinfo deletion.
Now looks like that is OK. All we have to worry about now is the
core dump...

=============================================================================
1 Sep
The problem is due to lost finfos, an issue that Fields were supposed
to take care of. Issue is that Fields can be made using a bare Finfo ptr,
and unless I watch out I could make a field with a ptr belonging to another
Field.

Got simple field access to work
Got array field access to work.
Still dubious about destroying fields.

DropComplete now fails when deleting the setField call onto the in msg:
setField<int>(tm[0], "in", 1234);

We have a very ugly mess with the Conns and the associated RecvFuncs.
Delete is called in two cases:
- Deleting a specific message. Here we know the src and dest Fields.
- Deleting an object and therefore all its messages. Here we know
	all the connections, and with each we can associate a func, either
	the remote func or the local one. Sometimes there are multiple funcs.

Related issue: How do we identify a message?
	Src and dest fields would be best. 
Can we get src and dest fields if we know the conn alone? No.
We need the additional info of the func, and which is src and which is dest.

Deleting objects
Obj is src: Do nothing for funcs. The target does not care
Obj is dest: Take rfunc to each conn src. Delete it there.

Should I make a msg identifier field,
class Msg {
	Conn* src_;
	Conn* dest_;
	RecvFunc f_;
	Finfo* srcFinfo_;
	Finfo* destFinfo_;
}

Extreme approach: Provide no info except conns at either end.
To get func: Scan all fields, and within each field scan all src/dest
Need additional info about which is src and which is dest.

Need to devise API for doing all this.
=============================================================================
2 Sep
Perhaps a simpler approach: Make it so that the removal of a Conn has no
effect on the recvfunc requirements. If we put each recvfunc in association
with an independent set of Conns it should Just Work. The only thing will
be garbage collection to clean up when no more Conns are left.

recvfunc_array

Conn: Subconns: Little vectors.
Add is controlled by recvfunc. identify the little vector by the recvfunc.
Conn should be able to get back to srcs if the little vector is empty.

Before starting this I'll back up the current moose as  minimus_01sep2005.tgz.
Done.

Slowly implementing the new MultiConn.

=============================================================================
3 Sep
Some constraints on messaging:
- Most messages should permit only one kind of recvfunc. Anything else should
	be relayed.
	- Likely exceptions: Channels, process messages.
- MsgDests need only keep track of the Conns. Recvfuncs are sent only to the 
	MsgSrc.
	- Corollary: all piggybacks should go in the same direction.
	Otherwise might get multiple kinds of recvfuncs to call from
	the MsgDest.
	- Exception: Value lookups, which are a single message each way.
		- In any case single msg relays don't care about the 
		funcs.

Implementing with a simplified version of MultiConn, later to be 
PlainMultiConn for use in msgdests. Works up to main.cpp:134, where it dumps.

Turned out to be an issue with the old usage of the RecvFuncs handling.
Patched over it and it ran to completion. Now to complete the implementation
of the full MultiFunc and go from there.

=============================================================================
4 Sep.
Putting together the MultiConn. Will need to stress-test it later.
Putting together the associated logic for MsgSrc. Some cleanup remains.

Nearly there, but stuck in a final linking stage with the obscure and unhelpful
error message:

basecode/basecode.o(.gnu.linkonce.t._ZN9MultiConnC1EP7Element+0x1a): In function `MultiConn::MultiConn[in-charge](Element*)':
/usr/include/c++/3.2.2/bits/stl_vector.h:891: undefined reference to `vtable for MultiConn'
basecode/basecode.o(.gnu.linkonce.t._ZN9MultiConnD1Ev+0xb): In function `MultiConn::~MultiConn [in-charge]()':
/usr/include/c++/3.2.2/bits/stl_vector.h:215: undefined reference to `vtable for MultiConn'
collect2: ld returned 1 exit status
make: *** [moose] Error 1

I have tried a number of things, including converting the connVecs_ vector
into a vector of pointers. In all cases it compiles completely and then gives
this error. Sigh.
OK, tracked it down. Just a member function that was declared but not
written out.
Of course, we now get an immediate core dump.
This is due to the MultiConn messing up on parent-child messaging. Fixed.
Now bug occurs at message traversal. Disconnect also fails.
Fixed traversal bug. Disconnect still failing.
Disconnect now working. Messages between ints still failing.

Need to check what happens to relays of array fields, especially when they
get recirculated in Fields.

Numerous fixes to use Element::field instead of going through the finfo.
Now it is improved to the point where it core dumps right at the start.

Found issue. I was creating a RelayFinfo for the original SetValue command,
and this was now being returned when I tried a GetValue command for the same
field. The RelayFinfo did not know how to respond to an 'add' request from
a GetFinfo, so it returned 0 and everything then croaked.

Two issues here:
	- What do RelayFinfos and other pre-attached Finfos do for subsequent
	requests, especially for values ?
		- Adding another ValueRelayFinfo will confuse subsequent
		  attempts to connect to the original field/RelayFinfo.
		  The ValueRelayFinfo will become the field representative.
		* Forward unknown requests down to a parent Finfo. At some
		  point one will meet a Finfo that knows what to do
		- Make a super duper RelayFinfo that knows how to do everything.
		  Issue is that it has to do distinct things when returning
		  values from when it is getting assignments.
		* ValueRelayFinfos can become invisible on the relay list,
		  by returning 0 for all match requests. Thus they are never
		  asked for anything else.
	Solved by doing the starred items above.
	- How do we clean up RelayFinfos when they have done their job ?
		RelayConns know their parent Finfos and can ask them to
		vanish.
		Solved.

Now the field message values do indeed go from one to the other, but the
message is not yet traversed properly. Another issue about the element
checking with the relays.
Implementation nearly there, the src part of the relay msg is found
but not the dest part.

Next: Lots of tests.
	- Fix the relay traversal.
	Some tests from Aug 26:
	* Creating the relay
	* Putting the relay on the element
	* altering field sort function so that it first looks for relays
	* Altering conn deleting stuff to do the same.
	Then, tests:
	* Setting int via msg
	* getting int via msg
	* Setting int and triggering another msg.
	- Connecting alternate dest to input of msgsrc
	- Connecting int to input of msgsrc
	- Connecting alternate dest to int.
	From  21 Aug:
	* stress test the multimsgsrc with different targets
	* Do piggybacks
	* Do relays, automatic formation of messages between unusual targets.
	- Do Solve relays?
	- Implement Synapses
	- Speed tests.

=============================================================================
5 Sep. 
Fixed the relay traversal.
Implemented setting int and triggering another msg. Seems to work.

=============================================================================
7 Sep.
A day lost on grants and reviews and other red tape. Now back to the tests.

	- Connecting alternate dest to input of msgsrc
To do this expanded TestMsg.h to include an addintional in and out msg,
in this case communicating with the j field. Confirmed that it worked the
same as the old version except for the pointer addresses.
Then expanded main.cpp to do the tests. The last two messages are our new ones.
All but the last entry are on element 0.
set 5-> int i -> fin -> fout2 -> fin1_2 (this is fin2 on element 1).

What it should do here is:
value 5 should go through to fin, assigning i to 10 (because of a double
assignment there) and sending the value 5 on to fout2. In the end j for
element 1 should get set to 5, and of element0 should not be touched.
Actual: j of element 0 is set to 5, of element 1 is still at 0.

Looking at the message reporting. For some reason fin thinks it is
connected to field j of itself.

Looks like there is a mix-up in the functions which look for the 
recvfuncs. The lookup names are wrong for other fields too.
But: The recvfunc for any relay will be the same. Problem is rather
general in that case.

Traversal aside, why are we still going to the wrong location?

Need to check the whole flow again more carefully

============================================================================
10 Sep
Testing message flow.

fin to fin2, same object:	OK
fin to fin, different object:	OK

fin to fin2, different object:	OK. Also works in presence of existing msg.

fin to fout2, same object:	Failed.
Here we only know about fout2 because of its action on some other msg.

============================================================================
10 Sep

Here we first make a message from fout2 to some regular msgdest so we
can monitor its effects.
fin to fout2, same object:	Failed. Even when I refreshed field.
No effect on anything.


Here we first make a message from fout2 to some regular msgdest so we
can monitor its effects.
fout to fout2, same object:	Failed even to add message.

============================================================================
12 Sep
Message adds from the SrcFinfos were all messed up. Working on it.
Conn.cpp:133: the deletion of the temporary ConnVecs is a problem. To fix.
============================================================================
13 Sep 2005
Figured it out. Slow of me. The vector ConnVecs resizes, and in doing so it
cleans out and rebuilds all of its entries, which are PlainMultiConns. So
their delete function gets called, leading to attempted disconnects,
and then all sorts of bad things happen.

Need to do some things:
* Put in clearance of empty connvec entries
* Perhaps eliminate ConnVec class altogether, just use PlainMultiConns.
* Use pointers rather than local storage for the connVec.
? Ensure that every time a ConnVec entry is deleted, the correspondign
	function is too.

OK, now we get a nice healthy core dump. More later.

============================================================================
14 Sep 2005.

Looks like it now works for fout to fout2. But tracking the messages still
fails.
Now I've improved it to the point where it no longer fails, it just gives
the default failure value of root.dummy.

Also it looks like the fin to fout2 is also working, again without properly
tracking the messages.

Will make a systematic scanner for all fields connected to all others,
check the connections, and run the messages.

============================================================================
15 Sep 2005

Full scale tester will do:
- Scan all fields, check type.
- Do set/get on all fields. Where the get works, check values.
- Connect all fields to all others, one at a time. Do set at input, look
	for effects
- For all A -> B above, also connect B -> C. Do set at A, look at effects on 
	C and targets.
- Repeat, except first do B -> C then A -> B.

For now: a major issue in traversal is how to handle it when the relay as
well as the original conn have messages. We already manage something for the
builtin msgs.
- One option is to assume that traversal will always use a full vector of
all possible targets. If this is done then we just need a uniform func for
filling up this vector. Issue arises when we really only need a single value,
for example a given synapse.
- Another option is not to query the inConn and outConn directly and instead
go through the Finfo for all operations.
- A third option is for the relay to pick up all the messages of the original.


Moving on to solvers.
	- The 'match' function now grabs all relevant new field requests.
	- Relevant existing messages are relayed to the solver.
	Really need to do the implementation to understand. Should be clean.

Moving on to synapses.
	- Do something simple like an E = Sigma ViWi
	where Vi is the value of the ith input and Wi is the ith weight.
	We want to be able to set and read the values of Wi just like an
	array.
	- The respondToAdd should generate a new synaptic Conn. This means
	we need a synapse specific field that spawns off new conns when
	connected to. Need to be careful about freeing the finfo when done -
	back to the issues with Field.
	- May need to implement a special new allocator for synapses as we
	make a lot of them.
	

Oops, turns out the SrcFinfos::add mostly don't use respondToAdd. Need to
fix, may be able to merge lots of the functions into a common base.
Also need to go through all 'adds' and do a destroy() on the finfos obtained
through respondToAdd.

Final thing at this stage is the speed test.

Other stages:
	minimus4?:
		- Sort out Elements as having ptrs to data parts. Do speed test.
		- Compile on Windows
		- Put on SourceForge
	rebuild:
		- Port over existing MOOSE
	parser:
		- Simple threading
		- Do parser
	threading:
	MPI:

Last thing at night status:
- Implemented pieces of synconn. Files affected:
	DestFinfo.h
	SrcFinfo.h
	Conn.h
	TestMsg.h
	TestMsg.cpp
Compiler tests to start.

============================================================================
16 Sep.
Compiles.
Runs, synapse receives stuff.
Accidentally set the synapses to integer values. This should be interpreted as
calling the synapse function with a specified integer. What actually
happened was that the addmsg set up a whole bunch of spurious synapses...
need to fix! 
Correct behaviour:
	- When a message is added to the base synapse, it should create a new
	synaptic connection.
	- When a message is added to an indexed, existing synapse, it should 
	treat it as a relay.
	- When a message is added to a nonexistent synapse it is an error,
	as usual.
	- When an existing synapse is disconnected, should we collapse it
	or leave it as a placeholder?
		- Collapsing it would change indexing.
		- Could scan for vacancies for future 'adds'.

Attempt to change synaptic weight failed.
Tracked it down to mistake in the array set function. This is pretty
horrible, will instead give a much simpler function for array sets that
takes the ArrayFinfo as an argument rather than do the whole thing from the 
Conn.
Now it works. Can set synaptic weights too.

Issue of handling of array fields and synapses.
- We have 2 cases: accesses to the base array, and indexed access to members.
- The index lookup function needs to return distinct codes for each option.
- Base array behaviour of the finfo should include things like adding new
	synaptic messages, or vector operations.
- Indexed access should include things like single array entry operations,
	or sending temporary input to a specified synapse.
- inConn and outConn accesses differ accordingly.

OK, concepts for above work with synapses. Still cleanup to do.

Next step: Fix up the message traversal, then on to speed tests.

Working on message traversal. Doing as a vector filled in by the finfo,
	which refers to a vector of conns filled in by the in and out conns.
	May wish to revisit FinfoConn as a way to show internal msgs.
	Tedious. May be able to eliminate 
	Finfo::targetFunc. I do not think it is used anywhere else.

Backed up current version of minimus3 as /home2/bhalla/moose/mus_sep16_2005.tgz
============================================================================
17 Sep. 
Looking at traversals. I could simplify the whole parseTrigger business
if I eliminate the FinfoConns and use the traversal vector instead.

Look later at cleaning up finfos a huge amount by putting the type
specification as a dual inheritance step much later, after the core
messaging functionality is done.

Traversal stuff nearly works, the internal ones refer to the root elm
rather than to the elm under examination. Otherwise OK.

Now seems fixed.

On to speed tests.

Structure like unit tests for the next phase: Each should report 
	test, memory, and speed. Compare speed with some reference.

============================================================================
18 Sep.
Doing unit tests. Rather difficult to get values on the timing front. 
Anyway, single_single has a ratio of about 2. Decent.
single_ripple has a ratio of about 3. Also it only handles about 100K
messaging depth. This is the max depth of the stack of calls. Point to
remember. Wonder what other architectures do.

Tomorrow I'll look at the key one, the multi_single, and then the synapse.

I should perhaps do a little profiling. I wonder why the speeds are slower
than anticipated from earlier runs in minimus. Perhaps it is because here
we are testing single msgs which are less efficient.

============================================================================
19 Sep.

The multi_single test does indeed go faster. Ratio is again about 2.
It is also a very good test for
creating and deleting huge numbers of messages. The delete process
takes far longer than the actual run, but it does appear to work cleanly.

The multi_synapse test is very fast. Also had problems with message deleting,
still to clean up.

Deleting of connections is a problem because the connection destination field
(synapse) refers to an array of conns, not to the individual conns. 
What we currently assume is that inConn() points to the individual conns.
What we need to do is to identify the correct synaptic conn from the 
incoming conn, then use this for removing conns.
Perhaps we should rethink this approach of querying inConn etc.
Anyway, hacked something in that should have worked. Didn't, and took an
awfully long time not to work.
Now it works. Still takes a very long time.

Perhaps should also have special routines for complete deletes of conns,
etc. In particular, if a set of objects have a lot of messages going to each
other and are all scheduled to be deleted, we only need to worry about 
cleaning up messages outside the set. 

At this point we nominally have completed this phase of development (minimus3).
The slow speed of deleting of large numbers of messages is a loose end.

Seen purely as an academic exercise, one way to handle it is to have two
different disconnection routines: one where all connections on the current 
object are to be dismantled, and one where they are being deleted pointwise.
The difficult part arises at the interface, where we have some objects
some of whose targets are to be deleted. 
Option 1: Go through all connections due to die. Check all targets for 
being on the delete list.
Option 2: Go through all connections due to die. Replace deletees with 
	zeros, and insert elms onto a set. Later go through set and 
	clean up zeros.

Option 1 should do it.

============================================================================
20 Sep
Loads of stuff pending, need to prioritize:
1 Cleanup especially msgsrc. Check up details of dual inheritance.
2 Windows
3 Parser
	yacc
	SWIG
4 Preprocessor (mpp)
5 Rebuild of existing moose on new foundation
6 RCS/CVS/SourceForge
7 MPI
8 Threading


A preprocessor would really help with rebuilding.
Windows compilation should be done now before the code gets bigger.
RCS/CVS/SourceForge should happen after the really fast changes are done.
	In other words probably not till after merger, possibly after parser.
Rebuild should not happen till I have a parser
Parser should happen after Windows compilation.

OK, priority assigned above. 
1 and 2 can proceed. 3 will need solid time. Now as good as any.

============================================================================
21 Sep
Msgsrc cleanup: Looks like we can do what we need using either virtual
base classes, or by deriving both base classes from Finfo. Bjarne
suggests that there are speed and space issues with doing virtual base classes,
so I won't. Space issues don't matter so much for us in the Finfos.

All this effort saves only 100 lines, but more importantly it puts common stuff
in one place to avoid code duplication and resulting errors.

============================================================================
22 Sep
Looking at list above. Cleanup and Windows compilation a bit held up,
so went on to parser. Doing this in minimus4.

Nearly compiled it in, and cleaned out most warning 
messages. Looks like last linking stage may need another library.

============================================================================
23 Sep
Gave up, could not find a suitable library. Instead wrote my own yywrap,
nothing but a dummy function returning 1.

Compiled. Created the parser. Did some basecode work in order to call the
Process action. This causes it to croak.

============================================================================
24 Sep.
Got parser to work. Let's see if we can implement le to be sure we know
how to get the thing to work.

Well, looks like I have something working but the listing of child
elements is not quite right.

============================================================================
25 Sep
Figured out why child element listing wasn't right - a really subtle bug,
turned out to be that the AdoptChild function was assigning Neutral::deleteFunc
to all classes, even though some were Elements and should have had
Element::deleteFunc.

This leads to 2 ideas:
- Have a virtual function in the Element that returns the deleteFunc. Use
	this in adoptChild.
- Use static functions to handle the static initializers for fieldArray
	and cinfo.
	This second idea is valuable in its own right for multiple reasons
	- Eliminate issues of initializer order. Inits will always happen when
		needed.
	- Allow more flexibilty in the inits. In particular, the fieldArray_
		can become a vector.
		This will still have its messy parts. Defer.

Implemented first idea. Works. Bag second for now.

Now working on mpp. Started out just defining an mpp file, but it has
grown to include a lot of cool ideas which will require additional 
Finfos to handle. Clearly I will not implement all these at once.

Slowly working on mpp.cpp. I have separated each of the parsable parts
into a different function.

============================================================================
27 Sep
Inching along on mpp. Working on implementing the field indexing stuff.
============================================================================
28 Sep
More inching along on mpp.
More or less done the fields
Just started on Src. Still need to sort out internal msgs and shared conns
	and creation of MsgSrc structures.

============================================================================
29 Sep
More inching.
Just begun on Dest.
============================================================================
30 Sep
Taking shape. Much more tedious than anticipated. However, it will make
it far easier to define classes. Now the main remaining thing is
to define Conns. This will also entail going back to some of the other
elements of the definition.

Issues:
- field naming. I am currently forcing all srcs to be <name>Out
	and all dests to be <name>In. Should I?
	How about synapses?
- Conns. I could simply have a separate Conn section, and for src and dest
	instead of single or multi, I could indicate the conn name. This
	would both specify if they were single or multi, and also tie up
	the Conns directly without the shared business.
- Synapses and Arrays: I need to revisit the templates and figure out how
	to put most of the function stuff in the template rather than in the
	wrapper code. The wrapper code has become quite bulky.

============================================================================
1 Oct.
Conn specification worked out. We either specify a connection directly, as
before, as single or multi. Or, if reusing a conn, we just give the earlier
name. The reused conn names need to be fully qualified with In/Out
suffixed to their names because of the possibility of there being two
Conns directly specified for in/out messages with the same name.
The revised version is in test2.mh
Working on the implementation in Src.cpp. Looks mostly OK, but in cases
where we are sharing conns, need somehow to lookup the conn type 
single/multi)

============================================================================
2 Oct 2005.
Incorporating conn stuff.
Mostly done now.
Also need to incorporate internal msg stuff. Will need to extract them from
the destVec, which has info on the internal msg calls, and fill in both
the destVec and srcVec entries before the printouts begin.
Done.

On now to some subset of stage 5, which will incidentally also thoroughly
test the mpp code.
As an amusing aside, the # of lines in the mpp cpps are almost as large as
in the basecode. The .h is only 10% as large as the basecode .h, though.

Perhaps this should proceed now in minimus5.

============================================================================
7 Oct 2005.
General cleanup. Trying to bring the basecode up to par with what the 
preprocessor expects. Still need to go through doing all the 2-arg messages.

Each field has a strSet, some have strGet.
strSet is a private func, uses recvfunc etc. It is NOT to be used for 
assignments directly, only through the assignFinfos that set up messages.
This is because the field may be on another node.
It is used whenever

Still struggling with the Finfo type matching. New thought:
have Finfos manage a separate class which is used for the RTTI.
That way the Finfos can deal with their main jobs first, and use this
separate class for the arg checking, and whenever needed specialize to
types without worrying about deriving from Finfo1, Finfo2 and so on.
Could use this little class to do string conversions, about the only thing
it is good for.

Field->set(string value)
This will look up the Finfo, take its Ftype class, use that to build the
AssignFinfo class. Then the AssignFinfo takes it from there.

This will require a major overhaul. We'll shift to 
minumus6 to implement the separate Ftype class.

This is going rather well. In the process of compiling

Now, so far we have been going through messages to assign to fields.
Is this necessary? If we ever assign to a field, that means we can get
hold of the field ptr. If on a remote node, the ptr will be something on
the postmaster. Either way, the assignment has to call a variety of funcs.
The only issue is if there is relaying on the field. In which case the
assignment should be on the RelayFinfo.

Will get to this tomorrow, once the compilation is done.

============================================================================
8 Oct 2005.
Compilation done.

Now looking at message-less field assigment. Usual issue of header
dependencies is holding it up, otherwise nearly done.

Slowly working through it. There is an issue with GetFinfo: If I implement
it then the mpp has to know about it.

This leads into a bigger issue: how to handle the use of messages that share
a connection.
	- Loading of the RecvFunc into srcs and dests that have not explicitly
	been part of the original call

Options:
	x Forbid it. Use separate conns.
		- Wasteful but safe.
	- Scan all relevant finfos and assign all funcs whenever such a conn is 
		made.
		- Tedious but doable.
		- What to do if not all pairs are linkable?
		- Principle of least surprise.
		- Don't have to use it.
		- Warn/skip if duplicated?
		- Would need another argument with the list of associated msgs.
		- Should have only one point of reference.
	- Permit only a specific, predefined set of Finfos to do this.
		- Tedious, unclean.
	x Require explicit creation of the return message.
		- Messy. Would need to coordinate distinct funclists

Utility:
	- Ensure logical coherence of certain kinds of connections.
		- But certain ugly hacks not possible
	- High usage: Most messaging is reciprocal
	- Good space savings.
	- Handle the getValue case cleanly as a special case.

OK, going with second option. Only one point of reference, it knows about
	all slaved messages.
	- The add function of the master sets up all messages
	- The remaining add functions don't
	- The respondToAdd function may additionally have to set up msgs
		going the other way.
	- The remaining respond functions do have to return finfos.	
	- The getValue situation is still messy, because conn vergence
		stuff has to happen on the relay.

Implementation options:
	- add does a loop around all outgoing conn verged msgs. Each 
		respondToAdd is unchanged.
	- add goes only to the primary target, passes in all relevant funcs.
		respondToAdd does something special for the primary target,
		returns all the funcs.

Can we, for now, get the code running without this explicit merging of message.
Compiled.
Minor check. OK.
Need to clean up AssignFinfo.h: most of it has been removed and we could
probably get rid of the whole file by merging into Ftype.h
Done. Minor check is OK.

============================================================================

9 Oct.
Exploring implementations for shared inputs and outputs. Something taking shape
in SrcFinfo.cpp. Basically a message is passed only between specified src
and dest, and each carries a list of associated finfos needing to have transfer
of rfuncs.

OK, I can see how this would happen. Some policy issues:
- Can any of these messages work alone?
- What is the policy if there is a mismatch of nOut and nOutTargets?
Consider use examples:
- Channels. OK to be rigid.
- Axial msgs. OK to be rigid.
- Plots and other triggered value extraction: Could imagine separating,
	but it would be an unusual case and should therfore be on the main obj.
- Process/Reset. Here we may have other things calling RESET in particular,
	independently of the process call by the scheduler.
- Value/coordinate plots. Optionally tag on to get coordinates as well as 
	values. Here coordinates would be queried rarely.

Upshot: Several clear-cut rigid cases. Many additional cases would work out if
we could define relays for exceptions. I think this would be a simple
case of having the appropriate respondToAdd. So:
- Rigid about exact match
- Spawn Relays for non-usable messages.
- Report OK but ignore when called for non-usable messages along correct path?

Issue crops up: How does a shared Finfo know when it is being called for a
Relay, when it is being miscalled by a legacy msg, and when as an error?
Legacy msgs will have to be intercepted.

Serious issue with the principle of least surprise here. We could silently get
a whole bunch of Relays set up unless there is a clear way to ensure that 
users don't connect up the wrong pairs. How to discourage? 
Deal with later.

OK, set up framework, now need to fill out and compile. Then I will need
to work a little bit more on mpp to handle the sharing info properly,
following which all will be ready to go.

See SrcFinfo.cpp, NSrcFinfo.h

============================================================================
10 Oct.
Just a little work done, en route to compiling.
============================================================================
11 Oct.
Struggling with the checking and form of the cases that handle 
sharedConn messages.

src needs to check that everything matches with the dest:
- If src is a plain conn msg, dest must be plain.
- If src is a shared conn msg, it should not be called at all.
- If src is the master of a shared conn msg, it needs to check
	that each of the sharedIn and sharedOut finfos match type with
	their dest counterparts. Ideally this should be through
	respondToAdd, but that function may pass back a relay.

============================================================================
12 Oct.
Step back on the shared connection issue. it is becoming messy, let's see
if we can come up with a clean basic concept here.

- Messages between two objects often come in groups.
- These groups are often logically monolithic.
	- So they should be built together.
- Distinct messages within a group have distinct call dependencies.
	- So they should remain distinct for traversal and call purposes.
- Sharing connection structures would also save space.
- Data flow is often bidirectional in these groups.
- There are possible exceptional cases
	- So we would need to fall back to relays sometimes.
- These message groups may be between distinct classes, e.g., different
	channel types interacting with a compartment.
	- So we cannot predefine any recvfuncs.

To build the group together, we need to
	- Ensure type safety
	- Set up the single connection
	- Set up the multiple recvfuncs.

respondToAdd is a unidirectional, single msg operation. Options to generalize:
	- expand it to handle multi-directional checks, by passing vectors
	- Have a distinct function for multimsg groups. This could replace
		the sharedConns flag: respondToSharedAdd.
	- call respondToAdd many times.
	- Bag it and do a direct loading of recvfuncs in the 'add' function.

OK, going along straightforward lines. See SrcFinfo.cpp where I have
begun implementation for the SingleSrc.

Need now to modify the add method of the shared finfos to put the recvfuncs
in without modifying the conns.
See SrcFinfo.cpp:117:
  sharedOut_[ i ]->add( e, df->sharedIn()[ i ] );

Finally compiled. At this point I see that there is an issue with the 
specification. In short, unless we keep the convention that the names
of the fields _must_ match, there is no way to know which Finfos are part
of a msg pair.

============================================================================
13 Oct.
Further issues: The dest member of a shared conn group is poorly defined.
Options:
	- All the dests and srcs in a group have the list with the group.
		- When doing the add we can go between any two in the group
	- Redo grouping with the previously suggested 'shared' construct.
		- Currently the definition is extremely obscure.
		- the src type definitions should stay as is, otherwise it
		is too confusing. But the definitions are checked on the
		'shared' line and warning issued if there is a mismatch.
		- Not nice that it is redundant.
		- Not nice to lose a hint that it is shared in the declaration.
		- Not nice that the work done to handle the sharing.

Issue now with the code itself:
How to align set going in and going out?
	- Case 1: conn to obj of same class.
		- Must have a symmetrical conn set on same class.
		- Any # of msgs possible.
		- Sequence of msgs in list must match: src to matching dest.
			- Scrap the sharedOut/sharedIn split, just have one list
			- This would prevent auto_msgs: perhaps a good idea.
		- 1st message is used for establishing connection?
	- Case 2: conn to obj of different class.
		- Must have symmtrical conn set on remote obj

Group naming
	- Should I define a separate Finfo class to handle these msgs?
		- It would simplify the SrcFinfo and DestFinfo code that
		handles message setup. 
		- It would be another layer of complexity in the concepts.
			- But by now the concepts have already expanded.
		- We could uniformly prevent individual messaging from
			any of the sharers.
	- Would need to avoid hitting the shared Group stuff when doing
		traversal.

Should I bag it for now? I want to get this beast out the door.
OK, let's put it in. Put it down to getting mpp to work properly.

Implemented SharedFinfo class. Straightforward. Lots of back-cleaning to
do now.

============================================================================
14 Oct.

Cleaning up stuff. Need to introduce flag for being shared into the 
src and dest finfos.

Working on the flag part. Perhaps it should be an enum:
exclusive conn
sharesConn, do not permit relays
sharesConn, but permit relays
Or, we can generically permit relays and assume (hope) that users know what
they are doing.

Another issue with sharing. The indexing of the conns depends on whether
the RecvFuncs match up. Unfortunately here we manage many RecvFuncs. Options:
- Send shared conns only to one class. Use a plainMultiConn
- Assume that the RecvFuncs will all change in sync. 
	- Dangerous: consider derived class targets where one is altered.
	- Will still need to locate index for connecting the Conn.
- Explicitly check all RecvFuncs. Find a way to force new index if any of
	them has changed. 
	- Will still need to locate index for connecting the Conn.
- Force increment of recvfuncs on every msg.
	For now, just complain if funcs differ.

OK, compiled. Lets aim for this to be the last iteration on cleanup.
============================================================================
15 Oct.
Having come so far, there remains the issue of handling field access. Despite
the generality of the conn sharing implementation, it does not deal with
relays.

To request a value, we need to send one message in with the request, and
pick up what comes back. This is best done along one conn, to preseve identity.
In general terms the request msg Finfo could differ from the target. In
the worst case, they could even be on different objects. A contradictory
set of requirements. 
Let's get one thing working well. Others can follow.
- Can dual inherit the ValueRelayFinfo from Shared Finfo. This could allow it
	to deal with incoming value requests. Then the src need not do anything
	special.
- Can figure out how to look up a specified value finfo for connection.
- Can reincarnate the GetFinfo. A complete cop-out. Would then need to
	figure out how to specify this in the .mh file. Not nice.

Working on it the dual inheritance approach. It is turning out to be 
exceptionally messy.

============================================================================
16 Oct
Possible approach: Instead of stretching the class definitions, do the 
following: 
1. Create a relay as usual, to send out values.
2. Create a special relay to trigger the first relay
3. Create a SharedFinfo to manage the above two relays.

Pretty awful, but now that it is broken down into separate pieces we can see
the other possible cases falling into place:
	- Object A requests a value from object B. 
		( the most common case, using all 3 relays as above. For
		simplicity, we may just want to bag the SharedFinfo part. )
	- Object A trigger object B to send a value to object C
		( Involves 1 and 2 )
	- Trigger a value send from the Proc of parent object itself 
		( Involves 1 and 2 )

At least two obvious implementations, one which refers to the original
ValueFinfo at each message addition to decide what to do, and the other which
looks up the RelayFinfos and does what they say. Although the latter may
seem elegant, I will use the first option. It puts all the decisions in
one place.

Done. Starting to compile it. Compiled. I have deferred the shared Finfo part.
Now on to mpp.

Begun implementing Shared.cpp. The Parse function is done. Key function will
be one to tell Srcs and Dests what Conn to use.

============================================================================
17 Oct
Implemented Shared.cpp. Seems OK. Need to do a bit of work on test6.mh
so it tests out other kinds of conns and msgs (not just tied to the shared
ones). Then we try to compile test6 itself.

Starting. Loads of compile errors.
============================================================================
19 Oct.
Mpp now compiles with Shared.cpp. Now phase 2: Getting the generated
class to compile within MOOSE. 

Slowly getting there. The preprocessor is forcing cleanups again.
	- The usual bugs in the generated code.
	- Simplifying the user API for handling sets to arrays. This has
	involved a change to the ArrayFinfo which now templates most of
	the nasty stuff, and leaves a rather simple little function for the
	user to fill in to get the field value.
Still have a bunch of error messages. Did a backup of the current
version into mus_oct19_2005.tgz

Finally: Compiled output of mpp. Unfortunately Moose dumps core as soon
as the system tries to initialize the new object. SharedFinfo is the problem.

============================================================================
20 Oct.
Mpp now compiles and the new object also compiles and loads.
Along the way I have implemented a crude unit test for the Dest portion of Mpp.
I still need to do something about the Internal MsgSrc and dests.
Oops, actually that was already working.

One major pending issue is cleanup: Message deletion. Later.

According to a long-ago schedule, the next step was to start implementing
the whole system. From 20 Sep:

Loads of stuff pending, need to prioritize:
1 Cleanup especially msgsrc. Check up details of dual inheritance.
2 Windows
3 Parser
	yacc
	SWIG
4 Preprocessor (mpp)
5 Rebuild of existing moose on new foundation
6 RCS/CVS/SourceForge
7 MPI
8 Threading


To rebuild we need to implement:
	+ Executor (to handle requests from the parser)
	- dumpfile parser
	+ Scheduler
	- compartment objects
	- Signaling objects


Planning executor and several of the other things.
Commands (W indicates wildcardable.:
	addmsg(W), dropmsg(W), getmsgs
	create, delete(W), move
	isa
	deep copy, Shallow copy, copy with ext messages
	getfield, setfield/call(W), showfields/listfields
Shell commands
	pwe le ce pushe pope
	listcommands listobjects alias
Utility commands
	start, stop, reset
	quit, include, (dump/save)
	showobject 
	printformat
Special commands
	createmap, gen3dmsg, dd3dmsg, createvol, cellsheet, position, 
	planardelay planarconnect planarweight volumedelay volumeconnec volumewt
	simdump simobjdump simundump

Many if not all of these things could be set up in the message context. 
The action end of things has to use direct func calls. So any threading
insulation has to be one level up. Not ideal for the SWIG interface.
Possibly quite good for the SLI parser.

Design issues.
	- If executor is on same thread as sched, there may be cases (eg, G1)
	where control never returns to executor.
	- But also need careful syncing of executor with sched operations.
	- ProcArg could include a mutex or similar thing for handling
		threading and requests to the solver to hold on.

For now: 
- Just implement the executor as a shell. 
- Tie shell to Parser using messages so that there could be 
	multiple shells/parsers.
- Likewise, tie shell to tty via messages. For now let the parser drive it.
- Provide functions to Parser as object methods (not globals).

============================================================================
21 Oct.
Day pretty shattered. Attempted to begin on shell coding, but too tired.
============================================================================
23 Oct.

Finally put the bits together. The parser talks to MOOSE. I have implemented
a Shell object which handles the commands and will also be used for talking to
SWIG. I am slowly building up an environment with the usual set of traversal
functions. Mostly work: le, create, pwe, echo.
Some debugging cases:
	le .. 		dumps core
	Does not handle loops.

============================================================================
24 Oct.
Did systematic comparisons with the old version in 
/home/bhalla/genesis/minimus4/moose_jun02_2004/tparser
I had eliminated a lot of redundant defines to get rid of warning messages.
Reinstated them. No effect.

The table in tp.yy.cpp differs from the one in 
~/genesis/mus/genesis_parser/GenesisParser.yy.cpp
by an increment of 2. Need to track it down. 
============================================================================
25 Oct 2005

A tangent to the ongoing development work on the new moose release:
Have to work on the old moose analysis of steady states. The method is
very promising but the criterion for distinct models is not so good. So I
am doing a distance-based criterion instead.
That works better, but there are other issues with the algorithm.
For example, it can put models into a state that cannot be reached by
the reaction system. For example, if A + B + C = K1, and 
A + 2B = K2, it would happily set each one to zero in turn 
without checking the second constraint.


Back to moose.
Files checked:
tp.yy.cpp
tp.yy.l
tp.tab.h
tp.ypp

OK, tracked it down to a little comment about getting more input
at GenesisParser.cpp:248. The comment gave me the clue. Bunged in a couple
of lines to get input, and it worked. Thanks, Matt or Dave.

Fixed the le .. case too.

Now implementing Show, Set and Get. Still to finish compiling.

============================================================================
26 Oct 2005.
Show, set, get work. Here is the current list of calls in the works:

Name		Wildcardable?	Status		Notes
setfield	Yes, NYI	OK, UT
getfield	no		OK		Should change naming for sli
showfield	yes, NYI	OK		Seems OK
addmsg		Yes		OK		Need to test
deletemsg	Yes		OK		Need to test
getmsg		No		broke
create		No		OK, UT		
delete		Yes		OK
move		no		OK
isa		no		part
copy		no		part, UT
shallowcopy	no		OK
halocopy	no		skel
call		yes		most
pwe		no		OK		Need general shell prompt
le		no		OK		ditto
ce		no		OK		ditto
pushe		no		OK
pope		no		OK
listcommands	no		OK
listobjects	no		OK		Done.
alias		no		OK		
start		no		deprecated	Eliminate this. Should use step
step		no		most
stop		no		skel
reset		no		OK
quit		no		OK		Eliminate 'Quitting' message,
						put in another CR instead.
include		no		OK, parser	This is a parser command.
showobject	no		skel
printformat	no		nonexistent.
setclock	no		-
useclock	no		-
showclocks	no		-


Others remain: Special commands
	createmap, gen3dmsg, dd3dmsg, createvol, cellsheet, position, 
	planardelay planarconnect planarweight volumedelay volumeconnec volumewt
	simdump simobjdump simundump



Some minor progress. One sticking point remains the handling of aliases.
If we can get the function lookup command to query the shell for aliases
that would do it.

============================================================================
27 Oct 2005.
Schizophrenic development track. Working now on CSPACE analysis code.
The time-course analysis of steady state (TCAS) needs an exponential fit
to estimate final steady state because many models do not settle in the 1000
sec of the simulation. If we do a fit we may be more accurate, yet be able
to wrap it up in 500 sec.

Did a crude test in /home/bhalla/genesis/moose using the stim file 
 test_slow_convergence.g
Seems OK, but much more to sort out still. Compare again against ssf
calculator.

============================================================================
30 Oct 2005
Results from slow-convergence test suggest that remaining issues may be to
do with conservation stuff, that also plagues the ssf approach.
Direct test of consveration matrix stuff. Wrote a little test program
and will use that along with the paper.
g++ test_consv_matrix.cpp consv_matrix.cpp -o tc

============================================================================
31 Oct 2005.
Slow unit testing of consv_matrix.cpp. Currently the tc command
gives an obvious error in the conversions, introducing big and incorrect
terms into the gamma.
Also I am not sure about the orientation of the gamma matrix.

============================================================================
1 Nov 2005
Progress in the consv_matrix.cpp code. I think it is nearly there now.

============================================================================
2 Nov 2005
Added a couple more test cases. They cleaned up another bug. Now to the 
interpretation, especially of the Test 3, which is from the Sauro and
Ingalls paper:
A + S1 <====> B + S2
C + S2 <====> D + S1

The output is:
 Printing [Smat]                      [Cmat]
      [ 1     0       ]       [ 1     0       0       0       0       0      ]
      [ 0     -1      ]       [ -1    0       0       0       1       0      ]
      [ 0     0       ]       [ 0     0       0       0       1       1      ]
      [ 0     0       ]       [ -1    0       1       0       1       0      ]
      [ 0     0       ]       [ 1     0       0       1       -1      0      ]
      [ 0     0       ]       [ 1     1       0       0       0       0      ]

I've checked, and this is how to intpret it:
The Nr matrix is just 
[ 1     0       ]
[ 0     -1      ]
But we need to take the top two rows of Cmat to figure out which terms it
represents. In this case, it is A' and A' - S' respectively.

The conservation matrix can be read right off the list of molecules, in this
case
S1 + S2 = const
-A + C + S1 = const
A + D - S1 = const
A + B = const
and I have verfied each of these.

Test 2 likewise looks OK.

Given this, I think we can proceed to rebuild the stoich matrix stuff.

The main problem here is that the convention for the stoichiometry matrix
is transposed. Should be N[mol][reac], is the other way.

Fixed. Now checking.
Next step is to go through the stoichiometry tests. Should google/medline for 
it.


............................................................................
Some mus stuff:
- Implemented move, but it still doesn't work for renaming.
- Did some minor cleanups based on the error messages from the Windows
	compilation. One headache is that Windows likes offsetoff,
	but GCC wants the C-style typecast of Element::* type offsets.
	Neither accepts the other option.
	Perhaps best approach is to write a macro or template.


============================================================================
4 Nov 2005.
Implemented stoichiometry testing in consv_matrix.cpp. Trying to call the
set_path msg in stoichmat so that I can see the outcome. This will be useful
for scanning through lots of earlier models and checking if the method
works.

============================================================================
5 Nov 2005.
Persuaded the stoich test to work within Moose. Promptly
found a problem case with the stoich evaluation: Got an elminated set
even though the system was stoichiometrically incorrect.
Quickly gave up on idea of requiring more consv law subsets equatios.
Doens't work.
Working out by hand, seems like there should come a point in the back-
elimination where there is an outright violation. No signs of it.

Implemented something with the following algorithm:
// 1. Transpose matrix so we are eliminating by reaction, not molecule.
// 2. Standard forward elimination as in conservation matrix.
// 3. Rotate matrix so that we can use the same routine to do
//    back-elimination
// 4. Do back elimination
// 5. Look for any singleton entries in a row. These are violations.
// Return 1 if no violations.

This seems to have worked in about 40 tests done so far. Unfortunately
it dumps core in some cases. I have now got a test case that dumps core,
in OK7.g
OK, fixed that. Still dumps on all117, but handles Arnold's model well,
though it takes a long time to check it out. Will need to work on the speed
issue. That should really have been very fast.
Now need to put it in CSPACE.

============================================================================
9 Nov 2005.
Trying to handle the somewhat onerous job of specifying UniConns by 
usng templates. Lots of bugs and issues already.
============================================================================
14 Nov 2005.
That was a bit of a dead end. Unable to do so, though I think with some
messing around it could be done. Reverted.
Tried to track down issue with creates down:
moose > create Int /bar
Error: create: Illegal object name /bar
moose > create Int /classes/bar
Error: create: Illegal object name /bar
moose > create Int classes/bar
Error: create: Illegal object name /bar

============================================================================
16 Nov.
Creation issues partially fixed. Looks OK, will need to set up unit
tests for creation.

Should put in a generic way for the shell to decide if it is to print out OK
after a call. Basically should occur only if a call succeeded and if it was
in interactive mode.

Need to figure out object name munging for moose vs sli. 
Working on pushe and pope, nearly there. Looks done now.

Beginning work on the copy routines.
Framework now in place. The message copying is still skeletal.

============================================================================
17 Nov
Better framework now for doing unit tests on the Shell. Many tests set up.
Need to have a function for checking lower case class names for SLI. Either
that or aliases for class names.

Copy is working to the extent that it does the trees and copies the values
of ints in the trees. Haven't yet dealt with messages in the trees.

Populated /classes. Dumps core when showing MyClass *.

Would like now to show messages using showfield and get/set. We already have
messages in the form of parent-child connections.
The strget was easy, but should also show msg in and out separately.

============================================================================
18 Nov.
Now showing both msg in and msg out. Should really do this by treating the
msglist as an array and having a better way to show each target.

For functions which return value I should have a temporary storage in the 
shell.

getfield implemented, doesn't work.
isa implemented, temperamental, sometimes works.

listcommands and alias: Both have the problem that we need to refer to a 
specific parser object.
Now I've set it up so that shell holds the name of the parser. Working
on passing it the alsiasing and listcommands code.

============================================================================
19 Nov
Implemented listcommands and alias.

Now to start on the scheduling.
Previously:
sched: Farms out jobs
job, clockjob: Manages a process such as I/O or simulation. On separate threads.
	Ordering is NOT guaranteed between jobs.
	clockjob: manages multiple clockticks to ensure correct ordering.
		Ordering IS guaranteed within a clockjob.
clocktick: Manages a given dt and is basis for ordering process calls.
simclock: Was there for partitioning clocktick calls among multiple threads.

Primary issue: Threading was unsafe. Messages went between things on different
	threads.
Secondary issues:
	- Thread partitioning of calculations worked but was inefficient.
	- Blocking calls to sim calculations from parser.

Proposal: 
	- Put everything in the sched on 1 thread. 
	- Drop the simclocks. Retain the rest.
	- Sequential calls to each job. 
	- Non-preemptive, but each job is expected to yield frequently.
		Note the problem this caused with the gsolver in Genesis.
	- Use MPI if we want to spread jobs around. 
	- Allow solvers to do their own threading.
	- Require solvers to yield control periodically.
	- Solvers return a next_change message to the clocktick to discuss
		whether to continue or to give the clocktick a chance to do
		stuff. If clocktick calls objects that may affect solver,
		either the clocktick or the objects themselves send a message
		to the solver to warn it.
	- Need a msg with extra info per target, similar to the synapse,
		but with info at source: sched has
		to associate a priority with each outgoing call to a job.
	- Implement a procInfo class that is passed to each compute 
		object during Process. Contains dt, currtime, shell, other info.
Issues: 
	- MPI is not standard. Pthreads or equivalent is.
	- May miss some kinds of automatic model partitioning options. But
		a good MPI decomposition should compensate.


Started implementation. 
sched implemented
job implemented.
first pass at having the shell call the sched to start the job.

Should soon have the system calling the clockjob
and then we'll fine-tune the call procedure.

Things to fix in mpp:
- Still puts in silly typedefs for checking
- Need unique names for conn Lookup functions. These are globals. Or need
	to sort out the whole global business using templates.
- The vector< something >& other in the field types confuses the system.
- Doesn't know what to do for inheritance.
- Messes up initial comments, e.g, for copyleft.
- Messes up when a function definition for a msgdest has an if statement.
- Comma at end of initializer line in object creation.

============================================================================
20 Nov.
Should really fix Genesis Parser to use shell only through messaging and other
proper calls.

The Field::setElement() command is a bad one, it lets us make impossible
fields.
============================================================================
21 Nov.
Looks like the Shared messages stuff is not properly implemented yet.

============================================================================
26 Nov
Lots of cleanup in the preprocessor and main code to handle shared messages
properly. Some scheduling stuff needed redoing too.

Remaining issue seems to be how to trigger the step. The shell argument needs
passing correctly.

OK, finally percolated through to the tocks. Need now to get their timing
sorted out. Look into uses of the STL queue.

============================================================================
27 Nov
Plan for doing signature/rate reader.
Rebuilt Cspace with minor change so the sigs are output. See
/home/bhalla/homework/CSPACE/nov27_2005_cspace
- signature: |Rxyz|
where R is the reaction identifier, and xyz are molecule identifiers.
Actually signature could be even tighter if we got rid of the separators.
Assume the rates follow in the sequence [x] [y] [z] r11 r12 r21 r22 r31 r32 ...
where [x] etc are initial concs of x, and rij is the jth rate of the ith
reaction. Each reaction has two rates.

Make it so the system can read in either reaction alone, or with as many
rates as are provided. Remainder stay at default.

============================================================================
28 Nov.
Not much to say for CSPACE. Got the reader to load in molecules and set
concs, now on to reactions.

Looked up Priority Queue STL container, page 478 Bjarne. Goes at O( log( n ) )
but given that most clocks are either the same or order-of-mag different,
it is probably best to do a custom queue like done earlier.

============================================================================
29 Nov 2005
Some progress on CSPACE reader. Now in debug mode with unit tester.
Unit tests passed. Now need to see if the actual model loads.
Then to do a function to load model automatically and generate SSF output.

Starting tests for kparser interface to reader, and a routine to do the
above loads and dumps in a single command. Doesn't yet do it.

Later, using sig option: seems to create model OK. Should test runtime
version of model, still to do the version where we can dump the entire ssf
and jacobian files as well as sig.

============================================================================
30 Nov 2005
Completed unit tests for all reaction motifs, also looked at kinconv kkit 
output using kkit (see /home/genesis/moose/SSF_test/cspace_signature_test.g)

Looks good. Now to implement the conversion to dump the signature file from a
model. For starters I am going to assume that the model has been read in
from a cspace signature, so the naming is OK. Later will have to implement
the true signature generation.

OK, done. Seems to work with the test case. Unhappy if enzymes are MM
enzymes, which had been a problem initially. Still need to test round trip.

OK, round tripped it. Works.
Command is

kinread sig <signature string>
and then the regular dump works.

Now to check the automatic generation of scrambled model in several formats.

kinread make_ssf <signature string>

Need to put in a randseed in the call.

Went back to round trip: there was a bug because k2 for enzs was not being
set correctly. Fixed and tested.

Put in the randseed. Got the kinread make_ssf command to work. For now it
is also dumping a .g file. Can easily change. Test: Is the .g the same as the
signature file.
Tested. Works. Sent to Naren.

============================================================================
1 dec 2005.
Begin clocktick handling. Plan is to have a structure in the clock job
with enough info to do the sequencing. This structure manages the messge.
============================================================================
2 Dec 2005.

ClockJobWrapper.cpp: the scheduling is taking shape. It is both efficient
and general, but requires some specialized messaging code. Basic idea is
that longer dt calls cascade to a linked list of ClockTickMsgSrc objects,
in a manner where the next dt is always returned to the outer loop. So the
major work in the outer loop is very fast, and occasionally percolates
to this linked list. Some implementation details:

- System looks for all ClockTick children to magically build messaging list.
- ClockJob::Resched asks all child ClockTicks for their dts. They send back
	a message with this info. Builds the internal list of ClockTickMsgSrc
	objects, which are a souped up MsgSrc-like class.
- Reinit just zeros out current time in ClockJob and its ClockTick children.
- ClockTicks only need to know dt. ClockJob knows current time and smallest dt.
- ClockJob::Start sets off efficient calls to child ClockTicks through routines
	in the ClockTickMsgSrcs.

Nearly compiled latest version.

============================================================================
3 Dec 2005.
Compiled, tested, mostly works. The system goes one extra tick at the end.

Next to build kinetic objects and a plotter, and begin simulations. It should
be interesting to do benchmarks again.

Just beginning to set up molecule.mh
============================================================================
4 Dec 2005.
Perhaps too easy to set up many messages. 
Idea: The plots should be done in a relay-based manner so they do not
	use any space unless used. Later.

Lots of work on mpp in the process of implementing the molecule:
* Bad printouts
* Fixed issue with if statements being treated as send calls.
* Additional tests in -test mode
* Fixed issue with ConnLookup function names being non-unique: Inserted 
	classname into the name.
* Checks if there are >2 of lines in a destmsg local function. If so, puts
	it in the .cpp. Otherwise inlines it.
* A '-force' option in the mpp command line which renames the output files
	rather than you have to move them by hand.
* Printing of dest FuncLocal in Wrapper.h is now before the static Func that
	calls it.
- For loops are treated as send calls.
- Other internal functions are treated as send calls.

Remaining
- Initialization for private fields of the header, especially static consts.
- Silly comma issue in constructor initializer list, crops up whenever the
	last of the conns is a single conn and hence commented out.

Goal is to make it so that any changes can be done directly in the .mh file

Implemented Molecule, Reaction, Enzyme. The first involved lots of setup stuff.
The second was very easy. The third was quite messy and took a fair while.
Now nearly done.

Lots of testing to do. 
put in a wildcarder so the the correct clock and scheduling can be setup.
Then we need to read models
Then we need to be able undump existing moels
Then we need a plot object. 

============================================================================
5 Dec 2005.
Of the list above, the plot object is the only critical one. I seem to have
mixed up the middle two. For starters, I could set the entire thing up in
a script provided I add in a text output to the molecule.

Working on plot object. More nastiness with mpp.
Fixed issue with other internal functions being treated like send calls.
Now I look up the list of valid send calls, so this kind of error should not
occur.

Looks better now. Plot compiles. Tried it out on imarti with GCC4. Compilation
barfs spectacularly.

Final thing for the day: Try to build a kkit .g file to handle a 
simple biochm

============================================================================
6 Dec 2005
Starting the kkit running stuff. Got side-tracked into working out the 
scheduling commands setclock, useclock and showclocks. The latter are
working but the useclock command relies on the implementation of wildcarding
so that the ClockTick path can be set.

============================================================================
8 Dec 2005.
Working on wildcarding. Implemented Ftype::valueComparison. Need to incorporate
Wildcard.cpp into compile path, and to complete Wildcard.cpp
Compiled. Shouldn't: there are plenty of Ftypes that do not supply the < 
operator.
Anyway, also ran through a series of unit tests, seems good.
On now, to the scheduling stuff.
Here got sidetracked into the issue of disconnecting messages. DATK syndrome,
need to step back. In the process of compiling. 


============================================================================
9 Dec 2005.
Compiled. Dumps core. Sidetracked into documenting it.

============================================================================
10 Dec.
many things wrong.
* Resets fail. Fixed. It was because the disconnectAll failed to clean
	up the vector after itself.
+ ClockTick dest field is hardcoded to 'tick'. Need to be able to set.
	For now recoded to 'process', which is a good default. Later will
	put in a way to specify field as well in function.
- Creating whole mess of test objects, in particular tocks, which need
to be deleted after use so that the simulation runs cleanly.
- Test for sched should be silent and should be internally checked, rather
than rely on user check.
- The checks for some shared finfos fail. Perhaps I should be very careful
	about ordering of components. I don't think there is a good automatic
	way to do this...

Now things are beginning to come together:
- trigPlot works but refuses to operate at the same dt as the main clock.
- The reaction is doing something but is producing garbage. The output
	is a decaying oscillation.

============================================================================
12 Dec.
Fixed the reaction. Now it gives a reasonable curve. Many things to do, but
first let's clean up the following:
+ ClockTick Dest: need to be able to specify target dest other than process.
* Test objects: Delete after use.
+ Test Tock output to be tested internally, not just printed out.
	+ To shell->echo. Depending on shell state it decides what to do.
		Compiled, not quite working yet. Seems responses are not
		getting from the ProcInfo into the Shell response field.
		Working on it.
	- To static Tock field publically accessible
	- To passed in value.
+ trig Plot to work at same dt as simulation
+ Trig plot to work off regular field, not to require special target msg.
+ Load optional command file and arguments on moose command line
+ Then, at last, build and test enzyme.

============================================================================
15 Dec.
* Showfield on the plot dies.

OK, tracked down trig Plot not working at same dt as simulation. Issue
	was actually with scheduler, doesn't like two ClockTicks with same
	dt as well as same stage.
	Still stuck
============================================================================
16 Dec.
Found the problem. I check for the requested tick being different from 
the existing one. But if it is the same I don't do anything about it.

I think it is fixed. Tested with the trig plot in test_reac.g.
More tests needed. Ideally get it into the unit tests.

On to the issue of getting trig plots to work with regular fields, ie,
the relays. There is a baroque bit of code already in place to look up
Element::findVacantValueRelay(..) which does something like the shared
finfo stuff, but not quite. The SharedFinfo solution is cleaner and should
be adopted instead. Issue is whether there will be a need for separate
triggers and responses coming into a field. This could happen if I wanted
to tell a field to send a value somewhere else.

OK, solution that melds into above. But it needs some more work to figure
out how to return a SharedFinfo in the RespondToAdd from the field.
Almost possible to do this, except that the SharedFinfo wants a 
getConn( Element* ) function for its initialisation. 

Looks like I may have to do an alternate case in SharedFinfo.cpp, where
the thing returned from the respondToAdd is not a SharedFinfo.
Done. Also modified the ValueRelayFinfo::relayFunc() lines 248-253 so that
this sends stuff back along the inConn rather than the usual outConn, provided
the recvFunc is defined and it looks reasonable.  Compile succeeds. 
Much testing to do.

============================================================================
17 Dec 2005.
Amazing. It just works. Tested on test_reac.g. Minor glitch with 
unnecessary error message fixed.

Woops. echo has stopped working. Should be in my basic tests.
Fixed. I had just set the shell to non-interactive.
Now loads commands but does not execute them till 'return' is pressed.
OK, fixed. Introduced new "parse" method into GenesisParser to get it to work.
Now loads files also, but does not execute them till 'return' is pressed.
	When it is pressed, it now spits out all sorts of junk. Need a 
	series of interactive modes depending on whether the thing is 
	responding to command line or to a function.

Prints spurious error messages about failed setfield commands. Fixed.

Doing some cleanup for compilation on imarti.

Look at last func in RelayFinfo.h. I think arg for appendRelay should be rf.
Also need to move e->appendRelay to a Field.
Then various things to do in ValueFinfo.h.

OK, done them, but by now I don't have access to the lab. Hopefully will be
able to move on to the next stage of compilation now.

In the meantime, let's see if enzymes work. Currently I can load the model
using test_enz.g, but the output seems to increase linearly.

============================================================================
18 Dec 2005.
Minor things: 
- Showfield for messages needs to show msg ins as well as msg outs. 
- child_in is reported as //dummy
- Showfield for values needs to show relays in case those are attached.
- le should report with a terminal / those elms which have children.

More fundamentally, there is no enz complex formed.
Getting there. The enz does implicit MM properly now but not explicit.
Now explicit also works. I had messed up the messaging to the complex.

Next step: Proper tests including benchmarks:
* Incorporate generic command into GenesisParserWrapper and Shell.
	* use argc, argv as msgs
	* Send a message to the shell rather than using a ptr.
	* Receive responses using messages returning char.
+ Implement simdump, simundump, simobjdump, enddump.
- Extend addmsg with message converters for old to new.
- Run, test, benchmark.


Doing rather tedious stuff to persuade the GenesisParserWrapper and the
Shell  to talk to each other through a message rather than the current
pointer. Getting there.

Also have the simundump function called in Shell.cpp. This is the start of
being able to test some big script files. 
Did lots of set up for this, but lots more to go to get it to work. Stuff
in progress (not compiled) in Shell.cpp.

============================================================================
19 Dec 2005
Incremental progress in the simdump stuff. Handles simobjdump and simundump
but there are still issues with specific conversions where the values do
not match, such as slave_enable modes. May need a special field for 
slave_enable in the Molecule for BC.

Had a go at compiliation on G++4. Much progress. The OFFSET headache
recurs. Used the WINDOWS flag and it was reduced to a warning. Need to
recompile locally too.

Getting there also with the addmsg backward compatibility hacks. The
key remaining things for reading kkit simdumps are:
- Time and other configuration settings
- Creation of /kinetics, /graphs etc.
- Set up of appropriate clocks
Also, as a utility,
- A save_plots command.

Ran with kholodenko.g. Loads of errors and a core dump.

============================================================================
20 Dec 2005.

Starting to read in the file. But dumps as soon as it is run.
- The MultiConn and NMsgSrc don't talk to each other well.

In an aside, I got the code to compile and run on imarti: 64 bits and GCC4.
But it is horribly full of warnings. Basically all the FIELD_OFFSET lines.

Tracked down the core dump. It is due to the problem with mixing shared
messages.

============================================================================
22 Dec 2005
Worked through the logic for the shared messages.
- If shared is a dest only, it can use a PlainMultiConn.
- If shared has at least one src, it must use a MultiConn.
- Shared to shared: At each end, determine if there is a recvfunc involved,
	that is, if the current end is at least one src. If so,
	need to create a new PlainMultiConn and tie it suitably to the
	MsgSrcs and dests.
- Shared from non-shared src: Here all the MsgSrcs corresponding to the
	shared entry must have DummyFuncs entered. Ideally they would not
	even be called. The DummyFunc could always be the last one.
	All such srcs could use the same DummyFunc and hence same
	PlainMultiConn.
- Shared to non-shared dest: Here as usual we have unique recvfuncs stored
	in the connected MsgSrc.
	- If there are multiple srcs, and only one is connected, the others
	need a DummyFunc at this slot.
	- If there are any dests, they must have some info to show that
	they are not being used otherwise the traversal will get confused.


Grinding through SharedFinfo.cpp:add() to build in the correct checks for
Shared finfos communicating each other. Currently looking at the situation
where the dest is a ValueRelayFinfo.

============================================================================
23 Dec 2005.
Did lots of code munging to get the addRecvFunc coordinated among various
Finfos. We now should be safely able to add functions. Still haven't dealt
with a regular message being sent from a shared msgsrc.

Getting closer. Most of the error messages cleaned out. But the 
kholdenko model still doesn't work.
Testing simpler cases
enz and reac work
2reac works: 2nd order in A
2_3reac works: 2nd order in A, 3rd order in B.
reacreac works: A <===> B <===> C
enzreac does not seem to work. No B is formed.
OK, it was just that I had not activated the clock for molecules.
Now comparing the kkit dump file for the enzreac model with the hand-written
moose version. kkit_enzreac.g does not work.
Also the genesis calculations differ slightly from the MOOSE ones.

Turns out the enzyme product message is missing in the simundump version.
Also there is a mysterious zero for k3 in the test_enzreac.g when it is loaded
into MOOSE using default values. Oddly, it does not seem to mess too much
with the results. Later.

Some more fixes with the simundump parser later, now the calculations seem
to match within MOOSE between reading a kkit dumpfile and a the 
test_enzreac.g file. But the plots don't come in the former.
Turns out to be a problem with calculating conc from n. Fixed. kkit_enzreac.g
works now.

The kholodenko.g model now doesn't give zeroes, but doesn't compute either.

Made test_MMenzreac.g. This too fails to show activity of the enz, though
test_MMenz.g does work.

k3 is mysteriously set to 0. I wonder if this is the problem. Why is it not
a problem in the nonMM sims.
Something about the processConn and its OFFSET calculations?

============================================================================
24 Dec 2005
I suspect the problem may be incorrect match between Conn and the func.

Confirmed the idea that we have a bad pointer somewhere. I swapped k3 and k2
in memory and now k2 is being set to zero.
Narrowed down further to an unfortunate interaction between regular and
shared messages that occurs in enzymes. The regular messages need to do
something different - basically fill other messages in the set with dummies -
in case the conn is shared.

OK, got tired of it. Put in a relay instead. Works. On now to the kkit dump
test and then to kholodenko.g
kkit dump test works both for MM and explicit enzreac models.
kholodenko.g does not work at all.

Two steps back. Did simple enzyme models, both explicit and implicit MM,
using kkit. Neither is read correctly by moose. The combination model with
enzreac, is read properly.
Turns out that the genesis_parser was using the REAC eA B message to set up
messaging, which is present only in explicit enzymes. Replaced by the
ENZYME n 
message and now the kkit_MMenz.g works. However, the kholodenko model still
has problems. At first I thought it was timestep problems, but the output
is messier than that.
OK, looks like it is a problem with how I calculate Km.

Yes. Now it works. Hoorah.
Did first set of benchmarks. It is marginally faster than the old moose.
However, if I can streamline the relays it may help.

When setting clock dt, must update info.

============================================================================
25 Dec 2005
Implemented clean way to deal with dt updates, sharing with various
incoming messages. Fairly grungy stuff ensues to reorder the internal
ClockTickMsgSrcs. Unfortunately it turns out that
the message from ClockJob to the ClockTicks is not at all clean, so the
implementation fails.

Major issues with scheduling. Possibly reset is not getting to cj


============================================================================
26 Dec 2005
The variable dt stuff has turned into one of those drawn out coding horrors.
I think it is working but the test simulation is not. I have checked using
the tock object, and it reveals some disorder in when exactly the ticks
get called out, likely due to rounding errors. See
kkit_test_clocks.g

as an alternative to the kkit.g fill-in file.

But nothing major to explain the problem with the outputs.
OK, systematically worked through it. It seems to be a problem with how
the changed dt reaches the numerical objects. Probably the timestep
jump confuses things unless the jump is perfectly synchronized and the
order of stepping is absolutely clear.

OK, solved the negative conc issue. Turned out that the order of stepping
was being changed when dts changed, and this meant that the reactions etc
were sending their initial values of A_ and B_ out rather than these
values scaled by the incoming molecular concentrations.

Finally, seem to have solved the reordering issue too. This was due to the
nextClockTime_ being left at the original values even though the dts had 
changed. Fixed this, now the plots seem to be OK. 2 solid days to handle
variable timesteps! Now to clean out the masses of printf debugging.

Done. Also set up a prdIn message on molecules and adapted the Genesis
Parser so that enzyme products go into this. Also sundry cleanups on 
molecules. Miniscule speedup, but haven't benchmarked properly. Still
to handle SUMTOTALS to get acc4 to be happy.

Handling, but the initialization is not yet clean.

Implemented an ugly hack to do sumtotals without a separate process phase.
Still some issues with getting acc4 to run correctly. But the general
shape of the curves is promising.

============================================================================
27 Dec 2005
Fixed the minor issue of the slave_enable incompatibility. acc4 is now
close. The remaining difference has to do with volume. A confusion over
the use of volumeScale. Fixed.

Some benchmarks
64-bit Linux OS
64-bit MOOSE (except for GENESIS run)
FX53
Method:		Kholodenko.g	acc4
rk5             2.3             26.1            110             102
rk4             29.5            5.4 (failed)    26.8(failed)    -
MOOSE EE        41.7            13.8 (inacc)    80.6            141
GENESIS EE      44.1            9.4 (inacc)     51              48

64-bit MOOSE2, using X2 4600+ and Fedora core 4
MOOSE EE	23.73		7.96
GENESIS EE			7.92

So a pretty good speedup with the new MOOSE, but I can't tell how much is
due to the better compiler and processor.

OK, all this is nice. Now for the next stages.
- Compile in simple compartment stuff
- Compile in simple HH channel stuff
- Compile on Windows.
- Release

============================================================================
28 Dec 2005
First pass at compartment and even more raw pass at hhchannel.

Need to amend all reinit messages to have a ProcInfo argument.

============================================================================
28 Dec 2005
hhchannel decisions, particularly on how to handle the interpols. Base rule
is that they should be shared, and that the originals should be referenced
by messages.
Access option:
- Make them invisible on the channel itself
- Make them readonly through the function access.
	If you want to mess with them, go to the original.
- Make them readwrite through function access. Refer all such calls through the
	messages to the original.

Calculation issues
- Do everything through messages to the interpols. Don't have local pointer or
	anything.
- Keep a local pointer; the messages just set up this pointer
- Should the messages handle the calculations or just do the lookup?
- As the calculations involve state variables, best to just do lookup. How
to organize messages:
	- v to lookup, a single value back
	- v to lookup, A, B back.
	- v to lookup, 6 values back.
	- v, state variable X to lookup, state variable back.
	- v, state variable X to lookup, X, calculated g scaling back.
	- Instead of a simple interpol, provide the same kind of channel
		table structure that the solver will use. A single lookup
		for all X,Y values.

Decision:
	- Interpols referred to by channel, RW.
	- All calculations through messages to a hhGate object having 
		2 interpols.
	- Pass in v and X, return X from hhGate.

============================================================================
30 Dec
Trying Windows compile. Main things so far:
- function references do not use pointer in Windows. Need to check if it
	will compile like that with Linux.
- Serious headaches with includes. Needed to put in a reference to class Shell
	in GenesisWrapper.h, even though Shell is included in the .cpp above
	GenesisWrapper.h.

Also slowly inching towards an HH simulation. Setting up the HHGate now.

============================================================================
31 Dec.
Now working on Interpol. Steps:
* Fix Finfos to handle 3 field args in msgsrc/msgdest.
+ Fix mpp to ditto.
+ Create MOOSE class of Interpol.
- Get basic data structure to work
- Write Finfo to use Interpol as a field (Eventually automate: Finfo to use
	any MOOSE class as a field)
- Get squid sim going.
- Get fields in HH channels to point through to interpols, accessing as if
	local.


============================================================================
1 Jan.
Slow progress on the compilation. Too many interdependencies. Defined lots of
things but till we can use Interpols as fields we won't be able to easily set
up models. I have a framework for doing encapsulated classes, which would
handle all these issues, but that will take careful work and time. Need
a better, brief name than EncapsulatedFinfo: GroupFinfo, LumpFinfo, ObjFinfo.

Now compiled, but the access to the interpols is still dangling.
Minor detour: Array sets were not working. Fixed.

Now back to doing ObjFinfo. Perhaps put this off till I get the squid
sim going.

============================================================================
2 Jan.
Tracing back to find issues with using ProcInfo in the reset. It boils down to
ugly hacks in the scheduling and how it ties to the shell. Should really
do so through messages. For now use a dummy ProcInfo for resets.
Also have an issue with dt for the compartment. Should not have to store this
silly field, but the randinject needs it to get from probability to 
actual prob per timestep.
Hacked the ProcInfo thing out for now. There is a persisting headache with
the scheduler giving warning messages, but it doesn't seem to affect function.
Now to get the system to handle array operations. This means the ObjFinfo has
to work.

Looking at modifying ValueFinfo a little bit to insert the lookup function.
Only problem is the Set command. The Get command uses an Element as an 
argument, so it is not a problem.

Idea: 
- Use the regular makeRelayFinfo function,
-generate a Finfo for the ObjFinfo to pass back with the 'match' function. 
	- This will make a ValueRelayFinfo if the class was a value. 
	- Otherwise 'match' should fail.
- Now modify the ValueRelayFinfo to handle the lookup and the index.

Made a setObjLookup virtual function off the RelayFinfos to allow us to
assign these values.
Now need to revisit set/get commands in ObjFinfo.

============================================================================
3 Jan 2006.

Now the idea is to munge ValueFinfo<T> so that it knows about lookup. 
In progress. Will in parallel have to deal with RelayFinfo and ValueRelayFinfo,
so that these fields can be accesses through msgs.

Implemented. Also set up the dreaded ObjFinfo as derived from ValueFinfo< T >.

Finally, compiling the whole mess.
Compiled. Now to incorporate some of the ObjFinfos into HHGate, which started
this whole mess. Huge backlog of other things, so this will have to be the
last of the architectural changes for some while.

OK, now it all compiles. And dumps core as soon as I try to access any of
the object fields. Core dump fixed, but doesn't work. Now it complains 
politely.

============================================================================
4 Jan 2006
Getting close. Though the system seems to be hitting the wrong location in 
memory, it is reproducibly setting and getting ObjFinfo field values. Still
doesn't see the array values.
Now the system is getting the correct ObjFinfo field values.

One or two rounds later: handling arrays within ObjFinfo as well. On now
to squid.g

Need to set base parameters and injection
Done. Charging curve OK after some messiness with units.
Now struggling, as usual with the HH parameters.
I think HH parms are nearly OK, but there may be some messaging issues 
remaining. The HHGate state is not being altered.

============================================================================
6 Jan 2006
With HHGates, we need a new kind of message/conn arrangement. Here each
incoming is matched with an immediate outgoing call. We do not want to
accumulate in and out values. So our 'send' call should not go to everyone,
just to the specific conn that triggered it.

Also need to do something sensible with isInteractive on the shell.

Fixed one major item, the fact that the B gate actually should have 
alpha + beta. Didn't work.
 
Checked the waveform for the n gate alpha and beta in the program vs 
those in the BoG. They match. Let's move on.

- When I eliminate the gates, just provide channel current with a fixed
conductance, the resulting potential is OK.


============================================================================
7 Jan 2006
Testing the interpol and lookup. Turned out to be lots of problems, many
related to a vestigial assignment of xdivs which omitted to assign invDx.
Also I had forgotten to set xmin and xmax. Anyway, with that all fixed, it
seems to work.
From 27 Dec I had wanted to:

* Compile in simple compartment stuff
* Compile in simple HH channel stuff
- Compile on Windows.
- Release

Some more items on wish list:
- Get it to run squid script without alteration
- Fix garbage with Shell::isInteractive
- Figure out how to send many immediate return values to the HHGate.
	Possibly a different kind of Conn like an array of single Conns.
	That way the one return target can be found quickly.
- Benchmark it.
- Get copy to deal with messages. Need elaborations such as filling in
	messages of certain kinds, e.g., for common HHGates.

============================================================================
8 Jan 2006
Did an initial set of things for making a special kind of conn for the 
returnToSender kind of situation. This basically handled an array of 
UniConn2, ie, a nice simple Conn. But more thought showed problems, primarily
that the recvfunc is not safely associated with the return conn in this
scheme. Options:

- Something like synapses. Here the special finfo is constructed for each
request. The finfo causes the formation of a new synapse data structure
if there is an add. This is nice but does not deal with our situation which
is the safe return of information to the sender.

- A regular MultiConn and associated NMsgSrc. This is already handled by the
existing code. Issue is how to specify which one to use for the return.

- A specialized Conn which inside is a bunch of single conns. This looks like
the synapse option and has the same problem: How to ensure that the return
function is correct.

- An array of MsgSrcs. Each time a msg is made, one of these is made.
	Expensive: Stores recvfunc each time + outgoing conn. But fast and 
	safe.
	SharedFinfo::add will first call connect for the dest conn. This
	operation should create the new conn on the dest. Then immediately
	a set of calls are made to all the addRecvFuncs. We should couple
	these as tightly as possible to the conn. Clearly the conn cannot
	hold the MsgSrcs, nor vice versa, as there is one conn and possibly 
	multiple srcs. Or we could specify that there is precisely one
	MsgSrc for this case?

Boundary conditions: 
- Need to manage recvfuncs safely and quickly. NMsgSrc like class.
- Need to quickly locate source for return operation. Either use caller
Conn and its target, or have the local conn hold extra information such
as the msgsrc, or have the local conn itself provide a return func.

============================================================================
9 Jan 2006
Conclusion:
	+ Make a special conn class, ReturnConn, which holds 
		parent, target, and RecvFunc.
	+ Make a vector of ptrs to these conns.
	- Make a new Finfo class for any shared Srcs using this conn.
		This is similar to the Synapse1Finfo.
		This class must provide an addRecvFunc which looks up the
		latest of the ReturnConns, and pushes the RecvFunc onto it.
		- Keep the interface clean in case we need to push multiple
		RecvFuncs.
	+ Make a new SharedFinfo class for the ReturnConn as a whole.
	- The incoming RecvFunc must do a suitable typecast of the target Conn,
		which is a ReturnConn.
	
Working on it.

============================================================================
10 Jan 2006.
During the implementation looks like I may need to do the whole family of 
Finfos: The SharedFinfo equivalent, the NSrcFinfo equivalent and the
DestFinfo equivalent. This is not a nice prospect. Let's see if I can avoid.

- SrcFinfo: Can use old NSrcFinfo if I have a specialized MsgSrc: ReturnMsgSrc.
	addRecvFunc: Goes to MsgSrc.
	relayFunc: This does a typecast of the MsgSrc. Would give an error
		for ReturnMsgSrc because this typecast is invalid.
- DestFinfo: 
	recvFunc: We can put our specialized recvFunc here.


One option is to make a special wrapper conn for the array of conns.
This is something I have already implemented. It helps for any Conn lookup
functions.

ReturnMsgSrc can be non-templated provide we insist that it does not support
the 'send' command. It will have to be derived from NMsgSrc to fit in with
the existing SrcFinfos. This will cause RelayFuncs to fail.

This is getting too messy. Look into a set of Finfos to deal with it.
- The SharedReturnFinfo which manages a set of subsidiary ones. Perhaps can
	get rid of it if the ReturnFinfos are clean enough.
- ReturnFinfo0, 1, 2, 3: A set of ReturnFinfos that handle both src and
	dest messages.

The ReturnFinfos can be readily done. They will work best with a 
MultiReturnConn. This needs some way to handle Conn::begin() and end().
- best if I can set up a custom iterator so that the Conn::begin() and
	Conn::end() calls are done painlessly. 
- (horrible) option is to have a parallel PlainMultiConn set up to
	hold the targets in a format that these calls like.
- Third, also horrible option, is to examine the calls that use the begin and
	end and see how to replace them with something more general but
	hopefully as fast. This is problematic as the foreach command
	is supposed to be optimal.
- Fourth, somewhat painful option, is to examine all the calls that use
	begin and end, again, but make sure that other than send nothing
	critical is lost. Send is dispensable for these messages.
	I've looked as a first pass, and actually things seem OK. Only the
	send command seems to use begin and end.

============================================================================
11 Jan 2006

Finally compiling the changes. Adopted option 4.
Also chipping away at documentation.

Ran squid2.g as a test of this. First pass: Just get identical results to
squid.g. Much to my surprise, it worked right off. Cowabunga.
Now to use the same HHGate for another segment of axon, again in squid2.g
Done. Seems to work. Amazing.

In the meantime, Rajnish seems to have gotten the code to compile on his
setup. It looks like our local machine has a config problem, not unusual
in Windoze.

============================================================================
14 Jan 2006
Didn't even note yesterday's big event: Release 0.01 of MOOSE. Most of the
recent work had been on documentation, not worth writing up in the NOTES.
Next steps:

- Get MOOSE to deal completely with kinetics stuff
- Backward compatibility stuff: primarily object name munging and addmsg stuff.
	Perhaps also interpol assignment stuff.
- Windows compilation

Bigger picture:
- Get current kinetics capabilities into this version of MOOSE, including
	conversions, so I can shift stuff over.
- Get complete biophysics stuff done so I can do bulb modelling stuff
- Get some level of parallelization going so I can do bulb modelling in 
	parallel.
- Implement solver architecture so people can begin to play with it.
- Bring in the GSL so I can do heavy crunching.



Started on first of these items. The main missing class right now is the
table. This is a true horror for backward compatibility, but the initial
setup and compilation are done. 
- Next need to handle the FillTable commands
which should really be referred to the internal Interpol structure. 
- Then the stuff for loading in tables from dumpfiles.
At that point I should be able to compare outputs from the nonscaf model.
- Then implement channels
- Then implement delays
At that point I should be able to compare nearly any model.
- Then onto the BC stuff.

Slowly and painfully doing the unit tests on the table. Tested up to and
including PROCESS: TAB_LOOP and TAB_ONCE.

============================================================================
15 Jan 2006.
Did PROCESS::TAB_BUF. Currently stuck at TAB_DELAY.
Fixed TAB_DELAY. That is it for the table per se. Next is to handle
the table loading and dumping, which is really an Interpol operation.

Implemented but not tested the loadtab. Dump comes much much later.
Need to take a really simple little file for testing loadtab.

============================================================================
16 Jan 2006.
See genesis/mus/KKIT_TEST/table_test.g
After much messing especially with the loadtabFunc in Shell.cpp, it now works.
Tomorrow we'll test the nonscaf model. After this the simple kkit
channel should be a piece of cake.

============================================================================
18 Jan 2006.
The nonscaf model tests are promising, but there are some nasty initial
transients esp. in IP3 that need to be sorted out. Otherwise the match
is good. Took a very long time to run though.

============================================================================
19 Jan 2006.
Minor cleanups to compile on gcc4. Attempted to get a UBUNTU compilation but
the live install did not have a compiler.

============================================================================
20 Jan 2006.
Implemented the concchan object. As expected, it was a piece of cake at least
to get the bits together.
Tested using Jyoti's oscillatory model. Took forever to run.
Doesn't work. Implemented test_chan.g which tests channel as well as 
table function. Slowly coming together.
Now signs of life, but more to do to get it to work.
Issues:
	simdump messaging confused
	Inside and outside need better naming. Influx and efflux are confusing.

In any case, put together 0.02 release with the little bits of work that
had been done over the week.

============================================================================

21 Jan 2006
Something from the old MOOSE:

Subject:	small fix to MOOSE sought
From:   	"Naren Ramakrishnan" <naren@cs.vt.edu>
Date:   	Fri, January 20, 2006 10:47 pm
To:   	"Upinder S. Bhalla" <bhalla@ncbs.res.in>
Priority:   	Normal
Options:   	View Full Header |  View Printable Version

Hi Upi,

thanks for responding to the UMd request. I have gotten only some informal
responses so far indicating interest, but nothing yet formal like an
interview, etc. Will let you know of any developments.

I have gone thru my runs and there are some strange bugs, Moose seems to
have not generated some of the SSF files for some signature inputs (recall
I am using the precompiled executable you had given). As a result, with
the parallel setup and some shortcuts I had done in file naming
conventions, some of the runs have become duplicated/wrongly associated.
Basically for some inputs, it gives a segmentation fault after generating
an empty model.cpsace file.

So i went back to recompiling Moose on my cluster and after some tweaking
of flags etc. this seems to work. But is it possible to change the
make_ssf function to take another argument indicating a name? So,

"kinread make_ssf <stem> <signature>"

will produce the stem.ssf, stem.jacobian, stem.cspace etc. files, as
opposed to the generic "model" prefix?

I see where to change it but didn't want to mess it up lest you had some
clean way to do this.

I will work on bundling the analysis part for you,

Naren.
============================================================================
22 Jan 2006
Old MOOSE fix continued:
After some muddling around, fixed it. Also added ability to read from files.
Command is:

kinread sig <signature>
kinread make_ssf <signature>
kinread make_ssf <stem> <signature>

kinread sig_file <signature_file>
kinread make_ssf_file <signature_file>

and the signature_file can contain the signature, or in the case of 
make_ssf_file, the stem plus the signature.

                              *--*

Moving back to new MOOSE.
Fixed the ConcChan object. Also fixed a strangeness with the SLAVE message
and slave_enable in Molecules.
Tested using test_chan.g. Later we'll try the massive IP3 model from Jyoti.

Implemented the CaConc object. Yet to test.
Implemented the Nernst object. Yet to test.

============================================================================
23 Jan
Did a little script in /home/bhalla/genesis/mus/test/csquid.g to test CaConc.
Does not work. 

============================================================================
24 Jan
Got CaConc to work. 
Testing Nernst. No plot appears. Possible issue with the return value 
E being plotted as it is a ReadOnly.
Confirmed that issue was ReadOnly: simply changed it to a regular ValueFinfo
and the Nernst thing works. Need to sort out the basecode here.
Fixed it. Now works. Onward.

============================================================================

25 Jan
Multiple compiler fixes.
* For the offsetof: put in a flag in the compiler
* For the Ftype::ret: tried just return T()
* For eval.cpp:843 and 890: Initialize r.
* In ClockTickWrapper.cpp:97 : replace int with size_t so that 64-bit
	issues are avoided.

After this it compiles cleanly on gcc4 as well as gcc3. However the
Debian distribution has a flex that does not like it.

============================================================================
26 Jan
Could provide extended fields using something like RelayFinfos. Would
hardly need any extra machinery.

Working currently with existing field stuff. See
/home/bhalla/genesis/mus/genesis_parser/ReadCell.cpp,
though perhaps it should move to basecode.

Wrote up most of it but haven't yet compiled. Tomorrow.

============================================================================
27 Jan.
Old MOOSE: Recompiled for Naren, under GCC4. Went quite quickly after the
learning experience with New Moose. Saved in 
/home/bhalla/genesis/moose_gcc4_jan27_2006.tgz
This version has had the GSL and SBML stuff removed.

New MOOSE:
Released as 
/home/bhalla/genesis/mus_release_jan27_2006.tgz

Working on ReadCell. Added into shell. Now doing setupAlpha,
which turns out to be very commonly used. With some luck I may be able to
do the Traub model from the original scripts.
In the process of compiling.

============================================================================
28 Jan 2006
Many things to do to be able to read traubproto.g
+ setupAlpha
* Usage of the recent element symbol ^ for sets etc.
* Setting multiple fields.
- Usage of . in setting fields.
	This problem turns out to be something involving wildcards.
- BC for odd fields.

Now slowly trying to do traub91proto.g
============================================================================
29 Jan 2006

More things to do:
+ Allow -> as separator for object fields
+ Handle X_A syntax for tabchannels
+ Implement TABCREATE as a call that creates a gate
- Set gate powers via the parent HHChannel
+ set calc_mode
+ Implement TABFILL to fill up tables.
- Figure out what to do about INSTANTZ
+ Implement addfield as creating a special finfo with the value. Give option for
	type, otherwise it is a string?

We need another kind of message src especially for use in shared conns.
This one looks up the destination on the fly and needs zero storage.
In the channel context we need two of them: One for passing powers of
gates to the HHGate objects. The other for passing TABFILL requests.
There are similarities here with what the solver messages do.
I have put together a skeleton in SolveFinfo.h, to be elaborated.

============================================================================
30 Jan 2006

Got addfield to work. Now should move on to the actual cellreader.
Slowly munging through it. Lots of errors.
Currently I am unable either to create a chan with a proto, or to copy it.
Dumps core in Element::shallowCopy which does not seem to do the right thing
anyway.

Finally put it together to the point where the thing assembles something
like a cell.

To do:
+ Axial/Raxial messages between compts
+ Set HHGate2 to be default HHGate.
+ Fix up connections to HHGates
	Various fixes in ReadCell and TabCreate etc.
- Figure out the INSTANTZ thing
+ Connect up gate powers appropriately.
- Follow up addmsg1 etc when making the cell
+ Nernsts seem not to happen.

Getting close. Now the gate messages are all set up correctly to the gate
in /library. But the whole thing dumps core as soon as it is run.

============================================================================
31 Jan 2006.

To do
- Figure out INSTANTZ
- Assign globals
- Use globals for scaling compartments
+ Fix axial messages.

Traub91.g now runs without dumping core, but generates a flat line.

Got a cable model to run after readcell, and it gives the right values.

Now struggling on getting the channel-rich models to run. Should try with
a single compartment model of the squid simulation so I can set up the 
channels by hand.

Trying to fix up the squid model using readcell. Still far from working.

============================================================================
1 Feb 2006
Finally got the squid model to work and give action potls using readcell.
Matches the other squid version well.

Onward. Implemented the val2str for Interpols. Now figuring out why the
setupalpha fills tables incorrectly.
Fixed.
Now stuck on tabfills. Calls from the script are not going through to call
the Interpol operation. As if they do not recognize the field tabFillIn.
Much gdb grunging later: turns out that the access to the field 
through Field( e, fname) fails, returns a dummy.
I wonder if its lack of a Conn matters.

============================================================================
2 Feb.
Tracked it down to 
makeValueFinfoWithLookup. This is currently supported only by ValueFinfos.
The set command here is using a DestFinfo. The issue is a generic one:
ObjFinfos will not work with anything but value fields, in the current 
framework.
Also in ValueFinfo.h: 90: I don't understand why InnerSet works at all.
lookup_ should be null in most cases.
OK, it is called only when a ValueFinfo is set to handle lookups.
Seems to me we need a complete overhaul of all Finfos. aagh, not again.

OK, put in a quick fix for this special case. General overhaul remains to do.

Put in stuff so that Ca conc now behaves. Still to handle readcell addmsgs.
That should then do it provided the channels work.

Did various testing operations using messages set up by hand. The
'instant' flag is now needed.
Done instant. But the graphs still do not match.
Check: Do the plots look the same if there are no K_C:
The plots are similar but not identical. 
Checks		Result
full CA3.p	differs lots
no_K_C_CA3.p	Significant difference.
			Turns out that K_AHP also uses Ca.
			Now getting closer.
no_chan_CA3.p	Matches, subtle difference.
only_Na_K_CA3.p	Subtle difference.
no_Ca_dep_CA3.p	Voltage plot is close, Ca is way out.
			Tracked it down to Ca channel, tracked that down
			to small and subtle difference in Y table: tabfill.
			Tracked it down: The default fill in GENESIS is a
			B-spline. In moose I use linear. Ugh.
			Confirmed: force the traub model to use linear fills.
			Curves match much closer.
no_KAHP_CA3.p	Huge difference.

Aaargh, it was a scripting error. When fixed, things match up.
OK, now on to the addmsg.

Working on it. Issues with ordering. I may need to do the messaging after
all the channels are in place. Error reporting should be more stringent.

Looks like it now works. Phew. Now let's take some fresh files to confirm.

Reasonable but not great match. Three issues:
- Symmetric vs asymmetric compartments
- hsolve vs EE
- back to the original splines for tabfill
============================================================================
4 Feb 2006
Some profiling on Intel Pentium M:
: Biophysics
- MOOSE is slightly faster than GENESIS for the traub model. About
	9.5 sec as compared to 11.5 sec.
- Time taken is pretty evenly distributed. Most time is in Interpol::doLookup.
	Again, a bit odd, as it just farms jobs out to other functions.
: Biochemistry: Ran kholodenko.g for 60K sec.
- MOOSE is much slower, odd: 22 sec vs 7.36 sec. This contradicts earlier times.
	Perhaps the use of doubles messes things up? Used a lot in GENESIS.
	Old moose was 5.3 sec. Something seriously wrong here.
- Time taken is odd. Lots of time in apparently simple and small routines,
	like A_ += A; B_ += B;
	I think we need to run a newer profiler.

Did a variety of obvious things, the discrepancy with the new MOOSE and
kholodenko.g remains.  Also with acc4.g. Baffling.
Basically the timing is almost identical to that without optimization.

Now working on bulbchan.g for making the mitral cell model.
+ setup_tabchan needs to be aliased to setupalpha
+ setuptau needs to be implemented
+ setup_tabchan_tau needs to be aliased to setuptau
+ tau_tweak_tabchan is tweaktau needs to be implemented
- settab2const needs to be implemented
+ tweak_tabchan needs to be implemented
- vdep_channel needs to be implemented. In this case I can replace it
	with a tabchannel.
- setupgate to be implemented
- Replace Kca_mit_usb with HHChannel and HHGate and Table.

Later:
- Synaptic channel
- ddsyn 
- receptor2
- spike
- axon


============================================================================
5 Feb 2006
Within Genesis itself, in the process of replacing the vdep_gate
for Kca_mit_usb with a regular tabchannel. This nearly works but there is
a tiny discrepancy still remaining that I would like to track down.
Ran the model with hsolve (only worked with the new tabchannel version)
and with 1 usec timestep. The hsolve version and the old version are close,
the new version diverges quite a bit even at the 1 usec dt. Huge difference
with 1 usec and 10 usec dt in both the non-hsove cases. So I am not sure if
any or all of these differences are simply a matter of numerical error.
When I take the dt for the hsolve down to 1 usec I get essentially the same
graph as with dt for the hsolve at 1e-5. So I think that is converged, at 
least as far as the new version goes.
Let's try still smaller dt for the old version, see if it approaches the hsolve
version. If so we know that at least the formulation of the model is OK.

OK, did it with dt=2e-7. Compared with hsolve at dt=1e-5, which is identical 
to hsolve with dt=1e-6. 
	oldEE, dt=2e-7, then hsolve, then oldEE, dt=1e-6

in that order, the second plot of the hsolve case is bracketed by the
old EE models. To me that means that there is a fundamental difference between
the calculations. It is small, however.

- Checked calc_mode to see if it differs. Calc_mode determines interpolation
	or indexed lookup. All are using interpolation in both bulbchans.

Can't track this down. Let's bag it and see how MOOSE deals with it.

Need to implement various conversions listed above.

============================================================================
6 Feb 2006.
Various fixes. Implemented tweaktau and tweakalpha.
Loaded model. Ran. Nothing but nans.
Problems with K_mit_usb: the ugly things use scaling by setting sy of the
tables. Working on it.
Fixed. Scaling works. Still nans.
Also added in a BC name for the basal calcium.  Still nans.
OK, turned out to be because I was not handling compt geometry properly for
polar coords.
Now starting to work. The Ca is not building up though.
Turns out ReadCell was not scaling the B term for Ca conc correctly. Fixed.


============================================================================
7 Feb 2006
Possible issue with compartment: It is not using previous value for Vm in
messages. Should do so for consistency with GENESIS, though the system is
actually more accurate without.

Looking at synchan. It is amazingly complicated. 2 phases: arrival of the
action, and process.

Arrival of action:
Much of it seems to be 
housekeeping for handling event buffer. The incoming synapse brings a
time, that is all. The weight field is handled locally.
Allows inputs to be bunched as each is tagged with simulation time. Good
for parallel. There is some totally weird stuff about setting the spike
time to time remaining after arrival. Will need to check if this matters,
or if it can be bagged and we just store absolute time.
Also GENESIS scans all incoming syn messages, not sure why. The action is
apparently called as soon as the msg arrives, and the data is the msg identity.
May be just to match it up to the msg #. MOOSE can eliminate this.
During process.
If latest time is due, then add to activation:
channel->activation += channel->synapse[syn].weight / dt;

Once there it is standard decay: 
x = channel->activation * channel->xconst1 + channel->X * channel->xconst2;
channel->X  = x;
channel->Y = channel->X * channel->yconst1 + channel->Y * channel->yconst2;
channel->Gk = channel->Y * channel->norm;
channel->Ik = ( channel->Ek - V) * channel->Gk;

So all this could be done rather compactly in MOOSE using STL.

============================================================================
8 Feb 2006.
Trying to replace previous Vm for axial and raxial messages. Gives very
different results from the original GENESIS version. Turns out that
even using the previous Vm value the calculations are asymmetric. Decision:
Bag it. The correct calculations need the solver anyway.

Some timings on imarti, simtime 1 sec, dt 1e-5:
Moose mit.g	:			69 sec
Genesis no hsolve :			66 sec				
Genesis with hsolve:			7.2 sec

I am a bit surprised at how slow MOOSE is. It goes much faster than
GENESIS with the molecule calculations.
Tried putting some of the compartment calculations inline. No real difference.
I think that the fundamental issue is that MOOSE use of messages for lookups
is slower than having the table within the tabchannel. This offsets the
general advantage of faster messaging.
Checked, compiles cleanly on imarti with GCC4.

Prepared release 0.05.

----------------------
Switch gears now to CSPACE.
============================================================================
12 Feb 2006.
Implemented and compiled a preliminary version of SynChan. Much testing to do.
============================================================================
13 Feb 2006.
Need thresholder to go with SynChan. Done: SpikeGen object.
Now need test simulation using synapses.
Implemented a test based on squid, for MOOSE. Need to do the equivalent
now for GENESIS to confirm.
Working on it. Still stuck - unable to resolve match.

============================================================================
14 Feb 2006.
Finally tracked it down to a GENESIS peculiarity in the squid demo. The
MOOSE version had been right all along. Saved plots and compared, match
is nearly perfect barring numerical and tiny setup differences.

============================================================================
15 Feb 2006.
Getting it all configured for subversion. Plan is to retain current location
of mus in /home/bhalla/genesis/mus.

============================================================================
16 Feb 2006.
CSPACE stuff: Working on the old moose. Implemented object for doing
bistability by construction. Testing in 
/home/bhalla/homework/CSPACE/feb16_2006_bistab_construct.
Beginning with model 
m2.g
from 
/home/bhalla/homework/CSPACE/feb11_2006_construct_bistab

============================================================================
17 Feb 2006
More CSPACE work. Implemented the old MOOSE bistab_construct object, works
well in one case, fails sadly in another.

Working on release number 0.06 of the new MOOSE. Minor fixes.
Committed as revision 2.

SVN Copied it over to file:///opt/SVN/moose/genesis/prerel_0.06
Committed as revision 3.

Checked out prerel, cleaned up, committed back as revision 4.
Saved as mus_release_feb17_2006, revision 5.

============================================================================
18 Feb 2006.
old MOOSE: much grinding on the bistab_construct object. Getting there.

From 14 Jan:
Bigger picture:
+ Get current kinetics capabilities into this version of MOOSE, including
	conversions, so I can shift stuff over.
+ Get complete biophysics stuff done so I can do bulb modelling stuff
- Get some level of parallelization going so I can do bulb modelling in 
	parallel.
- Implement solver architecture so people can begin to play with it.
- Bring in the GSL so I can do heavy crunching.

============================================================================
20 Feb 2006.
Working on solvers. It is a big problem, let us break it up into bits:
- What does the numerical method need? Can we generalize for all solvers?
- Harvesting the solved objects. Possibly a buffer class between a set
  	of numerical engines and the simulator.
- setting up connections to each object.
- Intercepting messages from outside the solved set
	- Building a list of msgsrcs
		- Handling triggers for updates
	- Building a list of msgdests
	- Handling valueRelay requests.
- Intercepting sets
- Intercepting gets
- Providing fallback computation options for unknown objects
- Solvers starting with a simple Euler solver.

============================================================================
4 April 2006
Added fixes for genesis parser provided by Dave Beeman and Joe Svitak
Dave's fixes: Correct problems with compiling with some recent
versions of bison. Turns out that this was a fix already implemented 
in GENESIS. Problem arose because of an error in the GenesisParser.ypp
Joe's fixes: Numerous gnarly Yacc syntax changes to make it handle
DOS type newlines.

Committed these fixes as revision 6.
Just because I don't yet reallly think in svn, here are the commands I used:
svn commit
(then I put in the log message)
svn update
(This updates my working copy to the current version)

Next is to work on solvers. Consider the signaling solver first, as we have
several working examples. Structure the harvester as a dually-inherited
class so that it is clean to pass the y(t) and y'(t) arrays as pointers.

Something about the API: 
Old solvers have the following fields:
mode
path

and messages:
proc
reinit
solveout: Goes to zombies

There seem to be two major wrapper functions: 
internal_set_path: Assigns solver zombies, fills up solveout msgs
set_solvefield: Handles calls to fields in zombies.

In the solvers I have various build commands:
build_mols(vector<element *>& path)
build_sumtots(vector<element *>& path)
build_reacs(vector<element *>& path)
Seems like these are a bit redundant but each solver has its own data structs
so it may be OK.
But for example for ODE solvers which need y(t) and y'(t) we could merge.
Something like kderiv. Should clean. Should find exactly how rksolve uses it,
this should be nearly enough to design something even for rosenbrock and
LSODA.

============================================================================
5 April 2006

Turns out kderiv does two things. It grabs the model values, but it also
does the calculations for rates. It is a complete representation of the model.
Should I instead set up a stoich matrix version? I would still need to have
the calculation of each rate term, but not too bad:

y'(t) = N.f( y(t) )

The kderiv form does have the merit that it is organized according to rate
type, and is therefore fast. But it should not be hard to handle reordering.

Why not start with a kderiv which talks to each thing individually asking
for y, y'. This can later subsume some objects while retaining the basic 
API for other objects. The objects which do not become internalized are
called externally solved objects.

This is a good exercise. Seems like we need the following:

kderiv to object:
updateOut: Sends y to the object.
updateStep: Tells object to update its y', given t and dt.
	Need version of this which only asks for y for objects like input tables
object to kderiv:
updateIn: Receives y' from object
	Need version which takes y from objects like input tables.

For an explicit solver, using Euler:

y(t + 1) = y(t) + y'(t) * dt

For an implicit solver, using backward Euler
y(t + 1) = y(t) + y'(t + 1) * dt

So just passing y and y' in either direction does not give enough info to
do externally solved objects implicitly. Can we do it?

Consider a compartment. To compute y[n]'(t + 1) we need
y[n+1](t + 1) and y[n-1](t + 1) and any branches. Mutually the same info will
be needed for these other compartments. This is hard to do because of matrix
dependence. Runge-Kutta type solutions would not be a problem.

Consider a channel. To compute y[n]'(t + 1) we need y[n+1](t + 1) for the
associated compartment, and an estimate for y[n]'(t + 1) itself. This should
be possible to set up on a single-channel basis.

Consider a molecule. Again, the implicit solution needs matrix-dependent terms
and is not suitable for externalizing. However, a Runge-Kutta solution would
again be OK.

Consider a reaction. This gets completely internalized because it defines the
matrix coeffs in a reaction system. This is possible to externalize rather
cleanly if we adopt the stoichiometry matrix design for our solver. See below.

Consider a tabulated input. This is just another fixed input to either a 
compartment or a molecule. Not a problem.

Consider a horrible computed rate function. This is not easy to internalize.
What we could do is to define the following messages and operations:
- An init/process	: Override or co-opt the existing sched
- All inputs		: Use existing molecules. ensure they are updated.
- The contribution of the rate function. This is just an entry in the rate
	vector.		: Send in the derivative term.

These elements would apply just as well to reaction rate terms. So we would
do well to put reactions in as a test case as an external input. 

Basically all we need to change for solved vs regular use is to provide a
derivative term.

Summary:
1. Implement kderiv to use stoichiometry matrix form.
2. Provide messages for external updates to rate vector
	- Init/Process
	- All mol values
		Could in principle just update the molecule and have the
		numbers propagate through to the reac.
	- dest for derivative.
3. Internally manage molecule levels, update externals as needed

============================================================================
9 Apr 2006
Fun with implementation. Some design issues for the kderiv, the part where
it manages the calculation of rates.

Option 1: 
	- Bunch of vectors for kf, kb, MM rates.
	- A vector for y.
	- A vector for rates.
	- Bunch of vectors for ptrs to doubles. This refers to locations in
		the above two vectors.
	Sub option 1.1
		- vector for # of ptrs to use in each calculation
		- Iterate through taking products of the double* s, and putting
			into rate vector.
	Sub option 1.2
		- Order above list for 1, 2, 3,... n prd terms.
		- Execute functors with suitable # of args on sub vector
			with start ptrs to ptrs of doubles, using transform
			so outputs go into rate vector.
	Advantages: Separate vectors for rates, values, etc. This set just
		ties them together
			Speed?
	Disadvantages: 	Computations are opaque.
			Need multiple subvectors

Option 2:
	- Vectors for Rate objects, MM objects, Sumtotals, and Externs.
		These are virtual objects so we can overload.
	- vector for y, vector for rates.
	- Each entry contains rate parms if any
	- Each entry contains ptrs to ys.
		Sub option 2.1
			- Each entry contains ptr to rates
		Sub option 2.2
			- Each entry has function that returns value
	- Use transform/for_each to iterate through vector of Rates, etc and
		store outputs according to options 2.1 and 2.2.

	Advantages: 	Separate entities for each reaction etc.
			Somewhat cleaner.
	Disadvantages:	Speed?
			Proliferation of subtypes if we want it faster.
			Construction and updating?

============================================================================
11 Apr.
Looks like we're going with option 2.2
Separate, long pending issue: How does solver handle clock ticks and eliminate
existing ticks?

Simplest approach is to replace the clocktick with the solver. Fine until
we have multiple solvers managing overlapping sets of objects.

============================================================================
15 Apr.
Slowly working on implementing the solver. Various aspects to it:
- The Stoich class, handling generation of the stoichiometry matrix and its
	calculations
- A set of classes for doing the rate vector terms. One each for the zero,
	first, second and higher order reactions. Additional ones for enzymes.
	Further ones for external rate objects.
- A class for doing sparse matrix calculations. Used for the stoichiometry
	matrix because of speed and space.
- A class for dealing with SumTotals.
- The actual numerical solution engine
- The stuff for setting up solver messages
- Ways to insert solver into scheduling hierarchy.

Setting up parts of this bit by bit. Have successfully done a skeletone
compile of the first 4.
============================================================================
16 Apr 2006

Too many silly issues with the preprocessor have cropped up. I have done a
substantial upgrade of the preprocessor to resolve these. This is 
checked in to subversion as revision 7.

Added a few more mpp fixes for handling templates and function calls using
them. Now the Stoich code compiles directly after preprocessing.
Checked in to subversion as revision 8.

Starting to take shape. Managed to compile version that handles the 
molecule assignments. This version immediately dumps core when it is given
a path to handle.

============================================================================
17 Apr 2006.
Got the thing to run without crashing, but can't check anything yet.

Suggestion: Further modularization of the solver system:

Stoich: Extracts stoichiometry matrix info from path. Useful in many other
	contexts too.
Ksolve: Handles the control of the zombie objects. Takes over process.
	Uses Stoich for value calculation.
Assorted numerical engines:
	EE: Exponential Euler engine talking to Ksolve. In-house.
	AdStoch: Adaptive Stochastic method of Vasudeva and Bhalla. In-house.
	RK5: Runge-Kutta numerical engine talking to Ksolve. GSL, In-house?
	RK4implicit: Implicit RK4 method. GSL.
	Gillespie: Gillespie method with optimization.

All fine here, but still need to work out how to do Stoich on own and in 
combination with Ksolve.

Returning to the debugging. Still not getting a correct count of molecules
in various states.

============================================================================
18 April 2006.
Turns out that the messages are not being added from the stoich to the
object. Perhaps OK for now, if the current goal is to build stoich matrix
as an independent object.

How to align stoich matrix with Ksolver? One option is to just use index
ordering: map the # in the wildcard path. Should the Stoich then worry about
the rate vector?

============================================================================
25 April.
Yes, rate vector should be in Stoich. Stoich should be the one-stop object
for getting all the kinetic info used by solvers and analysis routines.
Does the Stoich actually do the calculations? Makes sense: it has all the
info.
Does the Stoich control the external rate objects? No. That is the job
of the ksolve. The stoich needs to indicate that certain objects need to
be updated each dt. This becomes part of the internal sched of the ksolve.
ksolve also retrieves values and puts them into the Stoich.

Still working through the Stoich.mh

============================================================================
26 April.
Need some more stuff in the preprocessor. The field function definitions
need an easy way to override. Currently the default is to put them into the
MyClassWrapper.h and just lookup or assign values. Suggested syntax:
setField( FieldType& value ) {
	....
}

This should be placed somewhere at the end of the .mh file, after the 
class definition.

Then the job of the preprocessor is to replace the regular 
static void setField( Conn* c, Type value ) {
	static_cast< MyClassWrapper* >( c->parent() )->field_ = value;
}

with
static void setField( Conn* c, Type& value ) {
	static_cast< MyClassWrapper* >( c->parent() )->setFieldLocal( value );
}

in the MyClassWrapper.h.
In the MyClassWrapper.cpp, the local function is filled in at the appropriate
place:
setFieldLocal( FieldType& value ) {
	....
}

Similarly for getField.

In the works. Now compiles and reads in the correct number of molecules etc.

Working on setting up Stoich Matrix. Needs defn of matrix, as well as
still to compile.

Now able to compile, bypassing matrix stuff by just printing it out. Looks
like it is able to find substrates and products.
Still need to fix the FillStoich function.


Issue of coupling between Stoich, Ksolve, and actual solvers. Ideally
Stoich should be the hub and the other two talk only to the Stoich, not
to each other. This minimizes the number of interfaces.
Issue: The Gillespie algorithm needs to do dependency map traversal.
This is not accommodated in the current Stoich architecture. Later.

Now to home in on API for sparse matrix.

Also need to sent MOOSE to someone.

============================================================================
3 May 2006
Much work on the old moose, to write a calculator for total molecule count
(for checking models). This turns out to be far harder than expected. After
3 days or more of work on it, I have a version that works often, and reports
when it fails by giving a return value of -1. The way it goes is :

include {arg1} // Loads in the model file to test
create stoichmat /s
/s/path = "/kinetics/##"
shf /s/total_mol_conc
quit

Now to put together a variant that handles the batch file outputs.
============================================================================

10 May 2006
Working on MOOSE equivalent of the old GENESIS concchan. This is needed
primarily for conversions of old kkit models to SBML and other forms.
Nevertheless, it has to work to be sure it is valid.

============================================================================
15 May 2006
OLD MOOSE:
Working on a filter for tcas runs. It is somewhat shoehorned into the existing
kinread command to avoid any bigger MOOSE changes. Reads in a tcas file from
the CSPACE project, and filters out solutions which violate mass conservation.
Also checks for -ve solutions.

============================================================================
20/21 May.
OLD MOOSE:
Working on on concchan. Seems to be done. Notes are there too. Turn it
over to Arun now.
============================================================================
29 May
Compiled in stuff with a more functional SparseMatrix (it isn't really sparse,
but has the right interface). Current issue in StoichWrapper.cpp is
where to define the size of the SparseMatrix, esp the # of reactions.
We still have the issue of counting substrates and prds.

Later: Fixed substrate counting issues. Still haven't defined SparseMatrix
size properly. Now to get the enzymes into the StoichMatrix. In progress,
StoichWrapper.cpp:410 ish
============================================================================
30 May 2006
The stoichiometry matrix is now loading, apparently properly, from medium
sized models. 
* Define matrix size correctly
- Use it and rate vector in simple Euler solver dummy.
- Start with solver stuff.

From 17 April:
Stoich: Extracts stoichiometry matrix info from path. Useful in many other
	contexts too.
Ksolve: Handles the control of the zombie objects. Takes over process.
	Uses Stoich for value calculation.
Assorted numerical engines:

At this point it looks like Stoich should be the hub:

Elements <===> Ksolve <===> Stoich <===> EEsolve

Connection between Stoich and solvers:
From Stoich to solver: y'
from solver to Stoich: y

The y' will typically not change.
The y will often but not always be a distinct part of memory. Should
avoid copies.
The Stoich expects to have its own stable array for y and y'.

Summary:
Stoich should expose the arrays y for writing and y' as readonly.
Any updates in y should be done external to Stoich.
These must be done as messages so we know what is communicated.
We will use a shared message so that all is coordinated.
The shared message includes a trigger from the solver, and the y and y'
	array ptrs from Stoich back to the solver. 
The trigger call causes Stoich to update y'
Possibly we could return y' into an array passed in. We don't need to allocate
it in Stoich. 
Possibly we could use y also as a passed-in array if we converted our stoich
calculations from pointers to offsets. Slower.


Beginning the implementation with Stoich::updateV
There should be an algorithm that handles assignment of successive RateTerm
evaluations to successive v_ vector entries.

============================================================================
1 June.
Implemented preliminary (and very inefficient) SparseMatrix
calculations for yprime.

Set up an initial ForwardEuler to talk to the Stoich. At this level of
abstraction the ForwardEuler only needs to know its own dt and runtime.
Should also be able to request reinit in the same message. Reinit
can pass the rate vectors around too.

Should we have it so that ForwardEuler or other solvers can talk to multiple
equivalents of Stoich? Later

Working steadily through the implementation. I have most of it in place but
we need a little work to back-fit the Stoich class to talk to the new
ForwardEuler class.
- The ForwardEuler passes a yprime in to the Stoich class. This is
	because other integrators may want to keep track of multiple yprimes.
	yprime actually has multiplied into it a dt term, so it is delta-y.
- The preprocessor has a new section added, private_wrapper:
	This simply dumps its contents verbatim into the private section of the
	Wrapper.h.
- Working on the back-merge of Stoich.
	- Stoich.h: OK
	- StoichWrapper.h: OK
	- StoichWrapper.cpp: OK
- Compiled ForwardEuler as a preliminary integration engine.
	Now need to couple it into the currently hook-less system and
	display a good run, like kholodenko.g

============================================================================
2 June.
Working on the check. 

/home/bhalla/genesis/mus/test/test_ForwardEuler.g

Framework is set up and a couple of bugs squashed, but the values build
up steadily and nan soon.
Fixed by using smaller dt. Now output does not balloon, but it certainly
does not look intereesting.

============================================================================
5 June 2006
Shifted laptop to Ubuntu 6.06. This breaks the compile in various ways.
They are retrievable, but not cleanly. Anyway, I have asked for help on
it and will now have to go on with the solver stuff.

Start by trying to model a simple reaction. Runaway buildup.
Some parts are explained by inverted sign for rates. More later.


============================================================================
6 June 2006
Looks like MMenz is OK. Still trying to sort out issue with regular enz.
Later add higher order reacs to the test list.
============================================================================
7 June 2006
Got it to work for 4 test cases: reac, enz, MMenz, and kholodenko model.

Now, two immediate directions: 
- Implement another numerical engine. An RK engine would be nice. This
	will test out the generality of the API for the solvers. Also
	give a motivation for trying out the system in real work.
- Implement the zombie code. This is a bigger job. In theory it should
	be completely independent of the numerical engine.

Also, for when I am really tired, 
- Implement a good SparseMatrix.
- Implement a RateTerm for handling general equations.

The nice thing is that the system seems to be shaping up as completely modular.

============================================================================
8 June 2006
First lets try the Ksolve. For starters, we'll set it up to zombify a
model and make everything decay exponentially, amplitudes set by initial conc.
Tests:
- Eliminate messages from original Process, replace with zombie message.
- Keep track of different output messages to plots, even with different dts
- Initial condition to set ksolve
- in-simulation get of any n
- in-simulation set of any n
- Addition of new messages after solver put in
- Removal of messages after solver put in
- Deleting object

Working on design with just the molecule as a starting target.
- Use ProcessConn
- No extra space needed if we set up a new Dest for n
- SingleMsgSrc needs 2 words (Later: could eliminate one by templating?).
- RelayFinfo needs >= 5 words.
- Could design a SolverFinfo template using 1 word: The conn ptr. All
	else is handled by a templated function for looking up dests and
	another for srcs. Actual space usage = 3+ words because of holding
	the SolverFinfo ptr and the name of the finfo. This object needs
	to intercept all 
	in/out messages involving n, return msgs from the graphs, and set/get.
	- New calls will be intercepted at the Element::field(name) stage.
		- Sets and Gets: doable.
		- Message arrival: only SumTotal applies. Will need to
			construct relay and pipe extra info into solver
		- nOut msg out: Need to scan to see if it goes anywhere
			other than reacn. If so, need to construct relay
			etc. Also some counterpart on solver to handle
			updating.
		- Add msgs: Same func, only construct the relay on the fly.
			Need to deal with issue of user adding another part
			of the reacn system.
		- Drop msgs: Destroy appropriate relay along with original
			message if applicable.

Too much. Subdivide problem further
* Fix mpp so that stuff after the class definition goes into the 
	*Wrapper.cpp.
* Make the first pass at the Ksolve.mh
* Scan path and replace original Process messages

============================================================================
9 June 2006
I am now able to replace the process message from the ClockTick to the molecule
with a molSolve message from the Ksolver. However, this requires that
the replacement message look exactly like the original. Two options:
- Provide another target shared message on the molecule that uses the same
	ProcessConn, but also handles the additional terms.
	- Possibly cleaner. But it requires that each object know ahead
	of time what a solver is going to do to it. That is not acceptable.
- Do further hacks with the messaging so that a solveFinfo dynamically
	created on the molecule knows to use the ProcessConn, and deals with
	all remaining bits of info transfer.
	- Use mostly existing framework, need new Finfo. 
	- Cost of Finfo is steeper than expected: Name plus ptrs.

Try putting a new field in all Finfos, or at least all relay Finfos, that
links into the solver. Just addition of this field should redirect all
lookups suitably. It also means that the Match command should just ask
the original object Finfo what to return, and make a copy with the solver info
attached.
At first glance, this should work for most kinds of Finfo operations,
except for already established messages. 
- Messages sourced from zombie: Create a relay from solver to msgsrc on zombie.
	No need to yank message provided that there is no internal trigger.
- Messages into zombie: Issue is that the recvFunc is already deployed
	elsewhere. Seems like we have to yank message and redeploy.
	Possibly some messages could be left alone provided they do not
	trigger anything in cascade. Then to tap into the contents of these
	messages we need to connect back to the output of the originating
	object.

It boils down to altering the ValueFinfo to also hold solver info. We
will need to put in fields for set, get and conn. There is already an
objIndex_ field used for arrays, which we can coopt.
Perhaps we can create novel ValueFinfos using the set and get from the
solver.

For cleanness, I should aim to design all this to use legal messaging only.
Avoid pointers into objects if possible.

============================================================================
10 June 2006
Now for some specifics.

Setup:

Get: 
	- Look up Finfo
	- Operation of lookup asks solver for an update of the target
	- Finfo just returns usual field.

Set:
	- Look up Finfo
	- Finfo returns usual field
	- Finfo then sends update message to solver.

Message in:
	- Ignore all but slave or sumtotal.
	- At construction time: scan for these, build a relay to the
		update message going to the solver
	- When input comes in, update message takes it home.

Message out:
	- Ignore any that are within ambit of solver
	- Ignore All except concout and nout.
	- At construction time: 
		- Scan for these, build relay to the message going out.
		- Register required update on solver. 
	- Update periodically, then trigger relay out.

Plot:
	- Scan for or subvert existing relay for the ValueFinfoRelay
		- Subversion would simply mean inserting the routine below.
	- When input comes in, update message takes it home.
	- Then update message goes back to object.
	- Then return value can occur.

Add: (The object is a src)
	- Look up Finfo. Do we care? Assume yes. 
	- Return usual Finfo. Allow message out to be made
	- Do as we would at construction time for Message out:
		- Build Relay to message going out.
		- Register required update on solver
	- Update periodically to trigger relay out.

Respond to add: (Object is a dest)
	- Look up Finfo. If we care, then...
	- Allow message to be made.
	- Decide if it is a regular message in or a plot
		- Regular message in: As we would at construct time for Msg in:
			- Build Relay to trigger update message to solver
			- When input arrives, update message sent off.
		- Plot: As we would normally:
			- Subvert message
			- When input comes in, send req to solver
			- Solver sends back return value.

So, messages to and from solver include:
- Update message which sends values from object to solver. n, nInit, mode.
- Update message which sends values from solver to object: n.
- Trigger message which asks solver to send update to object.
- Dummy Process/Reinit messages which handle the connection and provide
	a channel for all this to happen.

What does the SolverFinfo have to do?
- When looked up, it has no way to know what the operation is going to be.
Actually no.
	- If it is a field, the operation will either be get or set,
		or add a message to the field.
	- If it is a src, operation will be add.
	- If it is a dest, the operation will be respond to add. 
- If we could register a post-operation callback, we could complete the
	operation.
	How about something at the time of destruction of the field?
	- Field: Callback updates solver, then scans for changes and does
		its thing.
	- src: callback scans for changes.
	- dest: callback scans for changes.

- Must provide all the traversal calls for incoming and outgoing messages
	between solver and object. Just another relay?

============================================================================
11 June 2006.
Before I begin messing up the system with new finfo objects, time to do
a version entry. More frequent versioning would be better. Last entry was
version 8, on 16 Apr 2006.

I just realized that in the operating system upgrade, I left out /opt,
which is where the old svn repository was. Fortunately a lot of
the repository state is in the local cache. Hm. What to do? Nothing 
obvious on the SVN FAQs. I'll subscribe to their mailing list and ask.
Here are the relevant comments:
> On Jun 11, 2006, at 15:00, Upinder S. Bhalla wrote:
>
>>   I forgot to back up my SVN repository files from /opt when I
>> upgraded my
>> OS. The disk has been wiped and reformatted. I do have the user
>> subdirectory with the current files and the local .svn subdirectory
>> with
>> the working revision. I realize most of my project history is history,
>> but I would like to reconstruct my SVN project back to the last
>> revision. What should I do?
>
> If you didn't back up the repository, then the history is gone, so
> you only have the revision that's currently checked out in your
> working copy. You could import that into a new repository and start
> over from there.
>
> I believe Subversion (at least the current version, 1.3.2) will
> ignore the .svn directories when importing, so you should just be
> able to "svnadmin create" the repository, "svn import" your old
> working copy into it, and "svn checkout" a new working copy from the
> new repository and get back to work.

On 6/11/2006 9:51 AM, Upinder S. Bhalla wrote:
> Thanks - I see that my earlier history is gone. But is there a way to use
> the local .svn files to populate the rebuilt repository with the most
> recent previous revision in addition to the current state?

This is probably a little tricky to get right on the first attempt, so 
first you should back up your current working copy (including all the 
.svn directories).

Then: make another copy of it somewhere, say OLD.  Use svn revert in OLD 
to  undo all the local changes, and do your import from OLD.

Then cd over to the pristine copy of your locally modified copy, and use 
svn status to find all the local modifications.  Copy all modified files 
over to OLD (overwriting what is there), do all deletes and adds in OLD, 
until OLD looks just like your locally modified version, and svn status 
there returns the same thing.   Then commit those changes.

Then back up your repository.

Duncan Murdoch

---------------------------------------------------------------------
My experience with this:
OK up to creating the OLD, reverting in it, and doing the import from OLD.

Now I made one big change: I want the SVN repository to be in a different
place so I won't forget to back it up ever again. I proceeded with the
next step ( copying over modified files into OLD till it looks like my 
locally modified version). This went fine. But when I tried to commit it,
it complained:
svn: Commit failed (details follow):
svn: Unable to open an ra_local session to URL
svn: Unable to open repository 'file:///opt/SVN/moose/trunk'

I interpret this to mean that it is still trying to dump the files into
the old repository, specified in the local .svn administration directories.
Option 1: Hack into the files in the .svn directories to change the 
path. A quick grep suggests where I should look, in a file called entries.
If I knew enough about the system I might do this, but I don't want to mess
things up.

Option 2: Check out version 1 into a temporary location. Copy over modified
files into this checked out version, do the adds etc, as before. Now
commit it. This works. I still need to clean things up and commit
a proper revision 3, but it is late and the tricky stuff should be out of
the way now.


Stuff for this version:
Various improvements to the preprocessor. 
	- Can put lines into the private portions of the *Wrapper.h
		file (previously only .h was possible).
	- Can put lines into the *Wrapper.cpp file.
Compilation fixes for Ubuntu 6.06. Unfortunately some of these involve
	hacking the output files from the parser. A make clean would not work.
	Because these are parser output files they are not managed by SVN.
	The fixes are listed below.
Lots of work on the solver for biochemical kinetics.
	Stoichiometry matrix works.
	Grabbing the state of the model works
	An API for connecting a numerical engine to the Stoich class works.
	A ForwardEuler numerical engine (purely for demonstration) works. 
	The beginnings of the Ksolve object compile, but it is not
	functional.  Ksolve will do the actual zombification of the model
	objects. At this stage it successfully takes over the Process
	function of molecules, but does not go on to handle forwarding
	of calls and
	assignments.



Compiler flags and other fixes to get compilation on
	g++ (GCC) 4.0.3 (Ubuntu 4.0.3-1ubuntu5)

- Here are the compiler flags that eliminate most errors:
             -DYYMALLOC -DYYFREE

- Here are the remaining error messages:

/usr/include/FlexLexer.h:113: error: redefinition of ‘class yyFlexLexer’
/usr/include/FlexLexer.h:113: error: previous definition of ‘class
yyFlexLexer’
GenesisParser.yy.cpp:1850: error: declaration of ‘int isatty(int)’ throws
different exceptions
/usr/include/unistd.h:717: error: than previous declaration ‘int
isatty(int) throw ()’
GenesisParser.tab.cpp: In member function ‘int myFlexLexer::yyparse()’:
GenesisParser.tab.cpp:2756: error: ‘1’ cannot be used as a function
make[1]: *** [GenesisParser.tab.o] Error 1

The first error (line 113) is fixed if we comment out this line:

GenesisParser.yy.cpp:20
    #define yyFlexLexer yyFlexLexer

(yes, it seems like an incredibly dumb line)

The second error (1850) goes away if we comment out the declaration
The third error (2756) goes away if 2755 and 2756 lines are commented out.

============================================================================
12 June 2006
Put all the SVN cleanups together, and now set to check it in as revision 3.
This revision should get us back up to speed with svn updates.

============================================================================
1 July 2006
General fix up to get it to recompile from a make clean. 
Now I need to figure out how to get the changes into SourceForge.

That looks difficult. Pity. I was ready to do a checkin, and there are
lots of interesting changes here in the offing.

How to do an efficient solver takeover of an object:
- Extend the Process shared message to include 
	- Update message to send values from object to solver: n, nInit, mode.
	- Update message which sends values from solver to object: n.
	- Trigger message which asks solver to send update to object.
- We want this to become a generic Process message. This means that all
	the shared messages also must be generic.
	- Update obj -> solver: Nope
	- Update solver -> obj: Nope
	- Trigger obj -> solver: Yes.
- Note that through all this we still really would like a Finfo to 
	intercept all calls. 
	- Or we redefine finfos too.
	- Or we intercept all Field calls.
	- We could use the info about the presence of the solver msg src
		func for trigger (see below) to check if we should intercept.
- We could use a nested shared object
- We could try right now to see if we can share the parts of a shared object.
	This looks possible from the SharedFinfo code.
	- We probably want to collapse the trigger into the update msg to
	reduce overhead.
- We could call trigger etc on the fly. This may get expensive though.

============================================================================
2 July 2006
Prior to doing these changes, I'll check all this into the local svn
repository on my laptop. Later will worry about merging it with the stuff
on the SourceForge server.

Working on it, but got sidetracked into fixing up evaluated fields in
the preprocessor because molecules use them a lot. We are getting close
to being able to define the entire class from the .mh.
Look at EvalField.cpp:77

Moving on. Compiled, now testing out MyClass.mh which as far as I know
has all the features so far implemented in the preprocessor.
Getting close. Stuck at balanceBraces.

Looks like it works now, at least for the evaluated fields. But the
statically consts are not yet set up.

OK, seems to have mostly come together. Tested OK against the MyClass.mh
and against Molecule.mh
Remaining niggles:
- comma after constructor initializers
- Assigning static consts.

Since we've already done a checkin, no harm in doing another. 
Checked in as version 5.

Now messing around with the molecule definitions. Trying to set up the
solver messages in Molecule to use the ProcessConn. Looks like it compiles,
at least. Now need to set the other side of it, the ksolve.

============================================================================
3 July 2006
Looks like the ksolve thing worked, at least to set up the connections.
Now to figure out how to use the messages to update info.
Now to get this integrated with the solver.

At this point the Stoich class goes and looks directly at element fields.
We need to do this cleanly. The Ksolve class is already handling element
access cleanly through its messages. The Stoich class should now be decoupled
from the elements, and connected through Ksolve as in the original diagram of
30 May:

Elements <===> Ksolve <===> Stoich <===> EEsolve

For now, lets check this in.

- Get Ksolve to take over reacs and enz too
- Get Ksolve to talk to Stoich 
- Change Stoich so it uses Ksolve info rather than look up its own end of things
- Fiddle with Fields so that requests for a field to assign a value to
	a molecule get forwarded to Ksolve.
- Fiddle with Fields so that requests for a field to obtain a value from
	a molecule get forwarded to Ksolve, ksolve updates the molecule,
	and then the regular field info operation occurs.
	- This is sort of working now. But:
		- It calls the trigger even if it is a setField call.
			This is because the trigger is keyed to looking up
			the field (triggerUpdate in MoleculeWrapper.cpp:211).
			This is not good.
		- It doesn't know how to map back onto the originating
			element. Clearly something like returnFinfo is needed.


============================================================================
4 July 
Clearly we need to do something different with returning the field, so that
it does the correct thing depending on what is asked of it.
- For a set, it should send info to the solver, then assign objectt.
- For a get, it should trigger the update from the solver, then allow info 
	to be taken from object.

I'll check this in and then go back to doing the separate finfo. This was
checked in as revision 7.

============================================================================
1 August.
Merged in the SourceForge version 4, which was deposited by Joe Svitak after
cleaning up for a Windows compile. Not too many changes but we still have
some nasty stuff in the parser to do with the new flex/bison. At this point
the local version should parallel the SourceForge version. Also sent it
in to SourceForge as revision 5.

============================================================================
4 August.
Getting back to solvers. As mentioned on 3/4 July, we can't use the current
triggerUpdate hack on the Element::getField function. Proposal:
+ Extend Field data structure with a flag indicating if it is solved.
	(Can't be in finfo, because finfos are readonly and shared)
* Use triggerUpdate to set this flag in getField
* in Ftype, modify the get and set to take const Field& argument (possibly later)
* In Ftype get and set, check the solver flag on the Field to see if we
	want to do anything about it.

============================================================================
5 August 2006
Do we use Element::isSolved() rather than the flag in Field?
Pros:
	Just in time
	No extra variable to pass or store
Cons:
	Multiple solvers?
	Not all fields care.

Ties into issue of updates. I want the solver to flag fields as being of
interest, not have to hard code it in.
Even better: solver should give the illusion of fields that do not exist?
	Don't get into this for now.  
@All this would be easy if we had a field array pointer for every object
rather than the current system of it being hard coded in.

Specific example: Molecule with xyz coords
Explicit solver: Ignores spatial info, uses in.
3d solver 1: includes xyz coords, ignores n which is always 1.
3d solver 2: Uses xyz coords to look up n in its internal space.

In general only 1 is operational at any time. However, one may have cases
where different parts of the same object are modeled by separate solvers.
(e.g., compt sims where xyz and Vm are modeled by a growth solver and hsolver
respectively). Ignore for now.

Single solver, somehow tells object which fields to report.
SolveSrc_ should do this. It has to be hard coded for any part of an object
that needs to be solved.
Example above:
Explicit solver: SolveSrc(n, nInit). Molecule::get needs update for n.
	Molecule::set needs to pass info for n and nInit.
3d solver1: SolveSrc(x, y, z). Molecule::get needs update for x, y, z.
	Molecule::set needs to pass info for x, y, z.
3d solver2: SolveSrc(x, y, z, n, nInit?). Molecule::get needs update for n.
	Molecule::set needs to pass info for n and nInit. However, the
	get call needs info for x, y, z as well and n has to come back.

reaction: SolveSrc(kf, kb). reaction::get needs nothing.
	reaction::set needs to pass kf and kb.

There is indeed local info about destination operations in the solveFunc
which accepts info from the solver in the composite message. The identity
of this composite message can tell us which fields are affected. But this
is very indirect, and it is simpler to write a specific function in the
object to return the isSolved(const string& name) flag.

Now into the core of it, and it is best to revert to something more like
the original triggerUpdate function, except that it needs additional info
to know whether it is a set or a get. Later the additional info will also
tell the solver if we are doing an addmsg or any other operation. I think
the only ops to worry about are set, get, addmsg, deletemsg, and delete.

OK, done. I now am able to access the inside functions of the solver and
also tell it whether to set or get. The object values get updated too.

From 3 July:
- Get Ksolve to take over reacs and enz too
- Get Ksolve to talk to Stoich 
- Change Stoich so it uses Ksolve info rather than look up its own end of things
+ Fiddle with Fields so that requests for a field to obtain a value from
	a molecule get forwarded to Ksolve, ksolve updates the molecule,
	and then the regular field info operation occurs.
	- This is sort of working now. But:
		- It doesn't know how to map back onto the originating
			element. Clearly something like returnFinfo is needed.


Looked at various options for the return call.
- The obvious one, ReturnConn, is not a good option.
	- Too much memory use
	- Need index info for the solver to know who called. We would need
		a map lookup if we used return conns.
- The next obvious one is something like a SynConn
	- Each SynConn stores only 1 connection, and an arbitrary type T,
		and therefore each has to also store the parent element.
	- The target synapse (or in this case, the solver) would have
		a vector of SynConns to manage.
	- The type T could store the index info for the solver. But we
		would end up storing redundant info for the parent. Synapses
		have this issue too.
- The next option is something customized for solvers.
	- If we preallocate the synConns, we can store them directly rather
		than their pointers. Saves a word.
	- If we use a vector of allocated UniConnBase-like things we can
		obtain the index by pointer arithmetic on the conns. But
		we still need a value in the allocated conn. 
			- an index, to find the base of the vector and
				hence everything else. 
				Too fiddly.
			- a pointer to the base of the SolverManagerConn
				class which gives us the parent element
				(the solver) as well as a way to look up
				index of conn. That would only be a little
				ptr arithmetic, not even a lookup. Speed
				cost is acceptable, space is a concern here.
				Clean enough to use.
			- a pointer to the parent element (the solver)
				from where we could navigate our way to the
				connections. This is not so good as we may have
				multiple sets of zombie classes on different
				solver messages.
		- So if we use the best of these, we need 2 words per slave
			object. One is the return Conn ptr, and the other is
			the ptr to the base of the wrapping Conn.
			- This compares to original SynConn approach which
			uses 4 words, or the preallocated SynConns using 3.


OK, I have set up a skeleton of all this. I will need to implement a variant
of an NMsgSrc to permit me to send a message to a specific target. But it
all looks pretty good. Only small compromises on speed. No map lookups.
Not too much memory waste. The whole thing uses only regular messaging.
Now I only need to make it work.

============================================================================
7 Aug 2006
As usual, harder to implement the details. Looks like the way to do the
system is to keep NMsgSrc nearly the same but reimplement MultiConn as
a base class that NMsgSrc uses. The original MultiConn is VecMultiConn
and the new one for solvers is obviously SolveMultiConn.
Possibly I can do this at the level of PlainMultiConn instead.
Actually the best bet is to have a single big vector of all the targets.
Then there is no messing around when sending data back to source. The
RecvFuncs are managed separately. This works only because we do not plan to
juggle messages, so the pointers are stable. Need great care to preserve ptrs.

NMsgSrc and its chidren will need a few extra functions:
- addVec: where we add a vector of targets all at once. The targets are
	guaranteed to have the same RecvFunc.
- addMixedVec: where we add a vector of targets all at once. The targets may
	differ and may have to be filtered for the correct arguments.
	Actually arguments are dangerous: could simply be a couple of doubles.
	Filtering has to be done before we get here.
- indexSend( index i , T1 v1, T2 v2 ...)

============================================================================
13 Aug 2006
Because I need to derive another class from the NMsgSrc, I don't really need
to use MultiConn as a base for the SolveMultiConn. But let's take it as
far as I can and see what happens.


============================================================================
14 Aug 2006
The SolveMultiConn stuff is going well, enough so that I am tempted to 
convert the existing MultiConns to this. Would work too, if it were not for
the issues of reallocation in a model that is being built up bit by bit.
Perhaps could set up an internal conversion of scaffolded
definitions for the multiconns to later be converted to this smaller and
probably faster format. Ironically, in the solver I do not really need the
speed.

Current status: Approaching the middle from several ends:
- NMsgSrc, which has attempts to do the various kinds of required messaging.
	Will need to add Finfo::sendTo() to the base class, and
	extend the various derived classes accordingly.
	I also have a dummy NMsgSrc1::sendSolve() that illustrates how I
	could do the old kind of Send using the SolveMultiConn.
- NMsgSrcFinfo, which needs to support the vector add operation for connecting
	up the array.
- Conn, which is getting close to having the bits to do the vector add.

In the meantime, the Ksolve is already prepared to use and test out this 
functionality.

============================================================================
15 Aug 2006
Working on connectVec and going on up through to the Field.
Need a way for Finfo::addVec to incrementally build slots up. 

============================================================================
24 Aug 2006.
Looking closely at the guts of the add function. It will be painful to
propagate addVec all the way through the system. Instead better to implement
an allocate function and then use the single connection add call 
for the rest of the process. Need to redesign all this, but it is too big
a job for now.

For now: 
Conn has a resize( vector< unsigned long >& segments) virtual base function
instead of connectVec. Only SolverMultiConn uses the resize function for now.
SolverMultiConn has been updated to support the regular Conn operations.
NMsgSrc has a resize( vector< unsigned long >& ) operation too.

Here is the sequence of calls:
KsolveWrapper->localSetPath: Field solveSrc.resize()
Field::operator->() is just the finfo. So,
Finfo::resize is a virtual base, goes to NSrcFinfo::resize()
	This function digs up the Conn. Calls conn->resize(). That is it.

OK, now lets try compiling. Usual pages of error messages. 

============================================================================
25 Aug 2006
Compilation done. Linking stuck.
Also pending: Implement molArray in the Ksolve to hold molecule data in
a concise form.
============================================================================
26 Aug 2006

Ideas for better implementation of messaging:
Connections: 
Class Conn {
	Element* e;	// Target element
	unsigned int index;	// Index of target Conn
};

Class Element {
	...
	private:
	...
		vector< Conn > c_; // A single vector with all the conns
};

// Every SingleSrc needs to know its start, but it can be compiled in.
Template < unsigned int I > Class SingleSrc {
	unsigned int start() {
		return I;
	}
	RecvFunc rf_;
};

class FuncHandler {
	RecvFunc rf_;
	unsigned int used_;
	unsigned int availble_;

	send ( T v ) {
		for
	}
};

Class NSrc {
	unsigned int start_;
	vector< FuncHandler > fh_;

	send( T v ) {
		// Internally there are two options here.
		vector< FuncHandler >::iterator i;

		// Here we just use the Element* argument
		for (i = fh_.begin(); i != fh_.end(); i++ )
			i->send( v, c_ + start );
		
		// Here we use both the Element* argument and also dest index
		// The dest index is needed for messages doing:
		// Relay: used to look up additional info (but that can be in
		// the alternate Element*)
		// Synapse: Used to look up syn wt and other syn local info
		// 	Need to put this in the send loop.
		// Return msg: Used to send info right back.
		//	But here we could just pass in the originating elm ptr
		// Solver msg: Used to identify caller and sometimes send
		//	back info. Need to put in send loop.
		for (i = fh_.begin(); i != fh_.end(); i++ )
			i->send( v, c_ + start );
	}

	sendTo( T v, unsigned int index ) {
		// Nasty bit here is to look up the recvFunc.
		// Alternately, the sender could send the element*. But
		// still need to find recvFunc.
		// Alternately, the local handler could do the lookup for the
		// target element* and replace the index with the element*
		// However, we still need to look up the recvFunc, so index
		// is probably best.
	}
};


Having done this:
All but one of the Conn classes vanish: Only Conn remains. No virtual stuff.
MsgSrc classes are modified, but similar number needed to template arguments.
There is a zoo of Finfos for different messages/fields etc. Some simplification.
SingleSrcFinfos and NSrcFinfos are not much affected. They were templated for
	arguments.


- We need a couple of Element* wrapper elements with associated recvfuncs
	to handle Relay messages.
- We need an efficient way to consolidate the Conn array and FuncHandlers.
	- For deleting
- We need an efficient way to find and replace recvfuncs and index when we
	create relays.

.............................................................................

Back to the present. Trying again to compile. Succeeded. Next steps:
- put in tables for the molecule info, 
- test the Ksolve messaging.
- Check in version.
- Interface with stoich
- Test overall solver system
- Put in RK solve
- Put in one of the GSL solvers.

- Consider refactoring messages.

============================================================================
27 Aug 2006
Problem with connections using SolveMultiConn: They end up using the
managing SolveMultiConn rather than the individual SolverConns.
Fixed that. Various other fixes. Current issue: SolveMultiConn is not correctly
identifying message sources. Fixed.
Next steps:
- put in array rather than fudging the return value
- Look at doing for reacs too
- Check in.
- See above list.

============================================================================
29 Aug 2006

Got array stuff to work. Also figured out how to handle the value assignment
stuff in the reacs, but the connectivity definition stuff still needs
thought. This was a critical part of the stoichmat object, but it looks like
scanning the model should be done by Ksolve. So Stoichmat is reduced to
doing the updates, and even that is mostly by the halfreac objects that
Ksolve will be setting up.

Anyway, for now we have enough working to justify a checkin.
Done, as revision 9.

Now working on getting the rest of the solver stuff in. 
* Separated out the code into a Ksolve.cpp file.
- Need to figure out how to handle different states of molecules:
	regular, buffered, and variable.


============================================================================
30 Aug 2006
Working on handling buffers too. 
in basecode::Conn.cpp:291: why is sourceSlot not 1 for the buffer? The
segments array looks OK, with 14 in 0 and 15 in 1.

Seems to be an issue with the way SharedMsgs work. Best to allocate a 
separate MultiSolveConn for each of the varMols, bufMols, and sumTotMols.

Issue is now that we end up with non-contiguous arrays for the molecules,
unless I do some creative stuff using offsets, in the functions that handle
access.

This is turning quite messy. There are several SharedFinfos that all use
processOut and reinitOut. The Conn and SharedFinfo basecode have to be able to 
manage multiple things on one Conn vector. 
Another aspect of this: processSrc and reinitSrc use molSolveConn. So does
mol. But sumtots use sumTotSolveConn. Won't work.

- Need to send a message to _all_ targets. Process is the obvious target to use.
- Need to get back to the SharedFinfo::maxIndexOfMatchingFunc to get the
	correct slot. With this it should be possible to share the conn
	between radically different message types.

============================================================================
31 Aug 2006

Looking at the design for messaging and Conns. The current problem is that
the MsgSrcs fail to correctly find which slot to use for the message,
especially in the messy context of the SharedConns.

In theory, any unique combo of recvFuncs for SharedConns should occupy a
separate slot. This seems not to work. The current algorithm simply looks
for the max entry. Need actually to look for a signature for the unique combo.

Another issue: SingleMsgSrcs on a SharedConn. Even worse, when they combine
with NMsgSrcs.

Conclusion:
Need to specify SharedConn slots by looking up the whole array of recvfuncs.
Combinations may matter. Assume that Single recvfunc treat any index as
the same. This is the current behaviour. The case should not really come up.

Worked through the motions on this. The conclusion is that current
SharedMessages will only handle a single message set at a time. Holes
in the rfuncs lists otherwise appear. It works, though.
Corrollary of this is that I need to define a whole set of Process, Reinit
and other message sources for each of the things that the Ksolver handles,
such as mol, buf, sumTot, reac and enz. Fifteen at least.

Anyway, the molecule stuff now works. On to the others. First check it in.

Did some updates to the preprocessor, it now does many of the solver-specific
things. Cannot handle the multiple shared messages using the same Conn, though.
Added in shared stuff for reacs, enz, mmenz, tables and rates.
Quick checkin before I start getting the rest of the system set up.
Now at revision 11.

Next steps: 
- handling the reacs and enzs.
- Scan model structure to build stoich matrix and rate vector
- Redo stoich object to talk to Ksolve via pointers
- Put in a RKsolver
- Put in rates
- Document and wrap up solver stuff.

============================================================================
1 Sep 2006

Developers discussion.

My key points:

Iterative design: I want to have all the parts working together, even as
a kludge, to get the big picture. Then we can optimize, refactor and so on.

Current status: I am working on the kinetic solver stuff. Issue is not the
solver itself, but its API via messaging. I think that is now ready to launch.

Remaining big gap(s)
	What about parallel stuff?
		Inter-node Messaging
		Threads
	What about persistence?
	What about GUI?

Will they change any user object design stuff?
Do we know enough now to be able to standardize the .mh format?

Specific ideas on refactoring messaging and connections.
Other specific ideas.

Do we want to separate parameters from variables.


Much work done to get Ksolve talk to everybody. A remaining segv which
looks like us running off the end of the segment_ array or perhaps the 
Conn Vec.
Merging in stoich code to build the data representation.

============================================================================
2 Sep 2006.

The stoich code is mergeable, but perhaps it would be better to have an
abstracted way of representing the connectivity so that instead of the
Ksolver doing the model assembly, the specific data handler
(stoich in this case) should. Ksolve should provide the interface to the
model details so that the data handler does not even need to know that
there are elements involved. I am not sure if this is a realizable goal.
Options:
1. Current: Ksolve builds stoich matrix, rate and S_ and Sinit_
	vectors. We have almost merged the entire Stoich class into Ksolve.
	- Ksolve is severely overloaded
	- Stoich is nearly empty.

2. Ksolve only handles messaging I/O. Stoich class still talks to model to
	build its internal data structures. In fact we could have Ksolve
	come in post-facto to set up the messaging I/O.
	- This produces two points of contact with the model. 
		- Ksolve is dependent: It does not get set up till Stoich is.
		- Stoich is primary. But once built it is hands off.
			- Sometimes we may want the stoich matrix on its own.

Option 2 seems to be a cleaner separation of roles, though it is not what
I originally envisioned. Now we need to redefine the operation of the 
Ksolver, which may even become a generic object:
	- Function to build each set of messages.
		- controlMols( vector< double >* S_, vector< double >* Sinit_, 
			vector< Element* >* mols );
		- controlBufs( vector< double >* S_, vector< double >* Sinit_, 
			vector< Element* >* mols );
		- controlReacs( vector< molRate >* S_, 
			vector< Element* >* reacs );
		- controlEnzs( vector< molRate >* S_, 
			vector< Element* >* reacs );
		...

Actually, looking at this it doesn't seem so easy to make it a generic.

Nomenclature:
	Old		New
	Ksolve 		KineticHub
	Stoich		Stoich
	ForwardEuler	ForwardEuler

Before going ahead with this change, I'll check in the sort-of-working
version we have. There are still issues with the mol, buf and sumTot use
of the same Conn, but the basics of the solver messaging interface
seem to be adequate.
Checkin done.
Begin work on KineticHub

============================================================================
3 Sep 2006
Almost got it to compile. Still to add stuff to stoich so it can talk to the
hub.

KineticHub compiles.
Working on Stoich.mh so that it generates the whole thing. Almost, but the
	usual minor preprocessor issues require a bit of hand-fixing. Compiles.

Checked in at this point as revision 13.

Forthcoming steps:
* Update Stoich.mh so that it talks to KineticHub
* Update KineticHub.mh so that it works with all fields of Stoich.mh
- Update KineticHub::zombie so that it transfers all nout and cout messages
	to KineticHub, and sets up Stoich so that these fields are updated
	per clock tick or even per internal tick.
- Implement Rate object and its linkage to KineticHub and onward to Stoich.mh
- Figure out how to rebuild models. The current zombie approach is one-time.

============================================================================
4 Sep 2006
Set up test script khub.g to put it all together. Immediate effect of
connecting Stoich to KHub is a segv. Should really put it all in a 
shared message.

Fixed segv.
Successfully set a value of an object being solved, and had the solver
recognize the fact, and proceed with the altered simulation. This is in
test/khub.g. Also able to get the value of the object.

From now it is all details.

Setting up reacConnection. It is a little tricky because we have 3 ways of
connecting up a reac:
forward only.
backward only.
both, separate
bidirectional.
All doable using flags and stuff, but it would be nice to be clean.
Options:
	- Use 4 kinds of reacConnections, one for each case
	- Use flags and typecasting
	- Require all reacs to be bidirectional
		- Small speed penalty
		- Avoids issue of restructuring if rates change.
		Actually turns out that they are bidirectional unless
		something really odd happens.

Ended up with a clean solution: added a virtual function for assigning 2 rates,
	sometimes only one is used.

Check in before I begin the job of converting the Stoich.mh and KineticHub.mh.
That was revision 14.
Managed to compile Stoich.mh. Only error was the comma at end of
initilization list, and its EPSILON.
Managed to compile KineticHub.mh. Loads of errors at first, but in the end it
compiles cleanly with no user intervention.

Unfortunately the code does not even handle the good old assignment to a
molecule. Debug it tomorrow.

============================================================================
5 Sep 2006.
Yesterday's issue was simply that the khub.g script had not been updated to
use the shared messaging.

Today: the enzymes are not being connected up to the solver. It complains
that no solve message is found on the enzyme.
OK, issue was that the conn array was not being resized to allocate storage.

Sorted that out. Now there is an effect of changing a rate: I get nans.
Various other fixes later: now the assignment of rates also works.

Check it all in.  Done as Revision 15.

Prioritize: What would it take for me to begin using it?
* Solver messaging: need for graphs: Day?
	This was actually pretty easy: a matter of placing SolverUpdate
	in the ValueFinfo Get and Set operations.
	Still leaves dangling other kinds of messages from zombies.
- Solver methods: GSL based ODE solver: 2 days. But no immediate use.
- Solver methods: Fast Gillespie: Week? Useful on robustness.
- HSOLVE able to handle mitral cell and bulb model: Week?
- Parallelization: Week??? Would love to have automatic farmer.
- Graphics, at least some stupid FLTK widgets
- Refactoring: Month?

Should clean out attempts of ClockTick to rebuild path to solved objects.
Unfortunately the original .mh is a mess and a big pain to rebuild.
I did the rebuild, but it seems to have broken.
Still haven't fixed the innerSetPath function to ignore solved elements.
============================================================================
6 Sep 2006
Much fixing and cleaning up. Now the innerSetPath ignores solved elements,
and I was able to get solver messaging to work with graphs. At this point
I can send this in as a release which mostly works as a solver example.

============================================================================
9 Sep 2006
Parallelization is the last big fundamental API thing to be done before
we go on to functionality work and/or refactoring.
Design points:
	- A postmaster per node.
	- Messages need to be sorted by type and sending schedule.
		Want to group as many as possible together.
	- Postmaster refuses return messages? But some (e.g., channels)
		are invisible. Others, like plots, can afford a lag.
	- Each node has a 'star' tree, or 'global' if you like. This
		holds objects for which duplicates are made on all nodes.
		Don't know if this needs to be so formal
	- Use specially named base objects to describe partitioning of objects.
		For example, in a diffusive kinetic model with n compartments,
		could put the model on /all. This is deprecated. The 
		preferred approach is to do the same kind of copies as on
		a single node, but to somehow make them spawn onto different
		nodes. Maybe simply pcopy /foo /#/foo. Or haveth
		Or use the createmap with some node parsing objects.

============================================================================
10 Sep 2006
For now, skip the high-level details. For the parallel API we first need
to make sure that we can generate and propagate 
- messages
- Objects
- Commands

Stages:
	- Write a PostMaster object that simply copies binary data from one
instance to another, as a surrogate for internode messaging.
	- Set up generic messaging into this PostMaster
	- Set up generic messagion out of the PostMaster
	- Communicate messages
	- Communicate message setup
	Later, move on to propagating objects and commands.

Implemented first pass at postmaster, compiled it in with lots of dangling
bits. I now need to set up a number of
support functions in Ftype.h and then I need to fiddle with the finfo::add
function to deal with replacing the Recvfunc with the one provided by
the originating finfo itself.
Also need to implement the traversal code so we can establish scheduling.

============================================================================
14 Sep 2006
Most of the messaging to and from the postmaster have been implemented.
Some issues with the MultiFtype in Ftype.h. What do we do about its local
rfuncAdapter, postRecvFunc and size.

============================================================================
17 Sep 2006
At this point the system compiles and appears to set up messages to the 
postmaster. The PostMaster has been heavily edited by hand, will later
need to go back to fix its .mh. 
Current issue is that I have set the reinit and Process to use solveConns
because we need to handle multiple incoming clock ticks for different things
to go out. Unfortunately solveConns need to be initialized. The obvious
place to do this is at reinit, but we cannot call reinit till the solveConns
are initialized.
If we manually call reinit before the regular thing, then we get other
problems but not a segv.

Much nasty debugging later, turns out that the Conn* coming to the 
getPostPtr function is the parent SolveMultiConn, not the SolverConn.
This probably has to do with the fact that we have only implemented solveconn
stuff from the viewpoint of the originator of the message.

Anyway, now I should check it all in because there has been a lot of change
and we are getting close, and at least this version compiles.
Also Joe has a version that compiles on Fedora 5, so we should merge into that.

The current version is checked in as version 17.

Tracked down at least some of the problems with scheduling of the postmaster
to the fact that the SolveConn it uses does not provide valid iterators
for begin and end. Nor should it. I need to recast the scheduling with
something other than a solve msg, even though it is convenient for
lookup. Possibly a synapse message? Save may also work better for our
actual data messages.

For now I'll just have a single tick0 and another tick1 dest messages from
the scheduler. Rebuilt PostMaster.mh and did a lot of retrofixes.
Compiled. Dumps core when I run.

============================================================================
23 Sep 2006
Fixed up in ugly hack way. Now it runs up to handling the outgoing messages:
outgoing from current node to remote nodes.
Not yet working for incoming. Much cleanup remaining to handle general
messages.
============================================================================
24 Sep 2006
Quick initialization fix so it doesn't segv. So far it handles outgoing but
not incoming. Let's check it in now before moving on. This was revision 18.

Now looking at incoming. The problem is that the message source on the
postmaster does not recognize aribitrary targets. We will need to
- Implement a variant of the msgsrc so that the messages get sent.
- Alter the send command so that it iterates through the incoming buffer
	in order to send the data.
- Perhaps set things up with a solve message so we can be sure about the
	order of the outgoing messages.

============================================================================
25 Sep 2006

Set up stuff to handle incoming msgs, that is, connecting postmaster to
arbitrary targets.
Nearly compiled, lots of const issues.
Compiled. Surprisingly, it runs without errors, but it does not seem to
be successful in making the outgoing message.

============================================================================
26 Sep 2006
Now outgoing message works too. But it isn't being called.

============================================================================
30 Sep 2006
Now both the incoming and outgoing messages work and I can transfer info
from one to another, and it comes out right. That confirms that the
messaging is fundamentally OK. Now on to scheduling this info flow.
First, check in this version. It was version 19.

Moving on. Issues:
- Building the internode messaging data allocation.
- Scheduling messaging across nodes
- Managing shared messages across nodes
- Selecting correct postmaster to handle message.

One thing to keep in mind is that when we have enough of the implementation
done to have a good list of all use scenarios, we should reimplement the 
messaging to use the fixed conn class. Excessive grunging with the
postmaster may not be a good thing till that conversion is complete.
Also we need to prioritize other things like making the whole system
useful.
For example, we need to do
- Joe's gcc4.1 compile fixes
- 64 bit compile
- Implement serious solvers (e.g. GSL)

===========================================================================
19 Oct 2006
- Data allocation for messaging: too messy to deal with right now. Let's
	get the more future-proof stuff in first.
To schedule outgoing messaging: 
	- At reset: Traverse each incoming back to source clock tick
	- Group all messages that share a clock tick.
	- Add a tick just after each tick, put this set of postmasters on it.
	- Set up data so that the correct set of outgoing messages go out
		on the correct tick.
	- Axon msgs have a delay field. If this is big enough, just
		piggy-back onto one of the other ticks.

To schedule incoming messaging:
	- Need a way to find when a message will be needed. Each msgdest
		needs to specify the next msgdest that needs its contents.
		Similar to way we specify the dest that triggers a msgsrc,
		but note that here we specify only an information flow link,
		not a direct execution link that msgsrcs have.
	- Set up the incoming messages: pass extra info from postmaster of src
		node to dest node. This could in principle be done at the
		same time that messages were being set up, but see below.
	- When all messages are set up: Traverse list of incoming msgs, 
		group all that share the same 'needed' tick.
	- Add a tick just before the 'needed' tick. Goes to all postmasters.
		Given that we keep doing this, we should find a way to 
		automatically ensure this is available in the scheduler.
	- Send the output of this tick to the postmaster to trigger a
		blocking wait for the internode message.

===========================================================================
20 Oct 2006
Implemented massive merge with Joe Svitak's code base, which is what lives
on SourceForge. Much of it is to do with separating out header dependencies.
There may be a few things dangling still, but the current merge compiles and
takes care of most of it. Will need to check later with the gcc4.1 compiler.
Checked it in as revision 21.

===========================================================================
21 Oct 2006
Checked compile on 64-bit system (gj) g++ (GCC) 4.1.1. Works.
Checked compile on 64-bit RH system (imarti). Compiles but fails unit test for
	scheduling.
Checked compile on 32-bit Ubuntu system (kadam). Compiles, passes unit tests.

Tracked down issue with RH system. Shell::isInteractive_ was not being
initialized. Check it in, revision 22.

===========================================================================
