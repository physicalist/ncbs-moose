\section{Construct a Database/AST from XML models}
\label{sec:multiscale}
  
  This is our defining module and it contains the basic functionality of this
  application. All XML modules are parsed into a dictionary and this dictionary
  is passed to the object of class [[Multiscale]] which is the main class in
  this module. We also have [[adaptorML]] file parsed in dictionary. 

\begin{remark}{Why AST/Database?}
 
 Should I directly map XML models to moose objects or a intermediate
 representation would be better. I am leaning towards haivng a intermediate
 sqlite3 based data-structure. The benefit of using sqlite is that we can simply
 insert and query the database without having to keep all XML models open. We'll
 simply populate the database for each given model. Details are bit hazy in my
 mind right now and I should add the them to this document as they become
 clearer to me.

\end{remark}
 
\paragraph{Structure} Structure of this module is following. 

%file:src/multiscale.py
<<multiscale>>=
<<Import>>
<<Local imports>>
<<Definition of class [[Multiscale]]>>

@ %def multiscale 

\paragraph{A skeleton of class}

  Now we have parsed XML. We are passing the parsed XML in dictionary to a
  method [[buildMultiscaleModel]] of this class. We know, what this class must
  have at this point. Let's write it down and we'll wonder later how to add more
  functionality. 
  
<<Definition of class [[Multiscale]]>>=

class Multiscale :
  
  def __init__(self, xmlDict) :
    self.xmlDict = xmlDict 
    <<initialize members>>
    debug.printDebug("INFO", "Object of class Multiscale intialized ...")

  <<methods in class [[Multiscale]]>>

  # This is the entry point of this class.
  def buildMultiscaleModel(self) :
      debug.printDebug("INFO", "Starting to build multiscale model")   
      <<flow of executation>>
  
  def exit(self) :
    # Clean up before you leave
    <<clean up the mess>>

  # Write down the tests, whenever needed.
  <<tests in class [[Multiscale]]>>



@ %def [[Multiscale]]

Before we move on, lets discuss some models developed by others we need to
import into moose.

%\include{proto.nw}

\subsection{Database to keep the XML models}
\label{subsec:database}

  We use sqlite3 database. Let import it and add a section in our class to
  handle this database.

<<Local imports>>=
import sqlite3 as sql 
@ 

<<methods in class [[Multiscale]]>>=
<<methods to deal with database>>
@

  And lets open a database and initialize it. And add code to clean up the
  connection before exiting the class.

<<initialize members>>=
self.dbdir = 'db'
self.dbname = 'models.db'
self.dbpath = os.path.join(self.dbdir, self.dbname)
if not os.path.exists(self.dbpath) :
  try :
    os.makedirs(self.dbdir)
  except Exception as e :
    debug.printDebug("ERROR"
        , "Faild to create directory {0} with error {1}".format(self.dbdir, e))
    sys.exit(0)
self.conn = sql.connect(self.dbpath)
self.cursor = self.conn.cursor()
@ %def database 

<<clean up the mess>>=
self.cursor.commit()
self.conn.close()
sys.exit()
@ %def exit

\subsection{Populate database}

    We have the parsed models and we would be searching them extensively when
    combining them together to map onto moose. Populate the sqlite3 database
    such that we can query it easily.

<<flow of executation>>=
<<populate database with models>>
<<build queries from adaptorML>>
<<run queries and generate moose scripts>>
@ %def flow

\paragraph{Populating database}

    Should be directly translated XML to [[sqlite3]]? No, that would defeat the
    purpose of using sqlite3 in the middle. We must transform the XML as much as
    we can to create a well-defined database which we can simply query and build
    moose scripts. Let's me describe the flow. ETL stands for standard practise
    of \textbf{E}xtract, \textbf{Transform}, and \textbf{L}oad.

\begin{figure}[h]
\centering
\begin{tikzpicture}
    [every node/.style = {minimum size = 1.5cm}, font=\small]
    
    %\input{macro.tex};
    %\myscript{(0,1)}{3}{4}{hello};

    \node[draw, rectangle] (model1) at (0,0) {\texttt{model1.xml}};
    \node[draw, rectangle] (model2) at (0,2) {\texttt{model2.xml}};
    \node[draw, rectangle] (model3) at (0,4) {\texttt{model3.xml}};
    \node[draw, circle] (db) at (4,2) {\texttt{sqlite3}};
    \node[draw, rectangle] (gen) at (8,2)  {\texttt{moose generator}};
    \node[draw, rectangle] (adaptorML) at (8,4) {adaptorML};
    \node[rectangle] (moose) at (8,0) {moose.py};
    \draw[->] (model1) -- node [below, midway] {ETL} (db);
    \draw[->] (model2) -- node [label={[xshift=0cm,yshift=-0.5cm]ETL}] {} (db);
    \draw[->] (model3) -- node [above, midway] {ETL} (db) -- (gen);
    \draw[->] (adaptorML) -- (gen) -- (moose);

\end{tikzpicture}
\label{fig:multiscale_flow}
\caption{Flow of multi-scale modelling. ETL stands for \textbf{E}xtract
\textbf{T}ransform and \textbf{L}oad.}
\end{figure}

\paragraph{Extract, Load and Transform}

  Now we are ready. Lets do ELT on each XML file.

<<populate database with models>>=
for xml in self.xmlDict :
  xmlRootNodeList = self.xmlDict[xml]
  for xmlRootNode in xmlRootNodeList :
    self.extractTransformLoad(xml, xmlRootNode)
@ %def ETL

  Now the hard part of populating the database.

<<methods to deal with database>>=
def extractTransformLoad(self, modelType, xmlRootNode) :
  if modelType == 'nml' :
    self.etlNMLModel(xmlRootNode)
  else :
      pass 

@ %def extractTransformLoad


\paragraph{ETL a NML model}

  ETL an neuroML model. 

<<methods to deal with database>>=
def etlNMLModel(self, nmlRootNode) :
  debug.printDebug("STEP", "ETLing a nml model")
 
@ %def etlNMLModel  
